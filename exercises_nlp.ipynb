{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNpYjwrVUvOPNaxuiFIBuHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/introduction-to-nlp/blob/master/exercises_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises on Natural Language Processing with TensorFlow\n",
        "\n",
        "- [x] Rebuild, compile and train model_1, model_2 and model_5 using the [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) instead of the Functional API.\n",
        "- [x] Retrain the baseline model with 10% of the training data. How does perform compared to the Universal Sentence Encoder model with 10% of the training data?\n",
        "- [ ] Try fine-tuning the TF Hub Universal Sentence Encoder model by setting training=True when instantiating it as a Keras layer.\n",
        "\n",
        "```\n",
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=True) # turn training on to fine-tune the TensorFlow Hub model\n",
        "```\n",
        "- [ ] Retrain the best model you've got so far on the whole training set (no validation split). Then use this trained model to make predictions on the test dataset and format the predictions into the same format as the sample_submission.csv file from Kaggle (see the Files tab in Colab for what the sample_submission.csv file looks like). Once you've done this, [make a submission to the Kaggle competition](https://www.kaggle.com/c/nlp-getting-started/data), how did your model perform?\n",
        "- [ ] Combine the ensemble predictions using the majority vote (mode), how does this perform compare to averaging the prediction probabilities of each model?\n",
        "- [ ] Make a confusion matrix with the best performing model's predictions on the validation set and the validation ground truth labels."
      ],
      "metadata": {
        "id": "3A_DkGAZdeiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get ready with the Data"
      ],
      "metadata": {
        "id": "WX4eAB1k6dIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First checking the prerequisite for this exercise notebook\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi1N25Hh5uyd",
        "outputId": "7e9ee3ed-53e8-4e3c-ec51-2447cfe8dbb0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-148bce30-f304-adb8-29c6-9fc207b2b92f)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the helper function\n",
        "!wget https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
        "\n",
        "from helper_functions import unzip_data, create_tensorboard_callback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqh71-tS6ILo",
        "outputId": "f34fe534-09fa-478b-f03a-c83b68791527"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-27 03:27:29--  https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2904 (2.8K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]   2.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-27 03:27:29 (43.2 MB/s) - ‘helper_functions.py’ saved [2904/2904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the dataset of tweets\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# unzip the data\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR7ZBRPR6UNz",
        "outputId": "5a94fbbd-f1e0-42c2-a136-2456cebabcf7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-27 03:27:53--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.147.128, 142.250.125.128, 142.250.136.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.147.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2023-02-27 03:27:53 (104 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the text dataset\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# shapes\n",
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5VeP8ee6gkz",
        "outputId": "9945a1f8-d95f-4ec4-831a-b5a4ef2485cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7613, 5), (3263, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view any samples\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x_xf_FYR6xTD",
        "outputId": "2d7722e6-16aa-405e-d9a4-e29be5bc1281"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b00dc237-a234-464c-b284-030565502db3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b00dc237-a234-464c-b284-030565502db3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b00dc237-a234-464c-b284-030565502db3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b00dc237-a234-464c-b284-030565502db3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need to reshuffle the training dataset\n",
        "train_shuffled_df = train_df.sample(frac=1, random_state=17)\n",
        "train_shuffled_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f2ZTvKqU69XC",
        "outputId": "2f6b5e7c-41fa-403f-f5e9-6cae180904ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id            keyword                    location  \\\n",
              "7027  10072            typhoon                         NaN   \n",
              "318     463         armageddon                         NaN   \n",
              "1681   2425            collide  www.youtube.com?Malkavius2   \n",
              "5131   7318  nuclear%20reactor          New York, New York   \n",
              "2967   4262           drowning          Hendersonville, NC   \n",
              "\n",
              "                                                   text  target  \n",
              "7027  Typhoon Soudelor: When will it hit Taiwan ÛÒ ...       1  \n",
              "318   RT @RTRRTcoach: #Love #TrueLove #romance lith ...       0  \n",
              "1681  I liked a @YouTube video from @gassymexican ht...       0  \n",
              "5131  Japan's Restart of Nuclear Reactor Fleet Fast ...       1  \n",
              "2967  #ICYMI #Annoucement from Al Jackson... http://...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a196a63-b711-442a-94f6-7dd1487e9ccd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7027</th>\n",
              "      <td>10072</td>\n",
              "      <td>typhoon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor: When will it hit Taiwan ÛÒ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>463</td>\n",
              "      <td>armageddon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @RTRRTcoach: #Love #TrueLove #romance lith ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>2425</td>\n",
              "      <td>collide</td>\n",
              "      <td>www.youtube.com?Malkavius2</td>\n",
              "      <td>I liked a @YouTube video from @gassymexican ht...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5131</th>\n",
              "      <td>7318</td>\n",
              "      <td>nuclear%20reactor</td>\n",
              "      <td>New York, New York</td>\n",
              "      <td>Japan's Restart of Nuclear Reactor Fleet Fast ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2967</th>\n",
              "      <td>4262</td>\n",
              "      <td>drowning</td>\n",
              "      <td>Hendersonville, NC</td>\n",
              "      <td>#ICYMI #Annoucement from Al Jackson... http://...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a196a63-b711-442a-94f6-7dd1487e9ccd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a196a63-b711-442a-94f6-7dd1487e9ccd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a196a63-b711-442a-94f6-7dd1487e9ccd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the training and test set from the train_shuffled_df\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_shuffled_df['text'].to_numpy(),\n",
        "                                                                              train_shuffled_df['target'].to_numpy(),\n",
        "                                                                              test_size=0.1,\n",
        "                                                                              random_state=17)"
      ],
      "metadata": {
        "id": "UnfndF5R7S6v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Vectorizer & Embedding Layer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "max_vocab_length = 10000\n",
        "max_length = 15\n",
        "# using the default vectorizor variables\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)\n",
        "\n",
        "# fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)\n",
        "\n",
        "# creating the embedding layer\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer='uniform',\n",
        "                             input_length=max_length,\n",
        "                             name='embedding_1')"
      ],
      "metadata": {
        "id": "5rLDYMl9_RBu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Rebuild, Compile and Train model_1, model_2 and model_5 using the Keras Sequential API instead of the Functional API\n",
        "\n",
        "\n",
        "Brief about each models,\n",
        "\n",
        "- `model_1` : Simple Dense Model\n",
        "- `model_2` : LSTM (RNN)\n",
        "- `model_5` : 1D (CNN)\n"
      ],
      "metadata": {
        "id": "s5ltEyOW5jeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model_1 : Simple Dense Model using Sequential API"
      ],
      "metadata": {
        "id": "_7SQUh-j5ri7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "SAVE_DIR='model_logs'\n",
        "\n",
        "# Build model with Sequential API\n",
        "model_1 = tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,), dtype=tf.string),\n",
        "    text_vectorizer,\n",
        "    embedding,\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(1, activation='sigmoid', name='model_1_sequential_dense')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# fit the model\n",
        "history_1 = model_1.fit(train_sentences,\n",
        "                        train_labels,\n",
        "                        epochs=5,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                experiment_name='model_1_sequential')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D6tqRSLBU_v",
        "outputId": "d98136c0-86ac-423a-cb79-de419881a638"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/model_1_sequential/20230227-041319\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 19s 66ms/step - loss: 0.6127 - accuracy: 0.6895 - val_loss: 0.5231 - val_accuracy: 0.7625\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 7s 32ms/step - loss: 0.4420 - accuracy: 0.8181 - val_loss: 0.4657 - val_accuracy: 0.7887\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3476 - accuracy: 0.8625 - val_loss: 0.4626 - val_accuracy: 0.8005\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2843 - accuracy: 0.8907 - val_loss: 0.4708 - val_accuracy: 0.8018\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2373 - accuracy: 0.9133 - val_loss: 0.4876 - val_accuracy: 0.7940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = model_1.evaluate(val_sentences, val_labels)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8v9w6fyElYK",
        "outputId": "33f1e940-924a-4d00-d23a-7abdb211fb42"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4876011312007904, 0.7939632534980774]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model_2 : LSTM (RNN)"
      ],
      "metadata": {
        "id": "lZz79VDXE8_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create new embeddings\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name='embeding_2')\n",
        "\n",
        "# Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,), dtype=tf.string),\n",
        "    text_vectorizer,\n",
        "    model_2_embedding,\n",
        "    layers.LSTM(64),\n",
        "    layers.Dense(1, activation='sigmoid')    \n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name='model_2_LSTM')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8tsA23rFMNe",
        "outputId": "5e25ded1-5f96-4422-81ce-b786b8314fc3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/model_2_LSTM/20230227-042654\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 18s 64ms/step - loss: 0.5155 - accuracy: 0.7451 - val_loss: 0.4556 - val_accuracy: 0.7940\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.3154 - accuracy: 0.8679 - val_loss: 0.5009 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2113 - accuracy: 0.9221 - val_loss: 0.5747 - val_accuracy: 0.7717\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.1514 - accuracy: 0.9480 - val_loss: 0.6074 - val_accuracy: 0.7861\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 12ms/step - loss: 0.1078 - accuracy: 0.9607 - val_loss: 0.9480 - val_accuracy: 0.7507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = model_2.evaluate(val_sentences,val_labels)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gIauNY8H5hK",
        "outputId": "007b4bb5-5636-4aac-c12b-c658d3f1f0c3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 8ms/step - loss: 0.9480 - accuracy: 0.7507\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9480307102203369, 0.7506561875343323]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model_5 : 1D CNN"
      ],
      "metadata": {
        "id": "BqKJylpKIArl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create embeddings\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name='model_5_embedding')\n",
        "\n",
        "# create the model\n",
        "model_5 = tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,), dtype=tf.string),\n",
        "    text_vectorizer,\n",
        "    model_5_embedding,\n",
        "    layers.Conv1D(filters=32, kernel_size=5, strides=1, activation='relu', padding='valid'),\n",
        "    layers.GlobalMaxPool1D(),\n",
        "    layers.Dense(1, activation='sigmoid', name='model_5_CNN')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model_5.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                      experiment_name='model_5_CNN')])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phszlDDwIHjm",
        "outputId": "b67998ca-d000-4336-93d8-5c48611ebc21"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/model_5_CNN/20230227-044948\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 21s 66ms/step - loss: 0.5650 - accuracy: 0.7129 - val_loss: 0.4709 - val_accuracy: 0.7861\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3431 - accuracy: 0.8587 - val_loss: 0.4878 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2092 - accuracy: 0.9234 - val_loss: 0.5720 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.1400 - accuracy: 0.9529 - val_loss: 0.6529 - val_accuracy: 0.7861\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.0961 - accuracy: 0.9693 - val_loss: 0.7122 - val_accuracy: 0.7651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_results = model_5.evaluate(val_sentences, val_labels)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH3c7bxjNI9X",
        "outputId": "6c1d6fab-a7ea-4668-9e20-1f094dd1f2aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.7651\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7121530771255493, 0.7650918364524841]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrain the `baseline` model with 10% data"
      ],
      "metadata": {
        "id": "F4oLxC_ANOuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the 10% of random data\n",
        "train_10_percent_df = train_df.sample(frac=0.1, random_state=17)\n",
        "train_10_percent_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryKqluwcN9hk",
        "outputId": "8141b871-0473-45ef-cf71-94ab5b8af001"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(761, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create training and validation data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_10_percent_df['text'].to_numpy(),\n",
        "                                                                            train_10_percent_df['target'].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=17)"
      ],
      "metadata": {
        "id": "3Y5EUJ_-OOzw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fJ1JLCMNs52",
        "outputId": "d7a18185-a63a-4942-d509-c9625bcaa9b1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline_scores with 10% of data\n",
        "baseline_10_percent_score = model_0.score(val_sentences, val_labels)\n",
        "baseline_10_percent_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhWwAHQNPCwE",
        "outputId": "8576c62f-4dda-4473-d2dd-afc026505339"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8051948051948052"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like our baseline_10_percent_score still beating the universal sentence encoder results which was trained with 10% of data"
      ],
      "metadata": {
        "id": "u9ydAsKZPNyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UTigo87qPg9t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}