{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNQ2oQrdezVHwUOnmQ2zNa4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/introduction-to-nlp/blob/master/nlp_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing with TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ],
      "metadata": {
        "id": "Ep05V4vWV7mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we're going to experiment deep-learning models so we need to enable GPUs\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubzX8Z9hWWcu",
        "outputId": "32f23f0e-9e9c-4bbf-c5ea-2c874e7fef58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-1ff35a48-fdfc-9e13-a94c-2ab1fba38cc1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Helper functions"
      ],
      "metadata": {
        "id": "Tyusp2doWbLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper_functions.py script from Github\n",
        "!wget https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
        "\n",
        "from helper_functions import unzip_data, create_tensorboard_callback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlTigivCWskW",
        "outputId": "d5644ecd-c468-4801-98a1-38169ff8ea57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-03 04:38:33--  https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2904 (2.8K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]   2.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-03 04:38:33 (47.7 MB/s) - ‘helper_functions.py’ saved [2904/2904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a Text Dataset\n",
        "The dataset that we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster or not disaster)\n",
        "\n",
        "See the original source here: https://www.kaggle.com/c/nlp-getting-started"
      ],
      "metadata": {
        "id": "CZ_5BTF-W7K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# unzip the data\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F88ynPezXO3A",
        "outputId": "360b66a4-c884-4d0d-eb74-02aa4d3cc3ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-03 04:38:35--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.10.128, 142.251.12.128, 172.217.194.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.10.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-02-03 04:38:36 (151 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Text Dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, so we can do it through pandas."
      ],
      "metadata": {
        "id": "WyMBzit1XakQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# check the shapes\n",
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwqhQM8yXl7f",
        "outputId": "a0f7dd36-2ce2-4ba8-ca66-d1b17d23e011"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7613, 5), (3263, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view some samples\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HnvCJoJRXvcI",
        "outputId": "97c0dca7-09bd-4f54-a968-c13cbc896be9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f0be88f-78eb-42c1-a9c6-f44bbd997bc8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f0be88f-78eb-42c1-a9c6-f44bbd997bc8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f0be88f-78eb-42c1-a9c6-f44bbd997bc8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f0be88f-78eb-42c1-a9c6-f44bbd997bc8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here, `text` is the tweet and `target` variable is to identify whether the tweet is a disaster or not, so if `1` then it's a disaster else not a disaster.\n",
        "\n",
        "Let's visualize some random `training` samples, but before that this is a good practice to shuffle the training samples first,"
      ],
      "metadata": {
        "id": "A1v_p_ElXytS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled = train_df.sample(frac=1, random_state=17)\n",
        "# frac=1 means 100% of samples will be shuffled\n",
        "train_df_shuffled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "p17uRynCYEDW",
        "outputId": "85a6428a-ef65-499e-ab0b-989bb4140da1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id            keyword                    location  \\\n",
              "7027  10072            typhoon                         NaN   \n",
              "318     463         armageddon                         NaN   \n",
              "1681   2425            collide  www.youtube.com?Malkavius2   \n",
              "5131   7318  nuclear%20reactor          New York, New York   \n",
              "2967   4262           drowning          Hendersonville, NC   \n",
              "...     ...                ...                         ...   \n",
              "406     584              arson           Jerusalem, Israel   \n",
              "5510   7863        quarantined                 Livonia, MI   \n",
              "2191   3139             debris                         NaN   \n",
              "7409  10600            wounded               santo domingo   \n",
              "2671   3833           detonate    back in japan ??????????   \n",
              "\n",
              "                                                   text  target  \n",
              "7027  Typhoon Soudelor: When will it hit Taiwan ÛÒ ...       1  \n",
              "318   RT @RTRRTcoach: #Love #TrueLove #romance lith ...       0  \n",
              "1681  I liked a @YouTube video from @gassymexican ht...       0  \n",
              "5131  Japan's Restart of Nuclear Reactor Fleet Fast ...       1  \n",
              "2967  #ICYMI #Annoucement from Al Jackson... http://...       0  \n",
              "...                                                 ...     ...  \n",
              "406   Mourning notices for stabbing arson victims st...       1  \n",
              "5510  Reddit's new content policy goes into effect m...       0  \n",
              "2191  Plane debris discovered on Reunion Island belo...       1  \n",
              "7409  Police Officer Wounded Suspect Dead After Exch...       1  \n",
              "2671  Detonate (feat. M?.?O?.?P?.?)\\nfrom Grandeur b...       0  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a07bdc59-b2d4-4e19-8784-f2800de36315\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7027</th>\n",
              "      <td>10072</td>\n",
              "      <td>typhoon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor: When will it hit Taiwan ÛÒ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>463</td>\n",
              "      <td>armageddon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @RTRRTcoach: #Love #TrueLove #romance lith ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>2425</td>\n",
              "      <td>collide</td>\n",
              "      <td>www.youtube.com?Malkavius2</td>\n",
              "      <td>I liked a @YouTube video from @gassymexican ht...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5131</th>\n",
              "      <td>7318</td>\n",
              "      <td>nuclear%20reactor</td>\n",
              "      <td>New York, New York</td>\n",
              "      <td>Japan's Restart of Nuclear Reactor Fleet Fast ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2967</th>\n",
              "      <td>4262</td>\n",
              "      <td>drowning</td>\n",
              "      <td>Hendersonville, NC</td>\n",
              "      <td>#ICYMI #Annoucement from Al Jackson... http://...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>584</td>\n",
              "      <td>arson</td>\n",
              "      <td>Jerusalem, Israel</td>\n",
              "      <td>Mourning notices for stabbing arson victims st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5510</th>\n",
              "      <td>7863</td>\n",
              "      <td>quarantined</td>\n",
              "      <td>Livonia, MI</td>\n",
              "      <td>Reddit's new content policy goes into effect m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2191</th>\n",
              "      <td>3139</td>\n",
              "      <td>debris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Plane debris discovered on Reunion Island belo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7409</th>\n",
              "      <td>10600</td>\n",
              "      <td>wounded</td>\n",
              "      <td>santo domingo</td>\n",
              "      <td>Police Officer Wounded Suspect Dead After Exch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2671</th>\n",
              "      <td>3833</td>\n",
              "      <td>detonate</td>\n",
              "      <td>back in japan ??????????</td>\n",
              "      <td>Detonate (feat. M?.?O?.?P?.?)\\nfrom Grandeur b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a07bdc59-b2d4-4e19-8784-f2800de36315')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a07bdc59-b2d4-4e19-8784-f2800de36315 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a07bdc59-b2d4-4e19-8784-f2800de36315');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how does the test set looks like ?\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P0I_-hG1YYwu",
        "outputId": "7fdddd13-6a6b-4c60-ec4f-5ba62e705eae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-316481a7-795d-410b-a799-156fd79c567b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-316481a7-795d-410b-a799-156fd79c567b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-316481a7-795d-410b-a799-156fd79c567b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-316481a7-795d-410b-a799-156fd79c567b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class ?\n",
        "train_df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9FJ8OerYhVh",
        "outputId": "e232ead0-81f6-4da0-cffc-dc28d1479476"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random samples\n",
        "\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df_shuffled)-5)\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(disaster)\" if target > 0 else \"(not a disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgQTdLVzYtcu",
        "outputId": "49768c29-37e0-4ff7-ebab-7fd01c51d345"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not a disaster)\n",
            "Text:\n",
            "When he lets you drive his truck and you start panicking because you had to 'flip that bitch'. ?????? http://t.co/W6O0uiZF8p\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 0 (not a disaster)\n",
            "Text:\n",
            "Join #charity 10k #run event! @DoningtonDash\n",
            "11am start Sun 20 Sept 2015\n",
            "Castle Donington Community First Responders\n",
            "https://t.co/G1Nw99YJ8U\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 0 (not a disaster)\n",
            "Text:\n",
            "@czallstarwes more like demolition derby ??\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 0 (not a disaster)\n",
            "Text:\n",
            "@parksboardfacts first off it is the #ZippoLine as no one wants to use it and the community never asked for this blight on the park #moveit\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 1 (disaster)\n",
            "Text:\n",
            "on the flip side I'm at Walmart and there is a bomb and everyone had to evacuate so stay tuned if I blow up or not\n",
            "\n",
            "----------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset into Train and Validation sets\n",
        "\n",
        "Since the test set doesn't contain the target variable so we might need some unseen data for model to be validated after training, so how about splitting our training set for validating purpose with some amount.\n"
      ],
      "metadata": {
        "id": "WmmI2TzZZa1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=17)"
      ],
      "metadata": {
        "id": "jEgDccMKTYSx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting Text into Numbers\n",
        "\n",
        "Our labels are in numerical form (0 and 1) but our tweets are in string form.\n",
        "\n",
        "But machine learning algorithm learns only through numbers so we have to convert those tweets/texts into numbers.\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers,\n",
        "- **Tokenization** : A straight mapping from **word**(known as *word-level tokenization*) or character(which is *character-level tokenization*) or sub-word(*sub-word tokenization*) to a numerical value. Just like One hot encoding, suppose we have a sentence as \"My name is Alpha\", then if we are mapping according to word, \"My\" would `0`, \"name\" as `1`, \"is\" as `2` and \"Alpha\" as `3`.\n",
        "- **Embeddings** : An embedding is a representation of natural language which can be learned. Representation comes in the form of **feature-vector**. For example the word \"Alpha\" could be represented by 5-D vector `[0.564, 0.897, 0.456, -0.987, 0.15]`. The size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "\n",
        "    - **Create your own embedding** - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as `tf.keras.layers.Embedding`) and an embedding representation will be learned during model training.\n",
        "    - **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task.\n",
        "\n",
        "\n",
        "Simply, \n",
        "\n",
        "**Tokenization** : Straight mapping from word to number.\n",
        "\n",
        "**Embedding** : Richer representation of relationships between tokens.\n",
        "\n",
        "It depends on your problem. You could try character-level tokenization/embeddings and word-level tokenization/embeddings and see which perform best. You might even want to try stacking them (e.g. combining the outputs of your embedding layers using [tf.keras.layers.concatenate](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate)).\n",
        "\n",
        "If you're looking for pre-trained word embeddings, [Word2vec embeddings](https://jalammar.github.io/illustrated-word2vec/), [GloVe embeddings](https://nlp.stanford.edu/projects/glove/) and many of the options available on TensorFlow Hub are great places to start.\n",
        "\n",
        "Much like searching for a pre-trained computer vision model, we can search for pre-trained word embedding to use for your problem. Try searching for something like \"use pre-trained word embeddings in TensorFlow\"."
      ],
      "metadata": {
        "id": "MitNUg-uTxx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization\n",
        "\n",
        "Mapping words to numbers.\n",
        "\n",
        "To tokenize our words, we'll use the preprocessing layer,\n",
        "`tf.keras.layers.preprocessing.TextVectorization`"
      ],
      "metadata": {
        "id": "oyTzuPa0V5bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Using the default TextVectorization variables\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                 standardize=\"lower_and_strip_punctuation\", # how to process the text\n",
        "                                 split=\"whitespace\", # how to split the text\n",
        "                                 ngrams=None, # create groups of n-words\n",
        "                                 output_mode='int', # how to map tokens to numbers\n",
        "                                 output_sequence_length=None) # How long should the output sequence of tokens be?"
      ],
      "metadata": {
        "id": "k6z0y1iEIEs5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "About the above params,\n",
        "\n",
        "- `max_tokens` : The maximum number of words in your vocabulary (e.g 20000 or the number of unique words in your text), includes a value for OOV(out of vocabulary) tokens\n",
        "- `standardize` : Methods for standardizing text\n",
        "- `split`: split the text\n",
        "- `ngrams`: how many words to contain per token split, for example if 2, it splits tokens into continous sequences of 2\n",
        "- `output_mode`: How to output tokens can be `int`(integer mapping), `binary`(OHE), `count` or `tf-idf`\n",
        "- `output_sequence_length`: Length of tokenized sequence to output, For example if set to 150, all tokenized sequences will be 150 tokens long.\n",
        "\n",
        "In the above cell, we have initialized the object with the default settings but let's customize it a little bit for our own use case.\n",
        "\n",
        "In particular, let's set values for `max_tokens` and `output_sequence_length`.\n",
        "\n",
        "For `max_tokens`(the number of words in the vocabulary), multiples of 10,000(`10,000`, `20,000`, `30,000`) or the exact number of unqiue words in your text(e.g `32,179`) are common values.\n",
        "\n",
        "For our use case, `10,000`\n",
        "\n",
        "And for the `output_sequence_length` we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."
      ],
      "metadata": {
        "id": "CgAnhcS2KVIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "id": "c4ysmlUhLX6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb29ce7-bc10-4c8c-a8f3-8f409af2070d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000\n",
        "max_length = 15\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "KA553WXeaU4a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To map our `TextVectorization` instance `text_vectorizer` to our data, we can call the `adapt()` method on it whilst passing it our training set."
      ],
      "metadata": {
        "id": "KJZbqKiobF3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "OOfO1BecbdMe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data mapped! Let's try our `text_vectorizer` on a custom sentence."
      ],
      "metadata": {
        "id": "h0hxXVglbj3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a sample sentence\n",
        "sample_sentence = \"There's a flood in my village!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGCO1vkUb3eW",
        "outputId": "3e9e7903-3572-4dd6-a85b-430bc96e3cf7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[281,   3, 214,   4,  13, 881,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try our `text_vectorizer` on a few random sentences ?"
      ],
      "metadata": {
        "id": "LC1QnE2WcBfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original Text: \\n{random_sentence}\\\n",
        "        \\n\\n Vectorized Text:')\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYj-_VcNcP7u",
        "outputId": "fb10ca96-f916-4c1e-eaf0-476934f06f38"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: \n",
            "4 THOSE WHO CARE ABOUT SIBLING ABUSE SURVIVORS join the new family tree: http://t.co/LQD1WEfpQd http://t.co/GgnbVZoHWu        \n",
            "\n",
            " Vectorized Text:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 180,  163,   65,  527,   53, 4622, 3202,  404, 1396,    2,   49,\n",
              "         285, 1172,    1,    1]])>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check the unique tokens in our vocabulary using the `get_vocabulary()` method"
      ],
      "metadata": {
        "id": "ZrtMKcpgcfcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "\n",
        "print(f\"Number of words in Vocab:{len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words:{top_5_words}\")\n",
        "print(f\"Bottom 5 least common words:{bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJLbch5kcuc5",
        "outputId": "2330acba-2468-4536-8fcf-66fff1843180"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in Vocab:10000\n",
            "Top 5 most common words:['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words:['ovo', 'overåÊhostages', 'overzero', 'overwatch', 'overturns']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding\n",
        "\n",
        "**Create an Embedding using Embedding Layer**\n",
        "\n",
        "We've got a way to map our text to numbers. How about we go a step further and turn those numbers into an embedding?\n",
        "\n",
        "The powerful thing about an embedding is it can be learned during training. This means rather that just be static, a word's numeric representation can be improved as a model goes through data samples.\n",
        "\n",
        "We can see what an embedding of a word looks like by using the `tf.keras.layers.Embedding` layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "rnhKQAUFdRqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(17)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length,\n",
        "                             name=\"embedding_1\")\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4AxkJ4teKHO",
        "outputId": "6aad55bf-8de3-41b2-83f7-6b5a50ce45f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7fedb02e4070>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`embedding` is a TensorFlow Layer, so that we can use it as part of a model, meaning its parameters(word representations) can be updated and improved as the model learns.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wd2p3RPvevde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text: \\n{random_sentence}\")\n",
        "print(\"\\n\\nEmbedded version:\")\n",
        "\n",
        "# embed the random sentence\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GseLqO74tWkN",
        "outputId": "6df92d6e-e3e1-4bce-aed5-b6a7f8d20c48"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: \n",
            "you know you hate your body when you buy 2 bags of chips and a variety pack of fruit snacks and a redbull as a snack\n",
            "\n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.02013494,  0.00367814,  0.00704851, ...,  0.00118704,\n",
              "         -0.03017279, -0.02486727],\n",
              "        [-0.04007417, -0.00953885, -0.04488143, ..., -0.03326275,\n",
              "         -0.03895334, -0.0359932 ],\n",
              "        [-0.02013494,  0.00367814,  0.00704851, ...,  0.00118704,\n",
              "         -0.03017279, -0.02486727],\n",
              "        ...,\n",
              "        [-0.02031898,  0.03425609,  0.03940277, ..., -0.04002044,\n",
              "          0.01343619, -0.00712932],\n",
              "        [ 0.02456499, -0.0027171 ,  0.02670671, ...,  0.01225286,\n",
              "          0.04258173,  0.00253669],\n",
              "        [-0.04131304,  0.01487033, -0.04388602, ..., -0.04878377,\n",
              "          0.04338017,  0.02946276]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These values might not mean much to us but they're what our computer sees each word as. When our model looks for patterns in different samples, these values will be updated as necessary.\n",
        "\n",
        "If we review the shape of Embedded Version Tensor it is, `(1, 15, 128)`, it means that,\n",
        "- 1: Is the quantity of sequences(sentences) we passed\n",
        "- 15: is the `max_length` that we decided to normalize every sentence, if greater than 15 tokens/words then trim extra tokens or if less than 15 then pad it.\n",
        "- 128: is the array size of each words, for example above sentence as `Now`, for this token the embedding tensor will look like,"
      ],
      "metadata": {
        "id": "9Kp2cu1Dt4sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_embed[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW7O7e1UDyKn",
        "outputId": "7da0137f-ea04-41b7-e3cf-a4b10dc5ce72"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([-0.02013494,  0.00367814,  0.00704851,  0.03835148,  0.01900088,\n",
              "        0.00061114,  0.01187392,  0.04401598, -0.04037824, -0.00385005,\n",
              "        0.01364303,  0.01933743,  0.03797182,  0.0317191 , -0.03191744,\n",
              "       -0.02826787, -0.00074808,  0.04151082,  0.02736055, -0.04909203,\n",
              "       -0.04026247, -0.02701092, -0.00230974,  0.02857598, -0.03896632,\n",
              "       -0.0462239 , -0.00654601, -0.04307854, -0.03492272,  0.03922273,\n",
              "        0.00525022,  0.03337574,  0.04375429,  0.02135426, -0.01749852,\n",
              "       -0.03767998,  0.00622987, -0.00512462,  0.00042514,  0.03733614,\n",
              "        0.02118028, -0.02392187,  0.04331103,  0.02193166,  0.01353315,\n",
              "        0.0086139 , -0.01341078,  0.0312569 , -0.01739498, -0.04435037,\n",
              "       -0.0316669 ,  0.01047034, -0.00990814, -0.04527396, -0.00659496,\n",
              "       -0.00198267, -0.01089675,  0.00849969,  0.03371694,  0.0001568 ,\n",
              "       -0.03257991, -0.03354436, -0.00902262,  0.04805397, -0.03052126,\n",
              "        0.03420988,  0.0225759 ,  0.02412956, -0.00361841,  0.02357078,\n",
              "        0.02759062,  0.0358895 ,  0.00555966, -0.01104671,  0.02670917,\n",
              "       -0.01149912, -0.04600449, -0.02122371,  0.03641845,  0.01975889,\n",
              "        0.00578529,  0.00034078,  0.00419533,  0.00530782,  0.00098165,\n",
              "        0.0076366 ,  0.00182668,  0.0252146 , -0.04386685,  0.02729591,\n",
              "        0.03786436,  0.01167542,  0.04887078,  0.01576657,  0.01772387,\n",
              "        0.0343534 ,  0.00173308, -0.02619892,  0.01305903, -0.02827129,\n",
              "        0.01249971, -0.01967156, -0.01868419,  0.04275053,  0.03756601,\n",
              "       -0.02471166,  0.03991767,  0.0104507 , -0.02442626, -0.01967533,\n",
              "        0.04784118, -0.04809597,  0.0104891 ,  0.02331034, -0.01711237,\n",
              "        0.0170349 ,  0.04198204,  0.00447233,  0.03798867,  0.03513515,\n",
              "        0.00022355,  0.00918432, -0.03959032,  0.03468546, -0.01697385,\n",
              "        0.00118704, -0.03017279, -0.02486727], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation function for our Model Experiments\n",
        "\n",
        "Since we're going to perform multiple experiments by creating deeplearning models and scikit learn algorithms, so to track them we should create a common function for comparison.\n",
        "\n",
        "There are various metrics to evaluate the classification models like precision, f1-score, recall. So let's look at them through a function altogether."
      ],
      "metadata": {
        "id": "dbKbKEU5Fxy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates Model accuracy, precision, recall and f1-score for a binary classification model\n",
        "  \"\"\"\n",
        "  # calculate the model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred)\n",
        "  # calculate precision, recall, f1-score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy * 100,\n",
        "                   \"precision\":model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1-score\": model_f1}\n",
        "                  \n",
        "  return model_results"
      ],
      "metadata": {
        "id": "bcwg-4J5GKUj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a Text Dataset\n",
        "\n",
        "For experiments with various machine learning model for text classifier we will be considering below experiments:\n",
        "- **Model 0** : Naive Bayes (baseline)\n",
        "- **Model 1** : Feed-forward neural network (dense model) \n",
        "- **Model 2** : LSTM Model (RNN)\n",
        "- **Model 3** : GRU (RNN)\n",
        "- **Model 4** : Bidirectional-LSTM (RNN)\n",
        "- **Model 5** : 1D CNN\n",
        "- **Model 6** : TF Hub Pre-trained Feature Extractor\n",
        "- **Model 7** : Same as model 6 with 10% of training samples"
      ],
      "metadata": {
        "id": "LUy8YjJ2EWQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0 : Getting a baseline\n",
        "\n",
        "We'll use `scikit-learn` library for building this model, and create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert words into numbers and then model them using Multinomial Naive Bayes Algorithm.\n",
        "\n",
        "> 📖 **Reading**: About TF-IDF on [Scikit-learn documentation](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)"
      ],
      "metadata": {
        "id": "72x7n-xuFM8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IkZ6K-UF1j2",
        "outputId": "a96501a2-b8e0-4355-a69b-88862d64d267"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multinomial Naive Bayes model is kind of shallow model which trains faster."
      ],
      "metadata": {
        "id": "gLex6UKjGaDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zihkmgPZGkfC",
        "outputId": "4a85b5d0-8abc-44c6-dee5-5434b14895df"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 80.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make some predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZtZ-lodG0ii",
        "outputId": "7b8fc803-b792-4975-d6f8-24c7d65dce13"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it is similar to our labels\n",
        "val_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uWMFYvAG-qx",
        "outputId": "3dde9c9f-e885-4d51-9ef3-e9b8e11e26b6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbG9m6vqJhGL",
        "outputId": "ff8a4b87-d310-4745-ea3b-c9f76356ab6e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.18372703412074,\n",
              " 'precision': 0.8125567744156732,\n",
              " 'recall': 0.8018372703412073,\n",
              " 'f1-score': 0.7968681002825004}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1 : A Simple Dense Model\n",
        "\n",
        "The first \"deep\" model we're going to build is a single layer dense model."
      ],
      "metadata": {
        "id": "qZJjPR31JqYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create directory to save Tensorboard logs\n",
        "SAVE_DIR = \"model_logs\"\n",
        "\n",
        "# Build model with functional API\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn text inputs into numbers using text_vectorizer\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model\n",
        "\n",
        "# compile the model\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "history_model_1 = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh4r0AfCHfnh",
        "outputId": "eab6f61d-6b71-442e-bf55-8c870d8694dd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/simple_dense_model/20230203-043844\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 10ms/step - loss: 0.6152 - accuracy: 0.6854 - val_loss: 0.5256 - val_accuracy: 0.7638\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.4439 - accuracy: 0.8167 - val_loss: 0.4640 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.3478 - accuracy: 0.8616 - val_loss: 0.4596 - val_accuracy: 0.7927\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2846 - accuracy: 0.8864 - val_loss: 0.4721 - val_accuracy: 0.7979\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2380 - accuracy: 0.9101 - val_loss: 0.4938 - val_accuracy: 0.7953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixLdaS-DJiv7",
        "outputId": "bd4c1587-21c7-46ae-8ae1-906429fcee9d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7953\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4938335716724396, 0.7952755689620972]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make some predictions\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFZ35FbBJrW-",
        "outputId": "3f2fedda-4c9e-4517-865b-4aa4c26a448f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12096813],\n",
              "       [0.00963379],\n",
              "       [0.07517964],\n",
              "       [0.43156   ],\n",
              "       [0.9998043 ],\n",
              "       [0.8580827 ],\n",
              "       [0.13515034],\n",
              "       [0.894733  ],\n",
              "       [0.58565694],\n",
              "       [0.08657642]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright ! Let's some more evaluations by using our common function for evaluation."
      ],
      "metadata": {
        "id": "SrsxhgWcKgH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for the evaluation we have to make it similar to our val_labels which is in 0 and 1\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "191_2ce5K5hV",
        "outputId": "7696fd90-d398-48b2-c879-d5ea1bf71bc5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_dense_results = calculate_results(y_true=val_labels,\n",
        "                                         y_pred=model_1_preds)\n",
        "\n",
        "simple_dense_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_qe3BuhKpa8",
        "outputId": "e5b4eaa3-1e8b-4f59-e8f4-e4ff4232eb14"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.52755905511812,\n",
              " 'precision': 0.7966788703003602,\n",
              " 'recall': 0.7952755905511811,\n",
              " 'f1-score': 0.7932321923411083}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For comparing the results like these between two models, let's create a helper function"
      ],
      "metadata": {
        "id": "WBvkM6hNLKma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for k,v in baseline_results.items():\n",
        "    print(f\"Baseline {k}: {v:.2f}, New {k}: {new_model_results[k]:.2f}, Difference: {new_model_results[k] - v:.3f}\")"
      ],
      "metadata": {
        "id": "-lpajBzWLZ2b"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_baseline_to_new_results(baseline_results, simple_dense_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usjwQEZSMA9v",
        "outputId": "090ecc81-a2f9-4614-a340-358d109528a0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.18, New accuracy: 79.53, Difference: -0.656\n",
            "Baseline precision: 0.81, New precision: 0.80, Difference: -0.016\n",
            "Baseline recall: 0.80, New recall: 0.80, Difference: -0.007\n",
            "Baseline f1-score: 0.80, New f1-score: 0.79, Difference: -0.004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Learned Embeddings\n",
        "\n",
        "Our first model (`model_1`) contained an embedding layer (`embedding`) which learned a way of representing words as feature vectors by passing over the training data.\n",
        "\n",
        "To understand what a text embedding is, let's visualize the embedding our model learned."
      ],
      "metadata": {
        "id": "Hysy96wpMGLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp7kot3HIkVN",
        "outputId": "c6b1c017-62dc-4c5f-88c2-85b629c68dc1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let's get our embedding layer's weights (these are the numerical representations of each word)."
      ],
      "metadata": {
        "id": "ObaHI9rrIujy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc39TunRJDn-",
        "outputId": "baf5bd58-aeed-4cb3-de54-e26256ff9dbb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the weight matrix of embedding layer\n",
        "embed_weights = model_1.layers[2].get_weights()[0] \n",
        "print(embed_weights.shape) # same size as vocab size and embedding_dim (each word is a embedding_dim size vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cnOYapAJFQ-",
        "outputId": "ef255fc7-0a51-4cca-df00-45358071b3d7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JDpi0keJaKg",
        "outputId": "98910ffb-14d5-4679-b33c-eaff9bfc392c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.05793182, -0.03914462, -0.02473386, -0.00400929,  0.0294634 ,\n",
              "       -0.01301203,  0.05229731,  0.04887474,  0.06025089,  0.00805069,\n",
              "        0.06344496,  0.06382321,  0.03528399, -0.02437459, -0.0378452 ,\n",
              "       -0.00860966, -0.02997299, -0.00939368,  0.0595504 , -0.06665281,\n",
              "       -0.01535043,  0.01206796,  0.0132463 ,  0.00885767, -0.03989455,\n",
              "        0.00598112, -0.05867314,  0.01391945, -0.01342947, -0.03151251,\n",
              "       -0.01170613, -0.01470302,  0.05553512,  0.06478365, -0.03305589,\n",
              "        0.00180235,  0.03188964, -0.01603713,  0.0065343 , -0.0136434 ,\n",
              "       -0.01092492,  0.0395552 , -0.00912934, -0.04180073, -0.01730741,\n",
              "       -0.00267581, -0.05257862, -0.00593809, -0.00243134, -0.00406672,\n",
              "        0.05934988,  0.00771908, -0.0055135 , -0.03471246, -0.0266527 ,\n",
              "       -0.01058053,  0.01899303, -0.0502522 , -0.01186908, -0.00643936,\n",
              "       -0.0397414 , -0.02110856, -0.00443363, -0.00674049,  0.02272329,\n",
              "        0.02054001, -0.01021376, -0.03714586,  0.03495812, -0.00551941,\n",
              "       -0.0540294 ,  0.05673278, -0.02860854,  0.0593399 ,  0.04321826,\n",
              "       -0.03300178, -0.01398473,  0.00378328,  0.0565896 ,  0.06639095,\n",
              "        0.04891377, -0.03926003,  0.0213817 , -0.0553074 ,  0.03143609,\n",
              "       -0.00662654,  0.02964565, -0.05007803, -0.04113481,  0.0172483 ,\n",
              "        0.00210687,  0.01717917,  0.0234562 ,  0.04754277, -0.02072727,\n",
              "        0.02285103,  0.03893688,  0.0365902 ,  0.03092392, -0.05657146,\n",
              "       -0.00815742, -0.03492343, -0.0570826 , -0.01064817, -0.04797027,\n",
              "       -0.01948297, -0.03375852, -0.01503073, -0.02164166,  0.00636745,\n",
              "        0.03055428,  0.06135832, -0.01142473, -0.02363287,  0.0190532 ,\n",
              "       -0.01181162, -0.0348068 , -0.03662143,  0.0323029 , -0.05484904,\n",
              "       -0.01756295,  0.03628292,  0.02103201,  0.03848096,  0.05498384,\n",
              "        0.00409454,  0.02326121, -0.00015124], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got these two objects, we can use the [Embedding Projector Tool](http://projector.tensorflow.org/) to visualize our embedding.\n",
        "\n",
        "To use the embedding projector tool, we need two files,\n",
        "- the embedding vectors (same as embedding weights)\n",
        "- the metadata of the embedding vectors (the words they represent - our vocabulary)"
      ],
      "metadata": {
        "id": "v8q7clW_JvQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import io\n",
        "\n",
        "# # Create output writers\n",
        "# out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "# out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# # Write embedding vectors and words to file\n",
        "# for num, word in enumerate(words_in_vocab):\n",
        "#   if num==0:\n",
        "#     continue # skip padding token\n",
        "#   vec = embed_weights[num]\n",
        "#   out_m.write(word + \"\\n\") # write words to file\n",
        "#   out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "\n",
        "# # Download files locally to upload to Embedding projector\n",
        "\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "# except ImportError:\n",
        "#   pass\n",
        "# else:\n",
        "#   files.download(\"embedding_vectors.tsv\")\n",
        "#   files.download(\"embedding_metadata.tsv\")"
      ],
      "metadata": {
        "id": "k_6Mx76TL1rT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks(RNN's)\n",
        "\n",
        "For further experimentations we're going to use special kind of neural networks used for sequence data such as to predict the next location based on the prior location or may be to generate a new sequence based on the past sequences which is done through **Recurrent Neural Networks (RNN)**.\n",
        "\n",
        "Recurrent Neural Networks can be used for a number of sequence-based problems:\n",
        "- **One to One:** one input, one output, such as image classification\n",
        "- **One to many:** one input, many output, such as image captioning\n",
        "- **Many to one:** many inputs, one outputs, such as text classification\n",
        "- **Many to Many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text\n",
        "\n",
        "Most commong RNN cell or layers used for designing the network are:\n",
        "- LSTM (Long Short Term Memory)\n",
        "- GRU (Gates Recurrent Unit)\n",
        "- Bidirectional RNNs (passes forward and backward along a sequence, left to right and right to left)\n",
        "\n",
        "The architecture of the RNNs would be,\n",
        "\n",
        "      Input(text) -> Tokenize -> Embedding -> Layers -> Output (label probability)"
      ],
      "metadata": {
        "id": "DteZn62KNfRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 : LSTM\n",
        "\n",
        "> **Note**: For a best practice when we are comparing different models then embedding layer should be different because embedding layer is a learned representation of words, if we were to use the same embedding layer for each model, we'd be mixing what one model has learned with the next. "
      ],
      "metadata": {
        "id": "uEYEHgyjmVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed and creating embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(17)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                           output_dim=128,\n",
        "                                           embeddings_initializer=\"uniform\",\n",
        "                                           input_length=max_length,\n",
        "                                           name=\"embedding_2\")\n",
        "\n",
        "# Create LSTM model\n",
        "input = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(input)\n",
        "x = model_2_embedding(x)\n",
        "#print(x.shape)\n",
        "#x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (if we want to stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_2 = tf.keras.Model(input, output, name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "id": "0SjUQmhdmdth"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the Tensorflow documentation on LSTM, it accepts 3D input tensor as [batch, timestamp, feature_vector] so when we stack one more cell of LSTM, then we must set `return_sequences=True` so that when next LSTM cell is stacked will be inject with 3D input or else it would through error of \"expecting 3D tensor but received 2D\""
      ],
      "metadata": {
        "id": "hPDrDQwSqlso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Function for Compiling and Fitting the Model"
      ],
      "metadata": {
        "id": "XWRxF6ChsAew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for compiling and fitting the model let's create a helper function\n",
        "\n",
        "def compile_fit_RNNs(model, dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Function used for compiling and fitting the model and save the \n",
        "  tensorboard experiment as well on the passed directory\n",
        "\n",
        "  Returns the model history\n",
        "  \"\"\"\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # fit the model\n",
        "  history = model.fit(train_sentences,\n",
        "                      train_labels,\n",
        "                      epochs=5,\n",
        "                      validation_data=(val_sentences, val_labels),\n",
        "                      callbacks=[create_tensorboard_callback(dir_name, experiment_name)])\n",
        "  \n",
        "  return history"
      ],
      "metadata": {
        "id": "t2esO0x8qZfU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_history = compile_fit_RNNs(model=model_2, dir_name=SAVE_DIR, experiment_name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw7zOCCtr90b",
        "outputId": "4aeeaf72-800a-4d67-a976-6420d591e47c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/model_2_LSTM/20230203-051605\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 8ms/step - loss: 0.5133 - accuracy: 0.7434 - val_loss: 0.4492 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.3184 - accuracy: 0.8695 - val_loss: 0.4724 - val_accuracy: 0.7966\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.2199 - accuracy: 0.9204 - val_loss: 0.5474 - val_accuracy: 0.7874\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.1537 - accuracy: 0.9456 - val_loss: 0.6827 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.1108 - accuracy: 0.9603 - val_loss: 0.8267 - val_accuracy: 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we check the summary of the LSTM Model"
      ],
      "metadata": {
        "id": "ENi7wJatsq18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMvUY6bgsuW3",
        "outputId": "73d17680-6ceb-4e4c-f603-8080c259a8e5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  multiple                 0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make some predictions\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsvQ90rasR-m",
        "outputId": "c38d4cd3-142f-4ab9-edaf-818d2e81c338"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0211548 ],\n",
              "       [0.00182996],\n",
              "       [0.01620475],\n",
              "       [0.16472116],\n",
              "       [0.9998977 ],\n",
              "       [0.99410546],\n",
              "       [0.01473757],\n",
              "       [0.7996622 ],\n",
              "       [0.8936984 ],\n",
              "       [0.54785377]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert them to compare with labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idYU2tb9sbcV",
        "outputId": "50071a1f-517c-4d86-9536-da359b597ee9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's calculate the results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC0KzqZpsnJ6",
        "outputId": "d352874a-18d3-4b4b-c0df-e740300a93fc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'precision': 0.7659025055163764,\n",
              " 'recall': 0.7664041994750657,\n",
              " 'f1-score': 0.7660201893659146}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare the baseline results with model_2\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0QZl372tc4T",
        "outputId": "29dce6ee-781f-48ab-db05-4fabca063e1e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.18, New accuracy: 76.64, Difference: -3.543\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.047\n",
            "Baseline recall: 0.80, New recall: 0.77, Difference: -0.035\n",
            "Baseline f1-score: 0.80, New f1-score: 0.77, Difference: -0.031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3 : GRU\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters."
      ],
      "metadata": {
        "id": "Qx7XI2aKt-10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the random seed and create new embedding layer\n",
        "tf.random.set_seed(17)\n",
        "\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build GRU model\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name='model_3_GRU')\n"
      ],
      "metadata": {
        "id": "4tnDsQXHuIgS"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see the summary\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NyQL49vvR7y",
        "outputId": "70de2bf9-61bc-43f7-e072-7c7e1751a0bd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  multiple                 0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's the same as LSTM model but with less params"
      ],
      "metadata": {
        "id": "DfdhvEYwveuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile and fit the model\n",
        "model_3_history = compile_fit_RNNs(model_3, SAVE_DIR, \"model_3_GRU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5dlJVK3vlXw",
        "outputId": "c42f06c8-8a58-4f6f-95ea-baf791485ab5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/model_3_GRU/20230203-052809\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 10ms/step - loss: 0.5328 - accuracy: 0.7219 - val_loss: 0.4518 - val_accuracy: 0.8045\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3221 - accuracy: 0.8641 - val_loss: 0.4690 - val_accuracy: 0.8018\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.2178 - accuracy: 0.9181 - val_loss: 0.5357 - val_accuracy: 0.7848\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1489 - accuracy: 0.9499 - val_loss: 0.6772 - val_accuracy: 0.7703\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1122 - accuracy: 0.9625 - val_loss: 0.6983 - val_accuracy: 0.7559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "# convert them into labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs)) \n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax7jpoHjvwRR",
        "outputId": "e8187bdc-bb76-4934-d392-832c81142b7a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the result\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                   y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9FOAOdQwE2b",
        "outputId": "2728fad2-7be9-4a5c-f45a-188bb34e81e9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.59055118110236,\n",
              " 'precision': 0.7551876442680979,\n",
              " 'recall': 0.7559055118110236,\n",
              " 'f1-score': 0.7551196015270819}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare with baseline score\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuuFbg8-wOo1",
        "outputId": "066afd3a-6199-48c6-aa2a-2892ae9b670a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.18, New accuracy: 75.59, Difference: -4.593\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.057\n",
            "Baseline recall: 0.80, New recall: 0.76, Difference: -0.046\n",
            "Baseline f1-score: 0.80, New f1-score: 0.76, Difference: -0.042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's looks like Baseline is still outperforming dense models, let's see one more model"
      ],
      "metadata": {
        "id": "_yuiOQbYwXjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4 : Bidirectional RNNs\n",
        "\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left."
      ],
      "metadata": {
        "id": "_VJlzkRkwhIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(17)\n",
        "model_4_embedding = layers.Embedding(input_dim = max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build the Bidirectional Model\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name='model_4_Bidirectional')"
      ],
      "metadata": {
        "id": "uqprPWR_wlLZ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the summary\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wHIKZp3xitb",
        "outputId": "01888a4d-3a3b-477a-c65a-eae9e047e686"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  multiple                 0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the parameters of the Bidirectional layer get doubled."
      ],
      "metadata": {
        "id": "hEAbh_vcxnqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile and fit\n",
        "model_4_history = compile_fit_RNNs(model_4, SAVE_DIR, \"model_4_Bidirectional\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxIMSyXOxtKd",
        "outputId": "bbd847cb-79ca-4e07-e663-b8fa34b3fc27"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/model_4_Bidirectional/20230203-053715\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 17ms/step - loss: 0.5140 - accuracy: 0.7427 - val_loss: 0.4542 - val_accuracy: 0.8018\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3149 - accuracy: 0.8691 - val_loss: 0.4835 - val_accuracy: 0.7900\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.2171 - accuracy: 0.9202 - val_loss: 0.5680 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.1469 - accuracy: 0.9520 - val_loss: 0.6563 - val_accuracy: 0.7612\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.1036 - accuracy: 0.9641 - val_loss: 0.7833 - val_accuracy: 0.7598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "model_4_pred_probs = model_4.predict(val_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js6QrUtEx1t8",
        "outputId": "d00966c6-eddb-4bc2-faaa-93bec20dd3f9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert them into labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uo1RB9Lx5yk",
        "outputId": "abf35b14-822f-4f85-8ccf-b55abe766056"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the result\n",
        "model_4_results = calculate_results(y_true = val_labels,\n",
        "                                    y_pred = model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXe4FqILyEfc",
        "outputId": "213b3e14-d103-4b1d-b879-61b42ae9abae"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'precision': 0.7600694650010854,\n",
              " 'recall': 0.7598425196850394,\n",
              " 'f1-score': 0.7599441744417845}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare with baseline scores\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UJ2lQftyQvP",
        "outputId": "647a8c2b-6a48-4ae3-8b94-22107f93290f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.18, New accuracy: 75.98, Difference: -4.199\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.052\n",
            "Baseline recall: 0.80, New recall: 0.76, Difference: -0.042\n",
            "Baseline f1-score: 0.80, New f1-score: 0.76, Difference: -0.037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l5To8KdlyZQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}