{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMB/Cu8ORhq93i6P9VOKWsO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/introduction-to-nlp/blob/master/nlp_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing with TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ],
      "metadata": {
        "id": "Ep05V4vWV7mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we're going to experiment deep-learning models so we need to enable GPUs\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubzX8Z9hWWcu",
        "outputId": "8d681c09-6d4b-4312-e3fb-2f219cdd7d2e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-0c0b432e-a08e-be39-c90b-2ff3f528f4e6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Helper functions"
      ],
      "metadata": {
        "id": "Tyusp2doWbLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper_functions.py script from Github\n",
        "!wget https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
        "\n",
        "from helper_functions import unzip_data, create_tensorboard_callback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlTigivCWskW",
        "outputId": "894e8688-8c05-477b-a778-7163b6a35119"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-30 05:04:16--  https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2904 (2.8K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]   2.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-30 05:04:16 (45.4 MB/s) - ‘helper_functions.py’ saved [2904/2904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a Text Dataset\n",
        "The dataset that we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster or not disaster)\n",
        "\n",
        "See the original source here: https://www.kaggle.com/c/nlp-getting-started"
      ],
      "metadata": {
        "id": "CZ_5BTF-W7K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# unzip the data\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F88ynPezXO3A",
        "outputId": "59c5bd90-c224-46ae-9198-973c56a7040a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-30 05:04:21--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.128, 74.125.24.128, 142.250.4.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-01-30 05:04:22 (28.9 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Text Dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, so we can do it through pandas."
      ],
      "metadata": {
        "id": "WyMBzit1XakQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# check the shapes\n",
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwqhQM8yXl7f",
        "outputId": "3e4843f0-2af6-4063-9500-00dbb87ccef1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7613, 5), (3263, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view some samples\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HnvCJoJRXvcI",
        "outputId": "e10a4878-0672-40ce-8778-5f3a29b67f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ffee9e3-9f02-4b7e-9743-0046b36583de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ffee9e3-9f02-4b7e-9743-0046b36583de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ffee9e3-9f02-4b7e-9743-0046b36583de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ffee9e3-9f02-4b7e-9743-0046b36583de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here, `text` is the tweet and `target` variable is to identify whether the tweet is a disaster or not, so if `1` then it's a disaster else not a disaster.\n",
        "\n",
        "Let's visualize some random `training` samples, but before that this is a good practice to shuffle the training samples first,"
      ],
      "metadata": {
        "id": "A1v_p_ElXytS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled = train_df.sample(frac=1, random_state=17)\n",
        "# frac=1 means 100% of samples will be shuffled\n",
        "train_df_shuffled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "p17uRynCYEDW",
        "outputId": "f84d7701-8970-4f4e-8b1f-d98df838da9d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id            keyword                    location  \\\n",
              "7027  10072            typhoon                         NaN   \n",
              "318     463         armageddon                         NaN   \n",
              "1681   2425            collide  www.youtube.com?Malkavius2   \n",
              "5131   7318  nuclear%20reactor          New York, New York   \n",
              "2967   4262           drowning          Hendersonville, NC   \n",
              "...     ...                ...                         ...   \n",
              "406     584              arson           Jerusalem, Israel   \n",
              "5510   7863        quarantined                 Livonia, MI   \n",
              "2191   3139             debris                         NaN   \n",
              "7409  10600            wounded               santo domingo   \n",
              "2671   3833           detonate    back in japan ??????????   \n",
              "\n",
              "                                                   text  target  \n",
              "7027  Typhoon Soudelor: When will it hit Taiwan ÛÒ ...       1  \n",
              "318   RT @RTRRTcoach: #Love #TrueLove #romance lith ...       0  \n",
              "1681  I liked a @YouTube video from @gassymexican ht...       0  \n",
              "5131  Japan's Restart of Nuclear Reactor Fleet Fast ...       1  \n",
              "2967  #ICYMI #Annoucement from Al Jackson... http://...       0  \n",
              "...                                                 ...     ...  \n",
              "406   Mourning notices for stabbing arson victims st...       1  \n",
              "5510  Reddit's new content policy goes into effect m...       0  \n",
              "2191  Plane debris discovered on Reunion Island belo...       1  \n",
              "7409  Police Officer Wounded Suspect Dead After Exch...       1  \n",
              "2671  Detonate (feat. M?.?O?.?P?.?)\\nfrom Grandeur b...       0  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15150619-9be0-4fc7-8158-8e9f34abbe47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7027</th>\n",
              "      <td>10072</td>\n",
              "      <td>typhoon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor: When will it hit Taiwan ÛÒ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>463</td>\n",
              "      <td>armageddon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @RTRRTcoach: #Love #TrueLove #romance lith ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>2425</td>\n",
              "      <td>collide</td>\n",
              "      <td>www.youtube.com?Malkavius2</td>\n",
              "      <td>I liked a @YouTube video from @gassymexican ht...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5131</th>\n",
              "      <td>7318</td>\n",
              "      <td>nuclear%20reactor</td>\n",
              "      <td>New York, New York</td>\n",
              "      <td>Japan's Restart of Nuclear Reactor Fleet Fast ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2967</th>\n",
              "      <td>4262</td>\n",
              "      <td>drowning</td>\n",
              "      <td>Hendersonville, NC</td>\n",
              "      <td>#ICYMI #Annoucement from Al Jackson... http://...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>584</td>\n",
              "      <td>arson</td>\n",
              "      <td>Jerusalem, Israel</td>\n",
              "      <td>Mourning notices for stabbing arson victims st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5510</th>\n",
              "      <td>7863</td>\n",
              "      <td>quarantined</td>\n",
              "      <td>Livonia, MI</td>\n",
              "      <td>Reddit's new content policy goes into effect m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2191</th>\n",
              "      <td>3139</td>\n",
              "      <td>debris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Plane debris discovered on Reunion Island belo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7409</th>\n",
              "      <td>10600</td>\n",
              "      <td>wounded</td>\n",
              "      <td>santo domingo</td>\n",
              "      <td>Police Officer Wounded Suspect Dead After Exch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2671</th>\n",
              "      <td>3833</td>\n",
              "      <td>detonate</td>\n",
              "      <td>back in japan ??????????</td>\n",
              "      <td>Detonate (feat. M?.?O?.?P?.?)\\nfrom Grandeur b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15150619-9be0-4fc7-8158-8e9f34abbe47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15150619-9be0-4fc7-8158-8e9f34abbe47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15150619-9be0-4fc7-8158-8e9f34abbe47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how does the test set looks like ?\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P0I_-hG1YYwu",
        "outputId": "8a43f561-6267-4cff-a382-e3b145bf69ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb93fefb-952a-426b-964c-687896766adf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb93fefb-952a-426b-964c-687896766adf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb93fefb-952a-426b-964c-687896766adf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb93fefb-952a-426b-964c-687896766adf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class ?\n",
        "train_df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9FJ8OerYhVh",
        "outputId": "571bec0b-7513-4243-e808-6425d37d75bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random samples\n",
        "\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df_shuffled)-5)\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(disaster)\" if target > 0 else \"(not a disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgQTdLVzYtcu",
        "outputId": "0b10fd8c-403a-498e-c73a-4fcc7889b28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 (disaster)\n",
            "Text:\n",
            "@mylittlepwnies3 @Early__May @AnathemaZhiv @TonySandos much of which has to do with lebanon 80s attack/ iran hostage crisis/ Libya Pan am\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 0 (not a disaster)\n",
            "Text:\n",
            "Oil prices falling but drivers could reap benefits http://t.co/QlTwhoJqYA\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 1 (disaster)\n",
            "Text:\n",
            "Gunmen open fire on bus near El Salvador's capital killing 4 a week after gang attacks killed 8 bus drivers: http://t.co/Pz56zJSsfT bitÛ_\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 0 (not a disaster)\n",
            "Text:\n",
            "hermancranston: #atk #LetsFootball RT SkanndTyagi: #letsFootball #atk WIRED : All these fires are burning through Û_ http://t.co/DmTab6g7j7\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 1 (disaster)\n",
            "Text:\n",
            "Police Officer Wounded Suspect Dead After Exchanging Shots http://t.co/brE2lGmn7C #ABC #News #AN247\n",
            "\n",
            "----------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset into Train and Validation sets\n",
        "\n",
        "Since the test set doesn't contain the target variable so we might need some unseen data for model to be validated after training, so how about splitting our training set for validating purpose with some amount.\n"
      ],
      "metadata": {
        "id": "WmmI2TzZZa1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=17)"
      ],
      "metadata": {
        "id": "jEgDccMKTYSx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting Text into Numbers\n",
        "\n",
        "Our labels are in numerical form (0 and 1) but our tweets are in string form.\n",
        "\n",
        "But machine learning algorithm learns only through numbers so we have to convert those tweets/texts into numbers.\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers,\n",
        "- **Tokenization** : A straight mapping from **word**(known as *word-level tokenization*) or character(which is *character-level tokenization*) or sub-word(*sub-word tokenization*) to a numerical value. Just like One hot encoding, suppose we have a sentence as \"My name is Alpha\", then if we are mapping according to word, \"My\" would `0`, \"name\" as `1`, \"is\" as `2` and \"Alpha\" as `3`.\n",
        "- **Embeddings** : An embedding is a representation of natural language which can be learned. Representation comes in the form of **feature-vector**. For example the word \"Alpha\" could be represented by 5-D vector `[0.564, 0.897, 0.456, -0.987, 0.15]`. The size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "\n",
        "    - **Create your own embedding** - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as `tf.keras.layers.Embedding`) and an embedding representation will be learned during model training.\n",
        "    - **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task.\n",
        "\n",
        "\n",
        "Simply, \n",
        "\n",
        "**Tokenization** : Straight mapping from word to number.\n",
        "\n",
        "**Embedding** : Richer representation of relationships between tokens.\n",
        "\n",
        "It depends on your problem. You could try character-level tokenization/embeddings and word-level tokenization/embeddings and see which perform best. You might even want to try stacking them (e.g. combining the outputs of your embedding layers using [tf.keras.layers.concatenate](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate)).\n",
        "\n",
        "If you're looking for pre-trained word embeddings, [Word2vec embeddings](https://jalammar.github.io/illustrated-word2vec/), [GloVe embeddings](https://nlp.stanford.edu/projects/glove/) and many of the options available on TensorFlow Hub are great places to start.\n",
        "\n",
        "Much like searching for a pre-trained computer vision model, we can search for pre-trained word embedding to use for your problem. Try searching for something like \"use pre-trained word embeddings in TensorFlow\"."
      ],
      "metadata": {
        "id": "MitNUg-uTxx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization\n",
        "\n",
        "Mapping words to numbers.\n",
        "\n",
        "To tokenize our words, we'll use the preprocessing layer,\n",
        "`tf.keras.layers.preprocessing.TextVectorization`"
      ],
      "metadata": {
        "id": "oyTzuPa0V5bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Using the default TextVectorization variables\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                 standardize=\"lower_and_strip_punctuation\", # how to process the text\n",
        "                                 split=\"whitespace\", # how to split the text\n",
        "                                 ngrams=None, # create groups of n-words\n",
        "                                 output_mode='int', # how to map tokens to numbers\n",
        "                                 output_sequence_length=None) # How long should the output sequence of tokens be?"
      ],
      "metadata": {
        "id": "k6z0y1iEIEs5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "About the above params,\n",
        "\n",
        "- `max_tokens` : The maximum number of words in your vocabulary (e.g 20000 or the number of unique words in your text), includes a value for OOV(out of vocabulary) tokens\n",
        "- `standardize` : Methods for standardizing text\n",
        "- `split`: split the text\n",
        "- `ngrams`: how many words to contain per token split, for example if 2, it splits tokens into continous sequences of 2\n",
        "- `output_mode`: How to output tokens can be `int`(integer mapping), `binary`(OHE), `count` or `tf-idf`\n",
        "- `output_sequence_length`: Length of tokenized sequence to output, For example if set to 150, all tokenized sequences will be 150 tokens long.\n",
        "\n",
        "In the above cell, we have initialized the object with the default settings but let's customize it a little bit for our own use case.\n",
        "\n",
        "In particular, let's set values for `max_tokens` and `output_sequence_length`.\n",
        "\n",
        "For `max_tokens`(the number of words in the vocabulary), multiples of 10,000(`10,000`, `20,000`, `30,000`) or the exact number of unqiue words in your text(e.g `32,179`) are common values.\n",
        "\n",
        "For our use case, `10,000`\n",
        "\n",
        "And for the `output_sequence_length` we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."
      ],
      "metadata": {
        "id": "CgAnhcS2KVIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "id": "c4ysmlUhLX6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56eef761-9d8b-4ee1-a89a-2b6dd5cf831a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000\n",
        "max_length = 15\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "KA553WXeaU4a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To map our `TextVectorization` instance `text_vectorizer` to our data, we can call the `adapt()` method on it whilst passing it our training set."
      ],
      "metadata": {
        "id": "KJZbqKiobF3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "OOfO1BecbdMe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data mapped! Let's try our `text_vectorizer` on a custom sentence."
      ],
      "metadata": {
        "id": "h0hxXVglbj3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a sample sentence\n",
        "sample_sentence = \"There's a flood in my village!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGCO1vkUb3eW",
        "outputId": "d7eade58-8633-4e0f-da06-f732c3311b53"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[281,   3, 214,   4,  13, 881,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try our `text_vectorizer` on a few random sentences ?"
      ],
      "metadata": {
        "id": "LC1QnE2WcBfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original Text: \\n{random_sentence}\\\n",
        "        \\n\\n Vectorized Text:')\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYj-_VcNcP7u",
        "outputId": "141608e3-49be-42dd-9606-6b7d083d397c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: \n",
            "11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...        \n",
            "\n",
            " Vectorized Text:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[823, 347, 389,  14, 727,   6, 828, 407,  41, 823, 347,  40,  64,\n",
              "        389,  14]])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check the unique tokens in our vocabulary using the `get_vocabulary()` method"
      ],
      "metadata": {
        "id": "ZrtMKcpgcfcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "\n",
        "print(f\"Number of words in Vocab:{len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words:{top_5_words}\")\n",
        "print(f\"Bottom 5 least common words:{bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJLbch5kcuc5",
        "outputId": "da7c07b2-cf84-45fd-f31e-42828e85e277"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in Vocab:10000\n",
            "Top 5 most common words:['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words:['ovo', 'overåÊhostages', 'overzero', 'overwatch', 'overturns']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding\n",
        "\n",
        "**Create an Embedding using Embedding Layer**\n",
        "\n",
        "We've got a way to map our text to numbers. How about we go a step further and turn those numbers into an embedding?\n",
        "\n",
        "The powerful thing about an embedding is it can be learned during training. This means rather that just be static, a word's numeric representation can be improved as a model goes through data samples.\n",
        "\n",
        "We can see what an embedding of a word looks like by using the `tf.keras.layers.Embedding` layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "rnhKQAUFdRqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(17)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length,\n",
        "                             name=\"embedding_1\")\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4AxkJ4teKHO",
        "outputId": "3cfe1a75-e0b0-4559-8d4a-3f99e015c16d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f17d006a190>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`embedding` is a TensorFlow Layer, so that we can use it as part of a model, meaning its parameters(word representations) can be updated and improved as the model learns.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wd2p3RPvevde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text: \\n{random_sentence}\")\n",
        "print(\"\\n\\nEmbedded version:\")\n",
        "\n",
        "# embed the random sentence\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GseLqO74tWkN",
        "outputId": "db9c6ec7-4aed-4371-f961-8bd12be7285a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: \n",
            "Now that's what you call a batting collapse #theashes\n",
            "\n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.01314962,  0.00719387,  0.02004207, ..., -0.04191788,\n",
              "          0.0154699 , -0.01650833],\n",
              "        [-0.00079762,  0.04007155,  0.01404953, ...,  0.02520284,\n",
              "          0.0242764 ,  0.03214594],\n",
              "        [ 0.01604157, -0.00236765,  0.01929165, ...,  0.03563354,\n",
              "          0.04398265, -0.03589463],\n",
              "        ...,\n",
              "        [-0.04305307, -0.04987746, -0.0366137 , ...,  0.01739735,\n",
              "          0.00826229,  0.04193049],\n",
              "        [-0.04305307, -0.04987746, -0.0366137 , ...,  0.01739735,\n",
              "          0.00826229,  0.04193049],\n",
              "        [-0.04305307, -0.04987746, -0.0366137 , ...,  0.01739735,\n",
              "          0.00826229,  0.04193049]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These values might not mean much to us but they're what our computer sees each word as. When our model looks for patterns in different samples, these values will be updated as necessary.\n",
        "\n",
        "If we review the shape of Embedded Version Tensor it is, `(1, 15, 128)`, it means that,\n",
        "- 1: Is the quantity of sequences(sentences) we passed\n",
        "- 15: is the `max_length` that we decided to normalize every sentence, if greater than 15 tokens/words then trim extra tokens or if less than 15 then pad it.\n",
        "- 128: is the array size of each words, for example above sentence as `Now`, for this token the embedding tensor will look like,"
      ],
      "metadata": {
        "id": "9Kp2cu1Dt4sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_embed[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW7O7e1UDyKn",
        "outputId": "2691f13a-9b92-4185-e67d-7c4abfd128cd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([-0.01314962,  0.00719387,  0.02004207, -0.03999835,  0.04695079,\n",
              "        0.01789708,  0.03059348,  0.02138252, -0.03624801,  0.00396798,\n",
              "       -0.03985019, -0.04329523,  0.01500774, -0.03659517,  0.03917797,\n",
              "       -0.04362958,  0.0154495 ,  0.0078933 , -0.01369306,  0.03302287,\n",
              "       -0.00288031, -0.04553231,  0.04097218, -0.01234646, -0.04826026,\n",
              "        0.02076019,  0.00254625, -0.00031816, -0.00150321, -0.00461284,\n",
              "       -0.04060421, -0.03143873,  0.0298737 ,  0.03604234, -0.0433757 ,\n",
              "       -0.01436574, -0.03462224,  0.0473052 , -0.04071296,  0.03264949,\n",
              "       -0.03514206,  0.00570067, -0.03294205,  0.00819801,  0.02374965,\n",
              "       -0.04027864,  0.04482595,  0.0060604 ,  0.03028399,  0.01870103,\n",
              "       -0.03406491,  0.03605679,  0.02144077,  0.03187365, -0.04643034,\n",
              "       -0.00920881,  0.04652185,  0.0316061 ,  0.04617418, -0.04849065,\n",
              "       -0.02418332,  0.01280299,  0.00942918,  0.00199284, -0.03562398,\n",
              "        0.0202616 , -0.03023897, -0.03024035,  0.03830625, -0.02724752,\n",
              "        0.01169823, -0.03027662, -0.03144013, -0.01476924,  0.0054714 ,\n",
              "       -0.00227799, -0.03429018,  0.03089159, -0.04679587, -0.03925322,\n",
              "       -0.04195093,  0.02749677, -0.01540104, -0.03303864, -0.02079431,\n",
              "        0.0452054 ,  0.03570647, -0.0496689 ,  0.00328605, -0.02085104,\n",
              "       -0.03158893,  0.03362397, -0.04470401, -0.0202415 ,  0.02235827,\n",
              "        0.03492473,  0.02712698, -0.0105809 ,  0.02270503, -0.02044622,\n",
              "        0.02441342,  0.04778511,  0.04707602,  0.0332685 , -0.02426286,\n",
              "       -0.03629088,  0.01421403, -0.00120753,  0.03174975, -0.03455583,\n",
              "        0.01227055,  0.02713798, -0.03267062,  0.03142576, -0.00820298,\n",
              "        0.01606223,  0.02331909,  0.02819754, -0.02447753, -0.00393425,\n",
              "       -0.02849346, -0.01348752, -0.03910694, -0.00147695, -0.01105843,\n",
              "       -0.04191788,  0.0154699 , -0.01650833], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a Text Dataset\n",
        "\n",
        "For experiments with various machine learning model for text classifier we will be considering below experiments:\n",
        "- **Model 0** : Naive Bayes (baseline)\n",
        "- **Model 1** : Feed-forward neural network (dense model) \n",
        "- **Model 2** : LSTM Model (RNN)\n",
        "- **Model 3** : GRU (RNN)\n",
        "- **Model 4** : Bidirectional-LSTM (RNN)\n",
        "- **Model 5** : 1D CNN\n",
        "- **Model 6** : TF Hub Pre-trained Feature Extractor\n",
        "- **Model 7** : Same as model 6 with 10% of training samples"
      ],
      "metadata": {
        "id": "LUy8YjJ2EWQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0 : Getting a baseline\n",
        "\n",
        "We'll use `scikit-learn` library for building this model, and create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert words into numbers and then model them using Multinomial Naive Bayes Algorithm.\n",
        "\n",
        "> 📖 **Reading**: About TF-IDF on [Scikit-learn documentation](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)"
      ],
      "metadata": {
        "id": "72x7n-xuFM8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IkZ6K-UF1j2",
        "outputId": "6f522344-9734-40d7-fd77-2517d7169117"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multinomial Naive Bayes model is kind of shallow model which trains faster."
      ],
      "metadata": {
        "id": "gLex6UKjGaDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zihkmgPZGkfC",
        "outputId": "c24b6541-f32d-45ff-b279-cb41796c5eb8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 80.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make some predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZtZ-lodG0ii",
        "outputId": "34fc9368-8639-453b-935d-946fa6b7e363"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it is similar to our labels\n",
        "val_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uWMFYvAG-qx",
        "outputId": "7589b085-4821-402c-c8b6-f1886ff9c14f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation function for our Model Experiments\n",
        "\n",
        "There are various metrics to evaluate the classification models like `precision`, `f1-score`, `recall`. So let's look at them through a function altogether."
      ],
      "metadata": {
        "id": "s149DQ4RHC7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(model, y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates Model accuracy, precision, recall and f1-score for a binary classification model\n",
        "  \"\"\"\n",
        "  # calculate the model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred)\n",
        "  # calculate precision, recall, f1-score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy * 100,\n",
        "                   \"precision\":model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1-score\": model_f1}\n",
        "                  \n",
        "  return model_results\n"
      ],
      "metadata": {
        "id": "o-3UV6wSHK3q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the results\n",
        "baseline_results = calculate_results(model=model_0,\n",
        "                                     y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbG9m6vqJhGL",
        "outputId": "626e4959-c1c9-4918-aede-dfd82c1aebfb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.18372703412074,\n",
              " 'precision': 0.8125567744156732,\n",
              " 'recall': 0.8018372703412073,\n",
              " 'f1-score': 0.7968681002825004}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qZJjPR31JqYI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}