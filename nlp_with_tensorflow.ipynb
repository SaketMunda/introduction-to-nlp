{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1_AWB-aUT2bx-YC6eDh3y4EvY1Wyvs-jd",
      "authorship_tag": "ABX9TyNkXah5+dxpkbtOe+2ZYWi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/introduction-to-nlp/blob/master/nlp_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing with TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ],
      "metadata": {
        "id": "Ep05V4vWV7mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we're going to experiment deep-learning models so we need to enable GPUs\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubzX8Z9hWWcu",
        "outputId": "f4e9a882-c9db-4cd9-e121-dda5e7a944e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-1368deaa-b604-8a20-c46f-23e67b7a8fc2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Helper functions"
      ],
      "metadata": {
        "id": "Tyusp2doWbLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper_functions.py script from Github\n",
        "!wget https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
        "\n",
        "from helper_functions import unzip_data, create_tensorboard_callback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlTigivCWskW",
        "outputId": "40582505-45a5-4287-9d36-51b43ca42753"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-08 02:40:42--  https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2904 (2.8K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]   2.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-08 02:40:42 (43.2 MB/s) - ‘helper_functions.py’ saved [2904/2904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a Text Dataset\n",
        "The dataset that we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster or not disaster)\n",
        "\n",
        "See the original source here: https://www.kaggle.com/c/nlp-getting-started"
      ],
      "metadata": {
        "id": "CZ_5BTF-W7K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# unzip the data\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F88ynPezXO3A",
        "outputId": "379d2963-eb21-4fa0-8740-b0a01e6cca4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-08 02:40:48--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.200.128, 74.125.68.128, 74.125.24.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.200.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-02-08 02:40:48 (117 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Text Dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, so we can do it through pandas."
      ],
      "metadata": {
        "id": "WyMBzit1XakQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# check the shapes\n",
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwqhQM8yXl7f",
        "outputId": "d6fef98e-b445-4210-b32f-7b68a346f8c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7613, 5), (3263, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view some samples\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HnvCJoJRXvcI",
        "outputId": "c080cb6f-115d-4345-9583-795ca3b62ad9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8fca626c-67c8-4a7d-b796-c62dcabe3279\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fca626c-67c8-4a7d-b796-c62dcabe3279')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8fca626c-67c8-4a7d-b796-c62dcabe3279 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8fca626c-67c8-4a7d-b796-c62dcabe3279');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here, `text` is the tweet and `target` variable is to identify whether the tweet is a disaster or not, so if `1` then it's a disaster else not a disaster.\n",
        "\n",
        "Let's visualize some random `training` samples, but before that this is a good practice to shuffle the training samples first,"
      ],
      "metadata": {
        "id": "A1v_p_ElXytS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled = train_df.sample(frac=1, random_state=17)\n",
        "# frac=1 means 100% of samples will be shuffled\n",
        "train_df_shuffled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "p17uRynCYEDW",
        "outputId": "f1e15bfd-fa95-4d97-885e-28e901afb672"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id            keyword                    location  \\\n",
              "7027  10072            typhoon                         NaN   \n",
              "318     463         armageddon                         NaN   \n",
              "1681   2425            collide  www.youtube.com?Malkavius2   \n",
              "5131   7318  nuclear%20reactor          New York, New York   \n",
              "2967   4262           drowning          Hendersonville, NC   \n",
              "...     ...                ...                         ...   \n",
              "406     584              arson           Jerusalem, Israel   \n",
              "5510   7863        quarantined                 Livonia, MI   \n",
              "2191   3139             debris                         NaN   \n",
              "7409  10600            wounded               santo domingo   \n",
              "2671   3833           detonate    back in japan ??????????   \n",
              "\n",
              "                                                   text  target  \n",
              "7027  Typhoon Soudelor: When will it hit Taiwan ÛÒ ...       1  \n",
              "318   RT @RTRRTcoach: #Love #TrueLove #romance lith ...       0  \n",
              "1681  I liked a @YouTube video from @gassymexican ht...       0  \n",
              "5131  Japan's Restart of Nuclear Reactor Fleet Fast ...       1  \n",
              "2967  #ICYMI #Annoucement from Al Jackson... http://...       0  \n",
              "...                                                 ...     ...  \n",
              "406   Mourning notices for stabbing arson victims st...       1  \n",
              "5510  Reddit's new content policy goes into effect m...       0  \n",
              "2191  Plane debris discovered on Reunion Island belo...       1  \n",
              "7409  Police Officer Wounded Suspect Dead After Exch...       1  \n",
              "2671  Detonate (feat. M?.?O?.?P?.?)\\nfrom Grandeur b...       0  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72374bc6-21ff-4a3a-9c46-92e1f2027d0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7027</th>\n",
              "      <td>10072</td>\n",
              "      <td>typhoon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor: When will it hit Taiwan ÛÒ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>463</td>\n",
              "      <td>armageddon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @RTRRTcoach: #Love #TrueLove #romance lith ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>2425</td>\n",
              "      <td>collide</td>\n",
              "      <td>www.youtube.com?Malkavius2</td>\n",
              "      <td>I liked a @YouTube video from @gassymexican ht...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5131</th>\n",
              "      <td>7318</td>\n",
              "      <td>nuclear%20reactor</td>\n",
              "      <td>New York, New York</td>\n",
              "      <td>Japan's Restart of Nuclear Reactor Fleet Fast ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2967</th>\n",
              "      <td>4262</td>\n",
              "      <td>drowning</td>\n",
              "      <td>Hendersonville, NC</td>\n",
              "      <td>#ICYMI #Annoucement from Al Jackson... http://...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>584</td>\n",
              "      <td>arson</td>\n",
              "      <td>Jerusalem, Israel</td>\n",
              "      <td>Mourning notices for stabbing arson victims st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5510</th>\n",
              "      <td>7863</td>\n",
              "      <td>quarantined</td>\n",
              "      <td>Livonia, MI</td>\n",
              "      <td>Reddit's new content policy goes into effect m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2191</th>\n",
              "      <td>3139</td>\n",
              "      <td>debris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Plane debris discovered on Reunion Island belo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7409</th>\n",
              "      <td>10600</td>\n",
              "      <td>wounded</td>\n",
              "      <td>santo domingo</td>\n",
              "      <td>Police Officer Wounded Suspect Dead After Exch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2671</th>\n",
              "      <td>3833</td>\n",
              "      <td>detonate</td>\n",
              "      <td>back in japan ??????????</td>\n",
              "      <td>Detonate (feat. M?.?O?.?P?.?)\\nfrom Grandeur b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72374bc6-21ff-4a3a-9c46-92e1f2027d0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72374bc6-21ff-4a3a-9c46-92e1f2027d0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72374bc6-21ff-4a3a-9c46-92e1f2027d0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how does the test set looks like ?\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P0I_-hG1YYwu",
        "outputId": "79d6e81b-7f7d-4b24-8a50-d2ba50cce0e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a90c58f4-3a97-453c-a92e-708760a4611a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a90c58f4-3a97-453c-a92e-708760a4611a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a90c58f4-3a97-453c-a92e-708760a4611a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a90c58f4-3a97-453c-a92e-708760a4611a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class ?\n",
        "train_df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9FJ8OerYhVh",
        "outputId": "74f648d3-f70b-435a-bf2e-018cbd3b948f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random samples\n",
        "\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df_shuffled)-5)\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(disaster)\" if target > 0 else \"(not a disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgQTdLVzYtcu",
        "outputId": "058faa82-9082-4b8f-898d-ddf3c711f90b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not a disaster)\n",
            "Text:\n",
            "Wholesale #WE Gon Rep That $hit At All Costs- Hazardous #WholeTeam3 #WholesaleEnt https://t.co/JWnXH9Q5ov\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 1 (disaster)\n",
            "Text:\n",
            "@UrufuSanRagu a Mudslide?\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 1 (disaster)\n",
            "Text:\n",
            "Some poor sods arriving in Amman during yesterday's dust storm were diverted to Ben Gurion airport: http://t.co/jkpjpcH9i6\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 1 (disaster)\n",
            "Text:\n",
            "@hannahkauthor Read: American lives first | The Chronicle #FreeAmirNow #FreeALLFour #Hostages held by #Iran #IranDeal http://t.co/gWnLHNeKu9\n",
            "\n",
            "----------\n",
            "\n",
            "Target: 0 (not a disaster)\n",
            "Text:\n",
            "And last year it was just a lot of 'THE DRUMS ARE FLOODING' and 'JANICE I'M FALLING'\n",
            "\n",
            "----------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset into Train and Validation sets\n",
        "\n",
        "Since the test set doesn't contain the target variable so we might need some unseen data for model to be validated after training, so how about splitting our training set for validating purpose with some amount.\n"
      ],
      "metadata": {
        "id": "WmmI2TzZZa1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=17)"
      ],
      "metadata": {
        "id": "jEgDccMKTYSx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting Text into Numbers\n",
        "\n",
        "Our labels are in numerical form (0 and 1) but our tweets are in string form.\n",
        "\n",
        "But machine learning algorithm learns only through numbers so we have to convert those tweets/texts into numbers.\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers,\n",
        "- **Tokenization** : A straight mapping from **word**(known as *word-level tokenization*) or character(which is *character-level tokenization*) or sub-word(*sub-word tokenization*) to a numerical value. Just like One hot encoding, suppose we have a sentence as \"My name is Alpha\", then if we are mapping according to word, \"My\" would `0`, \"name\" as `1`, \"is\" as `2` and \"Alpha\" as `3`.\n",
        "- **Embeddings** : An embedding is a representation of natural language which can be learned. Representation comes in the form of **feature-vector**. For example the word \"Alpha\" could be represented by 5-D vector `[0.564, 0.897, 0.456, -0.987, 0.15]`. The size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "\n",
        "    - **Create your own embedding** - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as `tf.keras.layers.Embedding`) and an embedding representation will be learned during model training.\n",
        "    - **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task.\n",
        "\n",
        "\n",
        "Simply, \n",
        "\n",
        "**Tokenization** : Straight mapping from word to number.\n",
        "\n",
        "**Embedding** : Richer representation of relationships between tokens.\n",
        "\n",
        "It depends on your problem. You could try character-level tokenization/embeddings and word-level tokenization/embeddings and see which perform best. You might even want to try stacking them (e.g. combining the outputs of your embedding layers using [tf.keras.layers.concatenate](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate)).\n",
        "\n",
        "If you're looking for pre-trained word embeddings, [Word2vec embeddings](https://jalammar.github.io/illustrated-word2vec/), [GloVe embeddings](https://nlp.stanford.edu/projects/glove/) and many of the options available on TensorFlow Hub are great places to start.\n",
        "\n",
        "Much like searching for a pre-trained computer vision model, we can search for pre-trained word embedding to use for your problem. Try searching for something like \"use pre-trained word embeddings in TensorFlow\"."
      ],
      "metadata": {
        "id": "MitNUg-uTxx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization\n",
        "\n",
        "Mapping words to numbers.\n",
        "\n",
        "To tokenize our words, we'll use the preprocessing layer,\n",
        "`tf.keras.layers.preprocessing.TextVectorization`"
      ],
      "metadata": {
        "id": "oyTzuPa0V5bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Using the default TextVectorization variables\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                 standardize=\"lower_and_strip_punctuation\", # how to process the text\n",
        "                                 split=\"whitespace\", # how to split the text\n",
        "                                 ngrams=None, # create groups of n-words\n",
        "                                 output_mode='int', # how to map tokens to numbers\n",
        "                                 output_sequence_length=None) # How long should the output sequence of tokens be?"
      ],
      "metadata": {
        "id": "k6z0y1iEIEs5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "About the above params,\n",
        "\n",
        "- `max_tokens` : The maximum number of words in your vocabulary (e.g 20000 or the number of unique words in your text), includes a value for OOV(out of vocabulary) tokens\n",
        "- `standardize` : Methods for standardizing text\n",
        "- `split`: split the text\n",
        "- `ngrams`: how many words to contain per token split, for example if 2, it splits tokens into continous sequences of 2\n",
        "- `output_mode`: How to output tokens can be `int`(integer mapping), `binary`(OHE), `count` or `tf-idf`\n",
        "- `output_sequence_length`: Length of tokenized sequence to output, For example if set to 150, all tokenized sequences will be 150 tokens long.\n",
        "\n",
        "In the above cell, we have initialized the object with the default settings but let's customize it a little bit for our own use case.\n",
        "\n",
        "In particular, let's set values for `max_tokens` and `output_sequence_length`.\n",
        "\n",
        "For `max_tokens`(the number of words in the vocabulary), multiples of 10,000(`10,000`, `20,000`, `30,000`) or the exact number of unqiue words in your text(e.g `32,179`) are common values.\n",
        "\n",
        "For our use case, `10,000`\n",
        "\n",
        "And for the `output_sequence_length` we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."
      ],
      "metadata": {
        "id": "CgAnhcS2KVIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "id": "c4ysmlUhLX6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ad6821-5cfa-4dcd-bf60-62df29a7c70f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000\n",
        "max_length = 15\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "KA553WXeaU4a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To map our `TextVectorization` instance `text_vectorizer` to our data, we can call the `adapt()` method on it whilst passing it our training set."
      ],
      "metadata": {
        "id": "KJZbqKiobF3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "OOfO1BecbdMe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data mapped! Let's try our `text_vectorizer` on a custom sentence."
      ],
      "metadata": {
        "id": "h0hxXVglbj3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a sample sentence\n",
        "sample_sentence = \"There's a flood in my village!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGCO1vkUb3eW",
        "outputId": "35616f20-35ad-4a17-f02e-45350d2eb66f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[281,   3, 214,   4,  13, 881,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try our `text_vectorizer` on a few random sentences ?"
      ],
      "metadata": {
        "id": "LC1QnE2WcBfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original Text: \\n{random_sentence}\\\n",
        "        \\n\\n Vectorized Text:')\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYj-_VcNcP7u",
        "outputId": "8fbe9afa-5113-4b2b-a653-38c3be0e3d73"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: \n",
            "@ChrisDyson16 Just wait until your friends at #MTA ruin it #Sorrybutitstrue        \n",
            "\n",
            " Vectorized Text:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   1,   30,  752,  269,   33,  779,   17,    1,  374,   15, 8250,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check the unique tokens in our vocabulary using the `get_vocabulary()` method"
      ],
      "metadata": {
        "id": "ZrtMKcpgcfcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "\n",
        "print(f\"Number of words in Vocab:{len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words:{top_5_words}\")\n",
        "print(f\"Bottom 5 least common words:{bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJLbch5kcuc5",
        "outputId": "d6a6919f-0577-4ef9-a055-f077e207d912"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in Vocab:10000\n",
            "Top 5 most common words:['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words:['ovo', 'overåÊhostages', 'overzero', 'overwatch', 'overturns']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding\n",
        "\n",
        "**Create an Embedding using Embedding Layer**\n",
        "\n",
        "We've got a way to map our text to numbers. How about we go a step further and turn those numbers into an embedding?\n",
        "\n",
        "The powerful thing about an embedding is it can be learned during training. This means rather that just be static, a word's numeric representation can be improved as a model goes through data samples.\n",
        "\n",
        "We can see what an embedding of a word looks like by using the `tf.keras.layers.Embedding` layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "rnhKQAUFdRqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(17)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length,\n",
        "                             name=\"embedding_1\")\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4AxkJ4teKHO",
        "outputId": "59d543ad-ccd7-4149-9422-fc9e4fc9bfe2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f9d0c571460>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`embedding` is a TensorFlow Layer, so that we can use it as part of a model, meaning its parameters(word representations) can be updated and improved as the model learns.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wd2p3RPvevde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text: \\n{random_sentence}\")\n",
        "print(\"\\n\\nEmbedded version:\")\n",
        "\n",
        "# embed the random sentence\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GseLqO74tWkN",
        "outputId": "86ad7f27-ee8c-4d21-d867-bfd722310f69"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: \n",
            "I want to see my @AustinPearcy22 so bad its not even funny. I will probably cry and drowned him in kisses when I do. ????\n",
            "\n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.02343173, -0.02652723, -0.03152039, ...,  0.02102336,\n",
              "          0.00488753, -0.0158362 ],\n",
              "        [-0.02298733,  0.02857829, -0.0227545 , ...,  0.00953416,\n",
              "         -0.04039486, -0.03494654],\n",
              "        [ 0.04393915,  0.03116182, -0.01985701, ..., -0.03828044,\n",
              "          0.04807109, -0.02644128],\n",
              "        ...,\n",
              "        [ 0.02343173, -0.02652723, -0.03152039, ...,  0.02102336,\n",
              "          0.00488753, -0.0158362 ],\n",
              "        [-0.00900798, -0.02913499,  0.02235535, ..., -0.00696812,\n",
              "         -0.03225274,  0.04643698],\n",
              "        [-0.0459116 ,  0.03902522,  0.02884947, ...,  0.007984  ,\n",
              "          0.04224494,  0.04923623]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These values might not mean much to us but they're what our computer sees each word as. When our model looks for patterns in different samples, these values will be updated as necessary.\n",
        "\n",
        "If we review the shape of Embedded Version Tensor it is, `(1, 15, 128)`, it means that,\n",
        "- 1: Is the quantity of sequences(sentences) we passed\n",
        "- 15: is the `max_length` that we decided to normalize every sentence, if greater than 15 tokens/words then trim extra tokens or if less than 15 then pad it.\n",
        "- 128: is the array size of each words, for example above sentence as `Now`, for this token the embedding tensor will look like,"
      ],
      "metadata": {
        "id": "9Kp2cu1Dt4sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_embed[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW7O7e1UDyKn",
        "outputId": "f306529c-17f0-434a-f361-022e7d0fca63"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 0.02343173, -0.02652723, -0.03152039,  0.0001976 ,  0.03178922,\n",
              "       -0.02187899,  0.01466176,  0.02729701, -0.01650792,  0.00071656,\n",
              "        0.01262747, -0.03931329,  0.04047468,  0.0302651 ,  0.04066459,\n",
              "        0.02593447, -0.01407721,  0.00172062, -0.01581769, -0.041679  ,\n",
              "        0.04537575,  0.0138167 ,  0.0227331 , -0.01948496,  0.02788392,\n",
              "       -0.04262939,  0.00603651, -0.04573451,  0.0013571 , -0.0103989 ,\n",
              "       -0.0108821 ,  0.01489433, -0.02658217,  0.00662044, -0.04545839,\n",
              "        0.02706282,  0.03625358, -0.03858987,  0.04437229, -0.02241309,\n",
              "       -0.00491514,  0.02914338,  0.02270282,  0.04649563, -0.0364399 ,\n",
              "        0.00605464, -0.03569745, -0.04163226, -0.02132156, -0.00294595,\n",
              "       -0.01529732,  0.02561878, -0.02697936,  0.04775373,  0.0125651 ,\n",
              "       -0.04730059,  0.0405975 , -0.03300925, -0.00553391, -0.02913319,\n",
              "        0.01346369, -0.0016955 , -0.03761097, -0.03137752,  0.01358772,\n",
              "       -0.01430515, -0.02071511, -0.01853206, -0.03415629, -0.04123973,\n",
              "        0.00285833, -0.0193691 ,  0.03437728,  0.00228564,  0.00245042,\n",
              "        0.01258678, -0.02226447,  0.01020283,  0.03914715, -0.03918568,\n",
              "        0.01827434, -0.01815154,  0.03523059,  0.02067916, -0.04028393,\n",
              "       -0.01903835,  0.03725784,  0.04527763, -0.03578581,  0.01363683,\n",
              "       -0.01421193, -0.01607915, -0.04940725,  0.02354393, -0.01749019,\n",
              "        0.0015435 , -0.04605948,  0.04097075,  0.01360849, -0.01705552,\n",
              "        0.04724362,  0.03420127, -0.04194589, -0.03105619,  0.03163079,\n",
              "        0.02440467, -0.00815658, -0.01287971, -0.01186044, -0.02792121,\n",
              "        0.01920288,  0.03053135,  0.02661918, -0.03563926, -0.04509741,\n",
              "        0.01171068, -0.0350423 , -0.02396256,  0.02461049, -0.01994069,\n",
              "        0.0355682 ,  0.04574582, -0.01890572,  0.04847977, -0.03557894,\n",
              "        0.02102336,  0.00488753, -0.0158362 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation function for our Model Experiments\n",
        "\n",
        "Since we're going to perform multiple experiments by creating deeplearning models and scikit learn algorithms, so to track them we should create a common function for comparison.\n",
        "\n",
        "There are various metrics to evaluate the classification models like precision, f1-score, recall. So let's look at them through a function altogether."
      ],
      "metadata": {
        "id": "dbKbKEU5Fxy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates Model accuracy, precision, recall and f1-score for a binary classification model\n",
        "  \"\"\"\n",
        "  # calculate the model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred)\n",
        "  # calculate precision, recall, f1-score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy * 100,\n",
        "                   \"precision\":model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1-score\": model_f1}\n",
        "                  \n",
        "  return model_results"
      ],
      "metadata": {
        "id": "bcwg-4J5GKUj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a Text Dataset\n",
        "\n",
        "For experiments with various machine learning model for text classifier we will be considering below experiments:\n",
        "- **Model 0** : Naive Bayes (baseline)\n",
        "- **Model 1** : Feed-forward neural network (dense model) \n",
        "- **Model 2** : LSTM Model (RNN)\n",
        "- **Model 3** : GRU (RNN)\n",
        "- **Model 4** : Bidirectional-LSTM (RNN)\n",
        "- **Model 5** : 1D CNN\n",
        "- **Model 6** : TF Hub Pre-trained Feature Extractor\n",
        "- **Model 7** : Same as model 6 with 10% of training samples"
      ],
      "metadata": {
        "id": "LUy8YjJ2EWQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0 : Getting a baseline\n",
        "\n",
        "We'll use `scikit-learn` library for building this model, and create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert words into numbers and then model them using Multinomial Naive Bayes Algorithm.\n",
        "\n",
        "> 📖 **Reading**: About TF-IDF on [Scikit-learn documentation](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)"
      ],
      "metadata": {
        "id": "72x7n-xuFM8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IkZ6K-UF1j2",
        "outputId": "490f3108-aa1e-4365-bd2b-2cbd3ae77f71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multinomial Naive Bayes model is kind of shallow model which trains faster."
      ],
      "metadata": {
        "id": "gLex6UKjGaDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zihkmgPZGkfC",
        "outputId": "0bdd3405-6d8e-48cc-82a5-078584309cd4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 80.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make some predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZtZ-lodG0ii",
        "outputId": "8ed4c060-7cd3-4f62-91b4-2b2522f18814"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it is similar to our labels\n",
        "val_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uWMFYvAG-qx",
        "outputId": "b2174a57-4afb-4dfa-884c-00fdd4297fb4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbG9m6vqJhGL",
        "outputId": "b2de8454-fdd4-407d-a785-22643ab24ad5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.18372703412074,\n",
              " 'precision': 0.8125567744156732,\n",
              " 'recall': 0.8018372703412073,\n",
              " 'f1-score': 0.7968681002825004}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1 : A Simple Dense Model\n",
        "\n",
        "The first \"deep\" model we're going to build is a single layer dense model."
      ],
      "metadata": {
        "id": "qZJjPR31JqYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create directory to save Tensorboard logs\n",
        "SAVE_DIR = \"model_logs\"\n",
        "\n",
        "# Build model with functional API\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn text inputs into numbers using text_vectorizer\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model\n",
        "\n",
        "# compile the model\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "history_model_1 = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh4r0AfCHfnh",
        "outputId": "c97d110e-c008-4d60-f398-2a0ac84e445f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/simple_dense_model/20230208-024055\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 5ms/step - loss: 0.6152 - accuracy: 0.6854 - val_loss: 0.5256 - val_accuracy: 0.7638\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.4439 - accuracy: 0.8167 - val_loss: 0.4640 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.3478 - accuracy: 0.8616 - val_loss: 0.4596 - val_accuracy: 0.7927\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2846 - accuracy: 0.8864 - val_loss: 0.4721 - val_accuracy: 0.7979\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2380 - accuracy: 0.9101 - val_loss: 0.4938 - val_accuracy: 0.7953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixLdaS-DJiv7",
        "outputId": "9a69136a-65b6-4845-eacc-9aa6a534dfad"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7953\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4938335716724396, 0.7952755689620972]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make some predictions\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFZ35FbBJrW-",
        "outputId": "ba30b16a-1ae0-4689-fc3e-ba9b5d62ac56"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12096813],\n",
              "       [0.00963379],\n",
              "       [0.07517963],\n",
              "       [0.43156   ],\n",
              "       [0.9998043 ],\n",
              "       [0.8580827 ],\n",
              "       [0.13515034],\n",
              "       [0.894733  ],\n",
              "       [0.58565694],\n",
              "       [0.08657645]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright ! Let's some more evaluations by using our common function for evaluation."
      ],
      "metadata": {
        "id": "SrsxhgWcKgH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for the evaluation we have to make it similar to our val_labels which is in 0 and 1\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "191_2ce5K5hV",
        "outputId": "8819f0d1-76b4-489e-bb89-b9985ddff382"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_dense_results = calculate_results(y_true=val_labels,\n",
        "                                         y_pred=model_1_preds)\n",
        "\n",
        "simple_dense_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_qe3BuhKpa8",
        "outputId": "97f05659-987e-41b9-d200-146e883c4889"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.52755905511812,\n",
              " 'precision': 0.7966788703003602,\n",
              " 'recall': 0.7952755905511811,\n",
              " 'f1-score': 0.7932321923411083}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For comparing the results like these between two models, let's create a helper function"
      ],
      "metadata": {
        "id": "WBvkM6hNLKma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for k,v in baseline_results.items():\n",
        "    print(f\"Baseline {k}: {v:.2f}, New {k}: {new_model_results[k]:.2f}, Difference: {new_model_results[k] - v:.3f}\")"
      ],
      "metadata": {
        "id": "-lpajBzWLZ2b"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_baseline_to_new_results(baseline_results, simple_dense_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usjwQEZSMA9v",
        "outputId": "0137a556-2765-43cf-9c81-e650c867ef9f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.18, New accuracy: 79.53, Difference: -0.656\n",
            "Baseline precision: 0.81, New precision: 0.80, Difference: -0.016\n",
            "Baseline recall: 0.80, New recall: 0.80, Difference: -0.007\n",
            "Baseline f1-score: 0.80, New f1-score: 0.79, Difference: -0.004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Learned Embeddings\n",
        "\n",
        "Our first model (`model_1`) contained an embedding layer (`embedding`) which learned a way of representing words as feature vectors by passing over the training data.\n",
        "\n",
        "To understand what a text embedding is, let's visualize the embedding our model learned."
      ],
      "metadata": {
        "id": "Hysy96wpMGLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp7kot3HIkVN",
        "outputId": "3bfb0e69-5d37-49c5-b1e2-4b36fc935e1c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let's get our embedding layer's weights (these are the numerical representations of each word)."
      ],
      "metadata": {
        "id": "ObaHI9rrIujy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc39TunRJDn-",
        "outputId": "2d3604b5-5336-473e-fb58-b104e018aa08"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the weight matrix of embedding layer\n",
        "embed_weights = model_1.layers[2].get_weights()[0] \n",
        "print(embed_weights.shape) # same size as vocab size and embedding_dim (each word is a embedding_dim size vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cnOYapAJFQ-",
        "outputId": "9e53eb00-e932-4f4b-dd6b-1f12468e3468"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_weights[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JDpi0keJaKg",
        "outputId": "ec4f9015-6e97-4b4e-f0bb-9dfaeb6af8f3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.05793181, -0.03914464, -0.02473383, -0.00400928,  0.02946338,\n",
              "       -0.01301204,  0.05229732,  0.04887474,  0.06025089,  0.00805069,\n",
              "        0.06344493,  0.06382313,  0.03528398, -0.0243746 , -0.03784518,\n",
              "       -0.00860966, -0.02997296, -0.00939369,  0.05955035, -0.0666528 ,\n",
              "       -0.0153504 ,  0.01206796,  0.01324632,  0.00885768, -0.03989453,\n",
              "        0.0059811 , -0.05867316,  0.01391945, -0.01342947, -0.0315125 ,\n",
              "       -0.01170612, -0.01470302,  0.05553511,  0.06478362, -0.03305588,\n",
              "        0.00180237,  0.03188962, -0.01603713,  0.0065343 , -0.01364341,\n",
              "       -0.01092497,  0.03955518, -0.00912936, -0.04180071, -0.01730738,\n",
              "       -0.00267582, -0.05257865, -0.00593809, -0.00243137, -0.00406673,\n",
              "        0.0593499 ,  0.0077191 , -0.0055135 , -0.03471249, -0.0266527 ,\n",
              "       -0.01058053,  0.01899304, -0.05025221, -0.01186906, -0.00643935,\n",
              "       -0.03974142, -0.02110856, -0.00443363, -0.00674051,  0.0227233 ,\n",
              "        0.02054   , -0.01021375, -0.03714587,  0.03495809, -0.00551941,\n",
              "       -0.05402941,  0.0567328 , -0.02860853,  0.05933991,  0.04321824,\n",
              "       -0.03300178, -0.01398473,  0.00378326,  0.0565896 ,  0.06639098,\n",
              "        0.04891378, -0.03926004,  0.02138171, -0.05530741,  0.03143609,\n",
              "       -0.00662656,  0.02964567, -0.05007802, -0.04113482,  0.01724831,\n",
              "        0.00210687,  0.01717914,  0.0234562 ,  0.04754277, -0.02072726,\n",
              "        0.02285102,  0.03893686,  0.03659021,  0.03092391, -0.05657143,\n",
              "       -0.00815742, -0.03492343, -0.0570826 , -0.01064817, -0.04797029,\n",
              "       -0.01948296, -0.03375851, -0.01503073, -0.02164169,  0.00636741,\n",
              "        0.03055429,  0.06135833, -0.01142474, -0.02363287,  0.01905318,\n",
              "       -0.01181161, -0.03480684, -0.03662144,  0.03230289, -0.05484901,\n",
              "       -0.01756295,  0.03628292,  0.02103204,  0.03848094,  0.05498388,\n",
              "        0.00409453,  0.02326121, -0.00015124], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got these two objects, we can use the [Embedding Projector Tool](http://projector.tensorflow.org/) to visualize our embedding.\n",
        "\n",
        "To use the embedding projector tool, we need two files,\n",
        "- the embedding vectors (same as embedding weights)\n",
        "- the metadata of the embedding vectors (the words they represent - our vocabulary)"
      ],
      "metadata": {
        "id": "v8q7clW_JvQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import io\n",
        "\n",
        "# # Create output writers\n",
        "# out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "# out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# # Write embedding vectors and words to file\n",
        "# for num, word in enumerate(words_in_vocab):\n",
        "#   if num==0:\n",
        "#     continue # skip padding token\n",
        "#   vec = embed_weights[num]\n",
        "#   out_m.write(word + \"\\n\") # write words to file\n",
        "#   out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "\n",
        "# # Download files locally to upload to Embedding projector\n",
        "\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "# except ImportError:\n",
        "#   pass\n",
        "# else:\n",
        "#   files.download(\"embedding_vectors.tsv\")\n",
        "#   files.download(\"embedding_metadata.tsv\")"
      ],
      "metadata": {
        "id": "k_6Mx76TL1rT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks(RNN's)\n",
        "\n",
        "For further experimentations we're going to use special kind of neural networks used for sequence data such as to predict the next location based on the prior location or may be to generate a new sequence based on the past sequences which is done through **Recurrent Neural Networks (RNN)**.\n",
        "\n",
        "Recurrent Neural Networks can be used for a number of sequence-based problems:\n",
        "- **One to One:** one input, one output, such as image classification\n",
        "- **One to many:** one input, many output, such as image captioning\n",
        "- **Many to one:** many inputs, one outputs, such as text classification\n",
        "- **Many to Many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text\n",
        "\n",
        "Most commong RNN cell or layers used for designing the network are:\n",
        "- LSTM (Long Short Term Memory)\n",
        "- GRU (Gates Recurrent Unit)\n",
        "- Bidirectional RNNs (passes forward and backward along a sequence, left to right and right to left)\n",
        "\n",
        "The architecture of the RNNs would be,\n",
        "\n",
        "      Input(text) -> Tokenize -> Embedding -> Layers -> Output (label probability)"
      ],
      "metadata": {
        "id": "DteZn62KNfRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 : LSTM\n",
        "\n",
        "> **Note**: For a best practice when we are comparing different models then embedding layer should be different because embedding layer is a learned representation of words, if we were to use the same embedding layer for each model, we'd be mixing what one model has learned with the next. "
      ],
      "metadata": {
        "id": "uEYEHgyjmVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed and creating embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(17)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                           output_dim=128,\n",
        "                                           embeddings_initializer=\"uniform\",\n",
        "                                           input_length=max_length,\n",
        "                                           name=\"embedding_2\")\n",
        "\n",
        "# Create LSTM model\n",
        "input = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(input)\n",
        "x = model_2_embedding(x)\n",
        "#print(x.shape)\n",
        "#x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (if we want to stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_2 = tf.keras.Model(input, output, name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "id": "0SjUQmhdmdth"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the Tensorflow documentation on LSTM, it accepts 3D input tensor as [batch, timestamp, feature_vector] so when we stack one more cell of LSTM, then we must set `return_sequences=True` so that when next LSTM cell is stacked will be inject with 3D input or else it would through error of \"expecting 3D tensor but received 2D\""
      ],
      "metadata": {
        "id": "hPDrDQwSqlso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Function for Compiling and Fitting the Model"
      ],
      "metadata": {
        "id": "XWRxF6ChsAew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for compiling and fitting the model let's create a helper function\n",
        "\n",
        "def compile_fit_RNNs(model, dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Function used for compiling and fitting the model and save the \n",
        "  tensorboard experiment as well on the passed directory\n",
        "\n",
        "  Returns the model history\n",
        "  \"\"\"\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # fit the model\n",
        "  history = model.fit(train_sentences,\n",
        "                      train_labels,\n",
        "                      epochs=5,\n",
        "                      validation_data=(val_sentences, val_labels),\n",
        "                      callbacks=[create_tensorboard_callback(dir_name, experiment_name)])\n",
        "  \n",
        "  return history"
      ],
      "metadata": {
        "id": "t2esO0x8qZfU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_history = compile_fit_RNNs(model=model_2, dir_name=SAVE_DIR, experiment_name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw7zOCCtr90b",
        "outputId": "330880ab-3934-4e8c-c612-4f1887fff9bd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/model_2_LSTM/20230208-024103\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 9ms/step - loss: 0.5133 - accuracy: 0.7434 - val_loss: 0.4492 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.3184 - accuracy: 0.8695 - val_loss: 0.4724 - val_accuracy: 0.7966\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2199 - accuracy: 0.9204 - val_loss: 0.5474 - val_accuracy: 0.7874\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1537 - accuracy: 0.9456 - val_loss: 0.6827 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.1108 - accuracy: 0.9603 - val_loss: 0.8267 - val_accuracy: 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we check the summary of the LSTM Model"
      ],
      "metadata": {
        "id": "ENi7wJatsq18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMvUY6bgsuW3",
        "outputId": "72c39392-31a0-438c-8072-819388d09673"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make some predictions\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsvQ90rasR-m",
        "outputId": "b19e974f-1480-4ae6-b26c-a9ed8c91b6e3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0211548 ],\n",
              "       [0.00182996],\n",
              "       [0.01620475],\n",
              "       [0.16472119],\n",
              "       [0.9998977 ],\n",
              "       [0.99410546],\n",
              "       [0.01473758],\n",
              "       [0.7996622 ],\n",
              "       [0.8936984 ],\n",
              "       [0.54785395]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert them to compare with labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idYU2tb9sbcV",
        "outputId": "509679f4-d1f9-4bba-85a2-147016621ff3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's calculate the results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC0KzqZpsnJ6",
        "outputId": "4431338c-a464-4812-c7ff-417c1c9b237e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'precision': 0.7659025055163764,\n",
              " 'recall': 0.7664041994750657,\n",
              " 'f1-score': 0.7660201893659146}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare the baseline results with model_2\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0QZl372tc4T",
        "outputId": "3b1c8792-a0f1-4cf1-bddf-3c175573044d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.18, New accuracy: 76.64, Difference: -3.543\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.047\n",
            "Baseline recall: 0.80, New recall: 0.77, Difference: -0.035\n",
            "Baseline f1-score: 0.80, New f1-score: 0.77, Difference: -0.031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3 : GRU\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters."
      ],
      "metadata": {
        "id": "Qx7XI2aKt-10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the random seed and create new embedding layer\n",
        "tf.random.set_seed(17)\n",
        "\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build GRU model\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name='model_3_GRU')\n"
      ],
      "metadata": {
        "id": "4tnDsQXHuIgS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see the summary\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NyQL49vvR7y",
        "outputId": "a04a8fd2-483d-4756-c160-a55e6973bb28"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's the same as LSTM model but with less params"
      ],
      "metadata": {
        "id": "DfdhvEYwveuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile and fit the model\n",
        "model_3_history = compile_fit_RNNs(model_3, SAVE_DIR, \"model_3_GRU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5dlJVK3vlXw",
        "outputId": "a0d0acb8-ff25-491a-9527-520f8667af44"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/model_3_GRU/20230208-024126\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 3s 8ms/step - loss: 0.5328 - accuracy: 0.7219 - val_loss: 0.4518 - val_accuracy: 0.8045\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3221 - accuracy: 0.8641 - val_loss: 0.4690 - val_accuracy: 0.8018\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2178 - accuracy: 0.9181 - val_loss: 0.5357 - val_accuracy: 0.7848\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1489 - accuracy: 0.9499 - val_loss: 0.6772 - val_accuracy: 0.7703\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1122 - accuracy: 0.9625 - val_loss: 0.6983 - val_accuracy: 0.7559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "# convert them into labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs)) \n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax7jpoHjvwRR",
        "outputId": "4b503352-2d4a-4ee6-a53e-68a5485f2be1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the result\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                   y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9FOAOdQwE2b",
        "outputId": "41e333b0-9610-425c-eb2b-db719bfc0834"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.59055118110236,\n",
              " 'precision': 0.7551876442680979,\n",
              " 'recall': 0.7559055118110236,\n",
              " 'f1-score': 0.7551196015270819}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare with baseline score\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuuFbg8-wOo1",
        "outputId": "a8621d9d-288c-41e9-9a53-644010370779"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.18, New accuracy: 75.59, Difference: -4.593\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.057\n",
            "Baseline recall: 0.80, New recall: 0.76, Difference: -0.046\n",
            "Baseline f1-score: 0.80, New f1-score: 0.76, Difference: -0.042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's looks like Baseline is still outperforming dense models, let's see one more model"
      ],
      "metadata": {
        "id": "_yuiOQbYwXjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4 : Bidirectional RNNs\n",
        "\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left."
      ],
      "metadata": {
        "id": "_VJlzkRkwhIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(17)\n",
        "model_4_embedding = layers.Embedding(input_dim = max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build the Bidirectional Model\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name='model_4_Bidirectional')"
      ],
      "metadata": {
        "id": "uqprPWR_wlLZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the summary\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wHIKZp3xitb",
        "outputId": "7c39167f-f2b4-45ee-cd50-63d6c1765fb8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the parameters of the Bidirectional layer get doubled."
      ],
      "metadata": {
        "id": "hEAbh_vcxnqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile and fit\n",
        "model_4_history = compile_fit_RNNs(model_4, SAVE_DIR, \"model_4_Bidirectional\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxIMSyXOxtKd",
        "outputId": "b63586f6-9c71-4f2e-f7fb-acbb73c178db"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/model_4_Bidirectional/20230208-024139\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 14ms/step - loss: 0.5140 - accuracy: 0.7427 - val_loss: 0.4542 - val_accuracy: 0.8018\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3149 - accuracy: 0.8691 - val_loss: 0.4835 - val_accuracy: 0.7900\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.2171 - accuracy: 0.9202 - val_loss: 0.5680 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1469 - accuracy: 0.9520 - val_loss: 0.6563 - val_accuracy: 0.7612\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.1036 - accuracy: 0.9641 - val_loss: 0.7833 - val_accuracy: 0.7598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "model_4_pred_probs = model_4.predict(val_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js6QrUtEx1t8",
        "outputId": "4b12e9eb-b1c4-412f-b446-ca6ce71d6764"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert them into labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uo1RB9Lx5yk",
        "outputId": "3e7973ca-5800-407d-81ad-d2850f7d7b1e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the result\n",
        "model_4_results = calculate_results(y_true = val_labels,\n",
        "                                    y_pred = model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXe4FqILyEfc",
        "outputId": "91b3d03e-6b73-4c43-c855-599d0610b12b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'precision': 0.7600694650010854,\n",
              " 'recall': 0.7598425196850394,\n",
              " 'f1-score': 0.7599441744417845}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare with baseline scores\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UJ2lQftyQvP",
        "outputId": "c6c4a90d-6590-493d-e434-636d1527789e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.18, New accuracy: 75.98, Difference: -4.199\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.052\n",
            "Baseline recall: 0.80, New recall: 0.76, Difference: -0.042\n",
            "Baseline f1-score: 0.80, New f1-score: 0.76, Difference: -0.037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolution Neural Networks for Text\n",
        "\n",
        "CNNs can be used to train Text inputs by using the 1-Dimension layers instead of 2-Dimensional convolution like did with Images.\n",
        "\n",
        "A Typical CNN architecture for sequences will look like the following:\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)\n",
        "```\n",
        "\n",
        "The main difference would be to use `tf.keras.layers.Conv1D()` instead of LSTM, GRU or Bidirectional cell in the layers, rest will be same."
      ],
      "metadata": {
        "id": "lyGbW4SxjYpL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5 : Conv1D \n",
        "\n",
        "Let's see first 1-dimensional convolutional layer (also called a temporal convolution), temporal means the data in timestamp sequences."
      ],
      "metadata": {
        "id": "HBf2K7hbj0sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer(['This is a test for conv layer'])) \n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, strides=1, activation=\"relu\", padding=\"valid\")\n",
        "conv_1d_output = conv_1d(embedding_test)\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output)\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyN-Ks1bkVHI",
        "outputId": "7f8b485b-5ae5-4bb3-9ddb-b894473e60a6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output shape of `conv_1d_output` is `[1,11,32]`, here the input length was `15` and output_dim - `128` of sequences in the embedding layer.\n",
        "\n",
        "The 1-D conv layer compressed inline with its parameters. And the same goes for max pooling layer output.\n",
        "\n",
        "Our text starts out as a string but gets converted to a feature vector of length 32 through various transformation steps(from tokenization to embedding to 1-Dimensional convolution to max pool)."
      ],
      "metadata": {
        "id": "l-nT5bXOk63W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## see the outputs of each layer\n",
        "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu8uiayyn79s",
        "outputId": "d0f5f428-7712-4585-a9c4-3c71433d2e20"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[ 0.00563604,  0.00831303, -0.03987604, ..., -0.00901502,\n",
              "          -0.02458371, -0.00313253],\n",
              "         [ 0.01050907,  0.07342833, -0.02361131, ..., -0.01137419,\n",
              "           0.03161566,  0.01970428],\n",
              "         [-0.03601192,  0.00866883, -0.04841171, ..., -0.04186256,\n",
              "           0.03951384, -0.02277594],\n",
              "         ...,\n",
              "         [-0.05793181, -0.03914464, -0.02473383, ...,  0.00409453,\n",
              "           0.02326121, -0.00015124],\n",
              "         [-0.05793181, -0.03914464, -0.02473383, ...,  0.00409453,\n",
              "           0.02326121, -0.00015124],\n",
              "         [-0.05793181, -0.03914464, -0.02473383, ...,  0.00409453,\n",
              "           0.02326121, -0.00015124]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              " array([[[0.        , 0.03461808, 0.04056317, 0.03943498, 0.03135175,\n",
              "          0.00109525, 0.001645  , 0.02065375, 0.03384818, 0.06376338,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.02814319,\n",
              "          0.        , 0.02335804, 0.        , 0.        , 0.08719777,\n",
              "          0.09039339, 0.        , 0.03038757, 0.        , 0.        ,\n",
              "          0.        , 0.01343112, 0.        , 0.06609242, 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.0764782 , 0.        , 0.01919919, 0.        , 0.03547236,\n",
              "          0.08662466, 0.        , 0.        , 0.        , 0.08428136,\n",
              "          0.05702461, 0.02060773, 0.        , 0.        , 0.        ,\n",
              "          0.02598079, 0.        , 0.        , 0.01701438, 0.        ,\n",
              "          0.        , 0.08233303, 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.00827229, 0.04662846, 0.02168218, 0.04228196,\n",
              "          0.08170681, 0.00100023],\n",
              "         [0.        , 0.05717973, 0.        , 0.        , 0.        ,\n",
              "          0.0749508 , 0.        , 0.0204897 , 0.        , 0.05699941,\n",
              "          0.11023183, 0.05702513, 0.        , 0.0231078 , 0.        ,\n",
              "          0.        , 0.00686765, 0.        , 0.00701854, 0.08093306,\n",
              "          0.10979289, 0.1302534 , 0.        , 0.030661  , 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.01952722],\n",
              "         [0.02640983, 0.01735173, 0.01103687, 0.08510981, 0.01400457,\n",
              "          0.05367161, 0.04072633, 0.01060583, 0.        , 0.0667636 ,\n",
              "          0.        , 0.08392847, 0.04772656, 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.03650602, 0.        , 0.03884182,\n",
              "          0.        , 0.06922229, 0.09860663, 0.        , 0.        ,\n",
              "          0.06090889, 0.        , 0.00417484, 0.02106523, 0.09397034,\n",
              "          0.06676271, 0.        ],\n",
              "         [0.01558589, 0.        , 0.02263873, 0.00055921, 0.00456196,\n",
              "          0.01505361, 0.0377702 , 0.        , 0.        , 0.05350944,\n",
              "          0.01694091, 0.00364913, 0.01459738, 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.00986612, 0.06423344, 0.07255763, 0.        , 0.        ,\n",
              "          0.        , 0.04436694, 0.        , 0.02071766, 0.04013615,\n",
              "          0.05641007, 0.        ],\n",
              "         [0.        , 0.03461329, 0.0522542 , 0.01082172, 0.02114743,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.03142166,\n",
              "          0.0248225 , 0.        , 0.02933147, 0.01765049, 0.        ,\n",
              "          0.        , 0.01048654, 0.05598031, 0.        , 0.        ,\n",
              "          0.        , 0.02534767, 0.05644293, 0.        , 0.        ,\n",
              "          0.        , 0.07428716, 0.        , 0.        , 0.        ,\n",
              "          0.00819663, 0.        ],\n",
              "         [0.        , 0.07465488, 0.        , 0.        , 0.03011664,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.08046456,\n",
              "          0.06392571, 0.03816448, 0.05070096, 0.        , 0.        ,\n",
              "          0.        , 0.02316466, 0.02950871, 0.        , 0.00791348,\n",
              "          0.        , 0.00830844, 0.05342643, 0.03598184, 0.        ,\n",
              "          0.        , 0.06427152, 0.        , 0.        , 0.        ,\n",
              "          0.01793888, 0.        ],\n",
              "         [0.        , 0.06735588, 0.        , 0.        , 0.04449611,\n",
              "          0.00111308, 0.        , 0.        , 0.        , 0.06157281,\n",
              "          0.11221662, 0.01950591, 0.03782237, 0.00625203, 0.        ,\n",
              "          0.        , 0.02321805, 0.        , 0.        , 0.        ,\n",
              "          0.01971478, 0.00913372, 0.02561829, 0.0506812 , 0.00621181,\n",
              "          0.        , 0.08538772, 0.        , 0.        , 0.        ,\n",
              "          0.04578617, 0.        ],\n",
              "         [0.        , 0.06735589, 0.        , 0.        , 0.04449612,\n",
              "          0.00111306, 0.        , 0.        , 0.        , 0.06157282,\n",
              "          0.11221664, 0.01950591, 0.03782237, 0.00625203, 0.        ,\n",
              "          0.        , 0.02321806, 0.        , 0.        , 0.        ,\n",
              "          0.01971479, 0.00913372, 0.02561828, 0.0506812 , 0.00621181,\n",
              "          0.        , 0.08538774, 0.        , 0.        , 0.        ,\n",
              "          0.04578617, 0.        ],\n",
              "         [0.        , 0.06735587, 0.        , 0.        , 0.0444961 ,\n",
              "          0.00111307, 0.        , 0.        , 0.        , 0.06157282,\n",
              "          0.11221664, 0.01950591, 0.03782236, 0.00625203, 0.        ,\n",
              "          0.        , 0.02321806, 0.        , 0.        , 0.        ,\n",
              "          0.01971477, 0.00913372, 0.02561827, 0.0506812 , 0.0062118 ,\n",
              "          0.        , 0.08538773, 0.        , 0.        , 0.        ,\n",
              "          0.04578616, 0.        ],\n",
              "         [0.        , 0.06735589, 0.        , 0.        , 0.0444961 ,\n",
              "          0.00111307, 0.        , 0.        , 0.        , 0.06157281,\n",
              "          0.11221662, 0.01950591, 0.03782238, 0.00625203, 0.        ,\n",
              "          0.        , 0.02321806, 0.        , 0.        , 0.        ,\n",
              "          0.0197148 , 0.00913373, 0.02561828, 0.0506812 , 0.00621181,\n",
              "          0.        , 0.08538774, 0.        , 0.        , 0.        ,\n",
              "          0.04578616, 0.        ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[0.0764782 , 0.07465488, 0.0522542 , 0.08510981, 0.04449612,\n",
              "         0.08662466, 0.04072633, 0.02065375, 0.03384818, 0.08428136,\n",
              "         0.11221664, 0.08392847, 0.05070096, 0.0231078 , 0.02814319,\n",
              "         0.02598079, 0.02335804, 0.05598031, 0.01701438, 0.08719777,\n",
              "         0.10979289, 0.1302534 , 0.09860663, 0.0506812 , 0.00621181,\n",
              "         0.06090889, 0.08538774, 0.04662846, 0.06609242, 0.09397034,\n",
              "         0.08170681, 0.01952722]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build the model"
      ],
      "metadata": {
        "id": "IeqGZ-isoDro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(17)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer='uniform',\n",
        "                                     input_length=max_length,\n",
        "                                     name='embedding_5')\n",
        "\n",
        "# Create 1-D conv layer\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, activation='relu')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name='model_5_Conv1D')\n",
        "\n",
        "# see the summary of the model\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI9CIi6AoKca",
        "outputId": "7c8ff76a-ad15-4628-fd61-be33e95b0794"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile and fit the model\n",
        "model_5_history = compile_fit_RNNs(model_5, SAVE_DIR, \"Conv1D_model_5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxAmZLe8pPmy",
        "outputId": "4ce9b630-e2a8-462e-859d-c731cb5e41a2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/Conv1D_model_5/20230208-024156\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 3s 7ms/step - loss: 0.5492 - accuracy: 0.7230 - val_loss: 0.4671 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.3318 - accuracy: 0.8628 - val_loss: 0.4971 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.1983 - accuracy: 0.9295 - val_loss: 0.5832 - val_accuracy: 0.7808\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.1230 - accuracy: 0.9580 - val_loss: 0.7008 - val_accuracy: 0.7717\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0889 - accuracy: 0.9715 - val_loss: 0.7734 - val_accuracy: 0.7598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make some predictions\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "# convert them into labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6jw6OhNpndy",
        "outputId": "c52f9999-7869-4d7d-f4a1-82d8e920ed10"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the results\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDaJpYHpp6rU",
        "outputId": "1011dcb6-8905-4577-9026-be4699507aeb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'precision': 0.759153894646392,\n",
              " 'recall': 0.7598425196850394,\n",
              " 'f1-score': 0.7589128680335064}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare with baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5BqqHSjqHUW",
        "outputId": "0c973add-1b3e-4bb6-a04a-30610504cce0"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.18, New accuracy: 75.98, Difference: -4.199\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.053\n",
            "Baseline recall: 0.80, New recall: 0.76, Difference: -0.042\n",
            "Baseline f1-score: 0.80, New f1-score: 0.76, Difference: -0.038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Pretrained Embeddings (transfer learning for NLP)\n",
        "\n",
        "A common practice is to leverage pretrained embeddings through transfer learning. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
        "\n",
        "Instead of using our own embedding layer, we're going to replace with a pretrained embedding layer.\n",
        "\n",
        "We're going to use the [Universal Sentence Encoder](https://www.aclweb.org/anthology/D18-2029.pdf) from Tensorflow Hub (a great resource containing a plethora of pretrained model resources for a variety of tasks.)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ie65o3e8OOmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 6 : TF Hub Pretrained Sentence Encoder\n",
        "\n",
        "Universal Sentence Encoder creates whole sentence-level embedding rather than creating a word-level embedding that we did earlier.\n",
        "\n",
        "Our embedding layer outputs an 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence."
      ],
      "metadata": {
        "id": "LNXkaZg8O8IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2XyCmPyLPq7V",
        "outputId": "a6c33fac-1f26-4315-a572-851a58b923c6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"There's a flood in my village!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load universal sentence encoder\n",
        "embed_samples = embed([sample_sentence, \n",
        "                       \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfIRbZUTPeQX",
        "outputId": "bab80a65-5faa-4690-8e47-59dcfd76a76f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.00875852  0.02968347  0.03308665 -0.02835228 -0.01226963  0.08441445\n",
            "  0.03303674  0.05103541 -0.01697742 -0.01577765  0.06972899  0.00490609\n",
            " -0.02069244  0.07354212  0.07200169 -0.02784333  0.00856447 -0.05491454\n",
            "  0.02859962 -0.03333077 -0.01728002  0.0557287   0.04092591  0.05927492\n",
            " -0.01725632 -0.04377813 -0.00842895 -0.00564028 -0.04898241 -0.02710576\n",
            " -0.03276608  0.0313632  -0.00436723 -0.03436001  0.03699801 -0.04601654\n",
            "  0.04075051  0.03726257 -0.03553419 -0.0628173  -0.03123069 -0.0353759\n",
            "  0.00546736  0.05002001 -0.09777351 -0.06816328 -0.01440394 -0.01097005\n",
            " -0.04983862  0.0248761 ], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# each sentence has been encoded into a 512 dimension vector\n",
        "embed_samples[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1RDJOQjP2N3",
        "outputId": "9499ec42-5a86-44dc-e675-0a3ead7e130b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can use the USE module into a Keras layer using the `hub.KerasLayer` class"
      ],
      "metadata": {
        "id": "RsY2p6boP8bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_encoder_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4',\n",
        "                                        input_shape=[], # shape of inputs coming to our model\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ],
      "metadata": {
        "id": "gH0SlnkNQGrv"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model using Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid', name='output_layer')\n",
        "], name='model_6_USE')\n",
        "\n",
        "# compile and fit the model\n",
        "model_6_history = compile_fit_RNNs(model_6, SAVE_DIR, \"tf_hub_sentence_encoder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "373NCa0_QYKi",
        "outputId": "a2d6d7ed-5a0e-48d7-eac0-3f2d896a5582"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/tf_hub_sentence_encoder/20230208-024301\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 17ms/step - loss: 0.5095 - accuracy: 0.7811 - val_loss: 0.4392 - val_accuracy: 0.8058\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4143 - accuracy: 0.8175 - val_loss: 0.4306 - val_accuracy: 0.8189\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3998 - accuracy: 0.8232 - val_loss: 0.4296 - val_accuracy: 0.8176\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3906 - accuracy: 0.8278 - val_loss: 0.4292 - val_accuracy: 0.8202\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3826 - accuracy: 0.8337 - val_loss: 0.4294 - val_accuracy: 0.8268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zAJvB1QQ67H",
        "outputId": "fc3299ef-1599-4a8c-8495-7a79f2f32448"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making predictions\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWJkD5ALQ87v",
        "outputId": "4cbeab43-9fcd-44ce-b470-7ba1ae736831"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeX3ae1BRN3v",
        "outputId": "55f71250-7e66-4226-c964-0a686baa295e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.67716535433071,\n",
              " 'precision': 0.8300866466031345,\n",
              " 'recall': 0.8267716535433071,\n",
              " 'f1-score': 0.8247090008454357}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare with baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEQhvKYnRbKh",
        "outputId": "a57ed12d-9efa-4bdf-9435-a16e3b804195"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.18, New accuracy: 82.68, Difference: 2.493\n",
            "Baseline precision: 0.81, New precision: 0.83, Difference: 0.018\n",
            "Baseline recall: 0.80, New recall: 0.83, Difference: 0.025\n",
            "Baseline f1-score: 0.80, New f1-score: 0.82, Difference: 0.028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we are able to beat the baseline score but using pretrained embeddings"
      ],
      "metadata": {
        "id": "NosNIMgDRg_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 7 : TensorFlow Hub Pretrained Sentence Encoder 10% of the training data\n",
        "\n",
        "One of the main benefits of using transfer learning methods, such as, the pretrained embeddings within the USE is the ability to get great results on a small amount of data (the USE paper even mentions this in the abstract)."
      ],
      "metadata": {
        "id": "SP5j_xsPRnjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qakknm_bUpo8",
        "outputId": "7aa80b86-0bde-4906-c592-423b5bfd7a94"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id            keyword                    location  \\\n",
              "7027  10072            typhoon                         NaN   \n",
              "318     463         armageddon                         NaN   \n",
              "1681   2425            collide  www.youtube.com?Malkavius2   \n",
              "5131   7318  nuclear%20reactor          New York, New York   \n",
              "2967   4262           drowning          Hendersonville, NC   \n",
              "...     ...                ...                         ...   \n",
              "406     584              arson           Jerusalem, Israel   \n",
              "5510   7863        quarantined                 Livonia, MI   \n",
              "2191   3139             debris                         NaN   \n",
              "7409  10600            wounded               santo domingo   \n",
              "2671   3833           detonate    back in japan ??????????   \n",
              "\n",
              "                                                   text  target  \n",
              "7027  Typhoon Soudelor: When will it hit Taiwan ÛÒ ...       1  \n",
              "318   RT @RTRRTcoach: #Love #TrueLove #romance lith ...       0  \n",
              "1681  I liked a @YouTube video from @gassymexican ht...       0  \n",
              "5131  Japan's Restart of Nuclear Reactor Fleet Fast ...       1  \n",
              "2967  #ICYMI #Annoucement from Al Jackson... http://...       0  \n",
              "...                                                 ...     ...  \n",
              "406   Mourning notices for stabbing arson victims st...       1  \n",
              "5510  Reddit's new content policy goes into effect m...       0  \n",
              "2191  Plane debris discovered on Reunion Island belo...       1  \n",
              "7409  Police Officer Wounded Suspect Dead After Exch...       1  \n",
              "2671  Detonate (feat. M?.?O?.?P?.?)\\nfrom Grandeur b...       0  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68b265f5-047e-4bc6-9a7c-b15d21eb6d2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7027</th>\n",
              "      <td>10072</td>\n",
              "      <td>typhoon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor: When will it hit Taiwan ÛÒ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>463</td>\n",
              "      <td>armageddon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @RTRRTcoach: #Love #TrueLove #romance lith ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>2425</td>\n",
              "      <td>collide</td>\n",
              "      <td>www.youtube.com?Malkavius2</td>\n",
              "      <td>I liked a @YouTube video from @gassymexican ht...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5131</th>\n",
              "      <td>7318</td>\n",
              "      <td>nuclear%20reactor</td>\n",
              "      <td>New York, New York</td>\n",
              "      <td>Japan's Restart of Nuclear Reactor Fleet Fast ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2967</th>\n",
              "      <td>4262</td>\n",
              "      <td>drowning</td>\n",
              "      <td>Hendersonville, NC</td>\n",
              "      <td>#ICYMI #Annoucement from Al Jackson... http://...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>584</td>\n",
              "      <td>arson</td>\n",
              "      <td>Jerusalem, Israel</td>\n",
              "      <td>Mourning notices for stabbing arson victims st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5510</th>\n",
              "      <td>7863</td>\n",
              "      <td>quarantined</td>\n",
              "      <td>Livonia, MI</td>\n",
              "      <td>Reddit's new content policy goes into effect m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2191</th>\n",
              "      <td>3139</td>\n",
              "      <td>debris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Plane debris discovered on Reunion Island belo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7409</th>\n",
              "      <td>10600</td>\n",
              "      <td>wounded</td>\n",
              "      <td>santo domingo</td>\n",
              "      <td>Police Officer Wounded Suspect Dead After Exch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2671</th>\n",
              "      <td>3833</td>\n",
              "      <td>detonate</td>\n",
              "      <td>back in japan ??????????</td>\n",
              "      <td>Detonate (feat. M?.?O?.?P?.?)\\nfrom Grandeur b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68b265f5-047e-4bc6-9a7c-b15d21eb6d2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68b265f5-047e-4bc6-9a7c-b15d21eb6d2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68b265f5-047e-4bc6-9a7c-b15d21eb6d2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
        "                                                                                                                            train_labels,\n",
        "                                                                                                                            test_size=0.1,\n",
        "                                                                                                                            random_state=17)"
      ],
      "metadata": {
        "id": "IMxJ7Lp1UX5E"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences_10_percent.shape, train_labels_10_percent.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrWNUwTeU-Qd",
        "outputId": "8b503b3a-4e72-4a0b-fd18-4e651528493a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((686,), (686,))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the length of 10 percent datasets\n",
        "print(f'Total Training examples: {len(train_sentences)}')\n",
        "print(f'Length of 10% training examples: {len(train_sentences_10_percent)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd-rtL16VJWA",
        "outputId": "b4ae215c-e80e-4632-8b13-74409309aaef"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Training examples: 6851\n",
            "Length of 10% training examples: 686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the number of targets in our subset of data\n",
        "pd.Series(train_labels_10_percent).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN7fqnIBVc8l",
        "outputId": "05a2d871-a12f-4b03-ecb2-8f0d030940a5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    409\n",
              "1    277\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to use the same architecture of `model_6` then we can try using cloning the model using `tf.keras.models.clone_model()`, doing this will create the same architecture but reset the learned weights of the clone target (pretrained weights from the USE will remain but all other will be reset)"
      ],
      "metadata": {
        "id": "l8ZKt6uFVzcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the architecture of model_6\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# compile the model\n",
        "model_7.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# fit the model\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_7_10_percent\")])"
      ],
      "metadata": {
        "id": "CSBN9vYBWhPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e469d3-8c21-452e-80fa-63cec3529d26"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/model_7_10_percent/20230208-025334\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 92ms/step - loss: 0.6651 - accuracy: 0.6968 - val_loss: 0.6418 - val_accuracy: 0.7546\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 47ms/step - loss: 0.5914 - accuracy: 0.8003 - val_loss: 0.5779 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 46ms/step - loss: 0.5117 - accuracy: 0.8294 - val_loss: 0.5194 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 53ms/step - loss: 0.4484 - accuracy: 0.8324 - val_loss: 0.4872 - val_accuracy: 0.7900\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 56ms/step - loss: 0.4034 - accuracy: 0.8324 - val_loss: 0.4758 - val_accuracy: 0.7979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "\n",
        "# convert it into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "\n",
        "model_7_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac_7_meu8Ta5",
        "outputId": "049976c0-3668-423f-f3be-e5780ee97946"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 1., 1., 0., 1., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's calculate the results\n",
        "model_7_results = calculate_results(val_labels,\n",
        "                                    model_7_preds)\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u62ddLX18rps",
        "outputId": "fdf9bee5-45b9-43e7-b6b5-3a27d1cd4480"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.79002624671917,\n",
              " 'precision': 0.7978709208429032,\n",
              " 'recall': 0.7979002624671916,\n",
              " 'f1-score': 0.7967846406102952}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the Performance of each of our models"
      ],
      "metadata": {
        "id": "mSxuwkge85TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# combine model results into a dataframe\n",
        "model_all_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\": simple_dense_results,\n",
        "                                  \"2_lstm\": model_2_results,\n",
        "                                  \"3_gru\": model_3_results,\n",
        "                                  \"4_bidirectional\": model_4_results,\n",
        "                                  \"5_conv1D\": model_5_results,\n",
        "                                  \"6_tf_hub_USE\": model_6_results,\n",
        "                                  \"7_tf_hub_USE_10_percent\": model_7_results})\n",
        "\n",
        "model_all_results = model_all_results.transpose()\n",
        "\n",
        "model_all_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "yDAr3vtb-F27",
        "outputId": "6d008200-336a-41e3-ceea-27b8eb951034"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          accuracy  precision    recall  f1-score\n",
              "0_baseline               80.183727   0.812557  0.801837  0.796868\n",
              "1_simple_dense           79.527559   0.796679  0.795276  0.793232\n",
              "2_lstm                   76.640420   0.765903  0.766404  0.766020\n",
              "3_gru                    75.590551   0.755188  0.755906  0.755120\n",
              "4_bidirectional          75.984252   0.760069  0.759843  0.759944\n",
              "5_conv1D                 75.984252   0.759154  0.759843  0.758913\n",
              "6_tf_hub_USE             82.677165   0.830087  0.826772  0.824709\n",
              "7_tf_hub_USE_10_percent  79.790026   0.797871  0.797900  0.796785"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f43798ce-f070-41b8-9db6-22af292c654f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>80.183727</td>\n",
              "      <td>0.812557</td>\n",
              "      <td>0.801837</td>\n",
              "      <td>0.796868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>79.527559</td>\n",
              "      <td>0.796679</td>\n",
              "      <td>0.795276</td>\n",
              "      <td>0.793232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>76.640420</td>\n",
              "      <td>0.765903</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.766020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>75.590551</td>\n",
              "      <td>0.755188</td>\n",
              "      <td>0.755906</td>\n",
              "      <td>0.755120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>75.984252</td>\n",
              "      <td>0.760069</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.759944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1D</th>\n",
              "      <td>75.984252</td>\n",
              "      <td>0.759154</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.758913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_USE</th>\n",
              "      <td>82.677165</td>\n",
              "      <td>0.830087</td>\n",
              "      <td>0.826772</td>\n",
              "      <td>0.824709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_USE_10_percent</th>\n",
              "      <td>79.790026</td>\n",
              "      <td>0.797871</td>\n",
              "      <td>0.797900</td>\n",
              "      <td>0.796785</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f43798ce-f070-41b8-9db6-22af292c654f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f43798ce-f070-41b8-9db6-22af292c654f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f43798ce-f070-41b8-9db6-22af292c654f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make the accuracy in the same range as other\n",
        "model_all_results['accuracy'] = model_all_results['accuracy']/100"
      ],
      "metadata": {
        "id": "4RZxJd9g_Vrw"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_all_results.plot(kind='bar', figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "L9Bb4tjE_-Ry",
        "outputId": "a2f0059b-a6b8-4d96-abc2-6a9fe5481d21"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the f1-score is the combination of recall and precision so let's plot f1-score value of each model in descending order"
      ],
      "metadata": {
        "id": "bxOnKXHcAmeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_all_results['f1-score'].sort_values(ascending=False).plot(kind='bar', figsize=(10, 7));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "66NC_W9SA3S9",
        "outputId": "1558c9cd-3a41-4ec9-9e6e-4eb8ffea1fba"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline**(`baseline_model`) is outperforming all the deep learning models except **Tensorflow Hub Universal Sentence Encoder** model i.e `model_6`.\n",
        "\n",
        "So always start with Baseline model training approach."
      ],
      "metadata": {
        "id": "urHC2adVBRDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading our model's training logs to TensorBoard\n"
      ],
      "metadata": {
        "id": "tzpwhmKVBnNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rhaLUeVbDuTH",
        "outputId": "a0c485ad-1d16-4ba7-c46b-3869e0dd1493"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_logs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir ./model_logs \\\n",
        "  --name \"NLP Experiments\" \\\n",
        "  --description \"A series of experiments of Natural Language processing dataset using many different approaches\" \\\n",
        "  --one_shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TB18-FdB41p",
        "outputId": "8c12fa95-50bd-42a6-ce29-ca0222680fee"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/Qxg0oj9rQw231Ad4MZYwig/\n",
            "\n",
            "\u001b[1m[2023-02-08T03:26:06]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2023-02-08T03:26:17]\u001b[0m Total uploaded: 210 scalars, 0 tensors, 7 binary objects (2.7 MB)\n",
            "\u001b[1m[2023-02-08T03:26:17]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/Qxg0oj9rQw231Ad4MZYwig/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save and Load the Best performing model\n",
        "\n",
        "`model_6` performed the best, so let's save that model i.e Universal Sentence Encoder TF Hub model"
      ],
      "metadata": {
        "id": "dUphR_BQDezG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"drive/MyDrive/Data Science/NLP_Disaster_Tweet/nlp_disaster_twt_classifier_USE.h5\"\n",
        "\n",
        "# saving the model in hd5 format\n",
        "model_6.save(f\"{model_dir}\")"
      ],
      "metadata": {
        "id": "hJ5YOppoE1Qk"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model with custom hub layer (required for HDF5 format)\n",
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model(model_dir, custom_objects={\"KerasLayer\":hub.KerasLayer})"
      ],
      "metadata": {
        "id": "Svi_SWQ2Gotd"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loaded_model_6_evaluate = loaded_model_6.evaluate(val_sentences,\n",
        "                                                  val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjqRx_gyHUFV",
        "outputId": "d43116e8-3367-4724-fb21-f865219d7a58"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step - loss: 0.4294 - accuracy: 0.8268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud2mkYb3Hk3r",
        "outputId": "b3fb5000-8ca6-4fec-fa54-a67fb3f30ba5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.67716535433071,\n",
              " 'precision': 0.8300866466031345,\n",
              " 'recall': 0.8267716535433071,\n",
              " 'f1-score': 0.8247090008454357}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing our Model's most wrong predictions\n",
        "\n",
        "We'll try to visualize model's wrong predictions and the model that we will consider is our best performing model i.e `model_6`\n",
        "\n",
        "So what we need ? We have,\n",
        "- Tweets in `val_sentences`\n",
        "- Actual Labels in `val_labels`\n",
        "- Prediction Probabilities in `model_6_pred_probs`\n",
        "- Predicted Labels in `model_6_preds`\n",
        "\n",
        "So let's create a dataframe for the above variables.\n"
      ],
      "metadata": {
        "id": "t1Pvril0Hn6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.squeeze(model_6_pred_probs[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35TW35lgJjXh",
        "outputId": "5b38a5b3-c7e9-48e0-daee-0c523cb0133f"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([0.4112893 , 0.12370362, 0.08662965, 0.08976427, 0.9920439 ,\n",
              "       0.5954548 , 0.11710725, 0.9699294 , 0.14874981, 0.11603939],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_predictions_df = pd.DataFrame({\"tweets\": val_sentences,\n",
        "                                       \"actual\": val_labels,\n",
        "                                       \"pred_probs\": tf.squeeze(model_6_pred_probs),\n",
        "                                       \"pred\":model_6_preds}).sort_values('pred_probs', ascending=False)\n",
        "# reset the index\n",
        "model_6_predictions_df.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "6go6tyivIeAb"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_predictions_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XiJzsfOEIofo",
        "outputId": "0d93b357-6010-46b1-dd70-e625748a45ed"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              tweets  actual  pred_probs  pred\n",
              "0  Dramatic Video Shows Plane Landing During Viol...       1    0.996967   1.0\n",
              "1  Malaysia Airlines Flight 370 that Disappeared ...       1    0.995433   1.0\n",
              "2  Gunmen open fire on bus near El Salvador's cap...       1    0.995371   1.0\n",
              "3  Monsoon flooding - Monsoon rains have have hit...       1    0.995311   1.0\n",
              "4  24 killed in two simultaneous rail crash as ac...       1    0.995307   1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-815515d5-bda3-489a-a0fb-a0a5f129e85e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>actual</th>\n",
              "      <th>pred_probs</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dramatic Video Shows Plane Landing During Viol...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996967</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Malaysia Airlines Flight 370 that Disappeared ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995433</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen open fire on bus near El Salvador's cap...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995371</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Monsoon flooding - Monsoon rains have have hit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995311</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24 killed in two simultaneous rail crash as ac...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995307</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-815515d5-bda3-489a-a0fb-a0a5f129e85e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-815515d5-bda3-489a-a0fb-a0a5f129e85e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-815515d5-bda3-489a-a0fb-a0a5f129e85e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's identify the most wrong predictions\n",
        "model_6_wrong_predictions = model_6_predictions_df[model_6_predictions_df['actual']!=model_6_predictions_df['pred']]\n",
        "\n",
        "model_6_wrong_predictions.head() # These are false positive, when the actual is 0 but model is predicted 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fIjZOiRkKRq_",
        "outputId": "d8404e60-9817-4f6c-cc2f-bf17becc99ac"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                tweets  actual  pred_probs  \\\n",
              "9    Kosciusko police investigating pedestrian fata...       0    0.990604   \n",
              "85   Episcopal priests on road trip with interracia...       0    0.952838   \n",
              "96   FAAN orders evacuation of abandoned aircraft a...       0    0.948847   \n",
              "99   Two Jewish Terrorists Charged In Historic-Chur...       0    0.944920   \n",
              "109  @writebothfists It got pretty windy here too.....       0    0.933099   \n",
              "\n",
              "     pred  \n",
              "9     1.0  \n",
              "85    1.0  \n",
              "96    1.0  \n",
              "99    1.0  \n",
              "109   1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d4d77b4-ea4c-4b6f-81c7-5825767a78b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>actual</th>\n",
              "      <th>pred_probs</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Kosciusko police investigating pedestrian fata...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.990604</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>Episcopal priests on road trip with interracia...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.952838</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>FAAN orders evacuation of abandoned aircraft a...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.948847</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Two Jewish Terrorists Charged In Historic-Chur...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.944920</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>@writebothfists It got pretty windy here too.....</td>\n",
              "      <td>0</td>\n",
              "      <td>0.933099</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d4d77b4-ea4c-4b6f-81c7-5825767a78b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d4d77b4-ea4c-4b6f-81c7-5825767a78b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d4d77b4-ea4c-4b6f-81c7-5825767a78b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many wrong predictions are there?\n",
        "len(model_6_wrong_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSnrTAvRK7-i",
        "outputId": "d27c80f6-2782-46bc-9b99-d5a6dfc43272"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_wrong_predictions.tail() # These are false negative, when the actual is 1 but model predicted 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "S-5HX9eXLIQi",
        "outputId": "db459fd7-247c-4773-ff0b-4cf4574d5568"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                tweets  actual  pred_probs  \\\n",
              "688                             @Truly_Stings Yo Dm me       1    0.064157   \n",
              "693  Jack Wilshere has poor injury recordand his of...       1    0.062328   \n",
              "698  Pandemonium use to be my fav cd ?? I had to ge...       1    0.060542   \n",
              "716  Keep shape your shoes ??#Amazon #foot #adjust ...       1    0.055170   \n",
              "744  Man Currensy really be talkin that talk... I'd...       1    0.042321   \n",
              "\n",
              "     pred  \n",
              "688   0.0  \n",
              "693   0.0  \n",
              "698   0.0  \n",
              "716   0.0  \n",
              "744   0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f34e4eec-ef03-4df0-9c16-29abb7be9e62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>actual</th>\n",
              "      <th>pred_probs</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>@Truly_Stings Yo Dm me</td>\n",
              "      <td>1</td>\n",
              "      <td>0.064157</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>Jack Wilshere has poor injury recordand his of...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.062328</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>Pandemonium use to be my fav cd ?? I had to ge...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.060542</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>Keep shape your shoes ??#Amazon #foot #adjust ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.055170</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>Man Currensy really be talkin that talk... I'd...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.042321</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f34e4eec-ef03-4df0-9c16-29abb7be9e62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f34e4eec-ef03-4df0-9c16-29abb7be9e62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f34e4eec-ef03-4df0-9c16-29abb7be9e62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false positives\n",
        "for row in model_6_wrong_predictions[:10].itertuples():\n",
        "  _, tweet, actual, pred_probs, pred = row\n",
        "  print(f\"Target: {actual}, Pred: {pred}, Prob: {pred_probs}\")\n",
        "  print(f\"Tweet:\\n{tweet}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hqhw7vGtLkco",
        "outputId": "b9249741-2171-47af-a80a-95f8c9485bd1"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9906039834022522\n",
            "Tweet:\n",
            "Kosciusko police investigating pedestrian fatality hit by a train Thursday http://t.co/m5djLLxoZP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.9528384804725647\n",
            "Tweet:\n",
            "Episcopal priests on road trip with interracial family shares harrowing story of police harassment http://t.co/RG4JIsHyBs via @dailykos\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.9488469362258911\n",
            "Tweet:\n",
            "FAAN orders evacuation of abandoned aircraft at MMA http://t.co/dEvYbnVXGQ via @todayng\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.9449200630187988\n",
            "Tweet:\n",
            "Two Jewish Terrorists Charged In Historic-Church Arson | The Ugly Truth http://t.co/iEksNFSbY7 http://t.co/VWCf3slkrW\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.9330989122390747\n",
            "Tweet:\n",
            "@writebothfists It got pretty windy here too... But no damage.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8820136785507202\n",
            "Tweet:\n",
            "Robert Conquest Famine Museum Kiev @GuidoFawkes @MediaGuido https://t.co/WE40iUX7Ib\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8804405927658081\n",
            "Tweet:\n",
            "PawSox owners public return from whirlwind trip to Durham - Knoxville News Sentinel http://t.co/9ckggGYvOU http://t.co/u0vdBrXfia\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8800685405731201\n",
            "Tweet:\n",
            "'Up' House Saved From Demolition - http://t.co/4CPNBBZkzg Will be moved to Orcas Island Washington.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.868062436580658\n",
            "Tweet:\n",
            "One thing you can be sure of. There will never be bush fires in Scotland as the ground is always soaking wet????\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.865434467792511\n",
            "Tweet:\n",
            "Beautiful lightning as seen from plane window http://t.co/5CwUyLnFUm http://t.co/1tyYqFz13D\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false negatives\n",
        "for row in model_6_wrong_predictions[-10:].itertuples():\n",
        "  _, tweet, actual, pred_probs, pred = row\n",
        "  print(f\"Target: {actual}, Pred: {pred}, Prob: {pred_probs}\")\n",
        "  print(f\"Tweet:\\n{tweet}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pREc_b5NNRW",
        "outputId": "58a77be1-250e-4a74-d400-3725ee384db9"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0.0, Prob: 0.08289161324501038\n",
            "Tweet:\n",
            "Please allow me to reiterate it's not the weapon it's the mindset of the individual! #professional #help! -LEGION! https://t.co/2lGTZkwMqW\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.08053254336118698\n",
            "Tweet:\n",
            "GAElite 0    Explosion Greg 2 [Top 3rd] [0 Out] [0 balls] [0 strikes] ... No one on [P: #16 Morgan Orchard] [B: ]\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.07742441445589066\n",
            "Tweet:\n",
            "Meek Mill responds to DrakeÛªs OVO Fest set with wedgie threat http://t.co/qqSKYbARNg\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.07410547137260437\n",
            "Tweet:\n",
            "Watch how bad that fool get burned in coverage this year. Dat dude is all-pro practice squad material\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.06825987249612808\n",
            "Tweet:\n",
            "Flattened thee striker\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.06415656954050064\n",
            "Tweet:\n",
            "@Truly_Stings Yo Dm me\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.06232791393995285\n",
            "Tweet:\n",
            "Jack Wilshere has poor injury recordand his off field behaviors doesn't help.#Arsenal\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.06054184213280678\n",
            "Tweet:\n",
            "Pandemonium use to be my fav cd ?? I had to get it http://t.co/6WhUgaeM3C\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05516950413584709\n",
            "Tweet:\n",
            "Keep shape your shoes ??#Amazon #foot #adjust #shape #shoe Mini Shoe Tree Stretcher Shaper Width Extender Adjustable http://t.co/8cPcz2xoHb\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04232141003012657\n",
            "Tweet:\n",
            "Man Currensy really be talkin that talk... I'd be more devastated if he had a ghostwriter than anybody else....\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making and Visualizing Predictions on Test Dataset\n",
        "\n",
        "So far we have evaluated our model on `train` and `validation` data but real test would be how our model is performing in the real world data, so before directly testing it with custom tweets we have our `test` data to make predictions with our best performing model."
      ],
      "metadata": {
        "id": "R-hyaLw9NeF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view our test data\n",
        "test_df[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ooBwRczeOw_o",
        "outputId": "a9087c72-d857-4561-eba8-ab237ed3f536"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
              "5  12     NaN      NaN                 We're shaking...It's an earthquake\n",
              "6  21     NaN      NaN  They'd probably still show more life than Arse...\n",
              "7  22     NaN      NaN                                  Hey! How are you?\n",
              "8  27     NaN      NaN                                   What a nice hat?\n",
              "9  29     NaN      NaN                                          Fuck off!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79c39ae6-7e8d-4cd8-ba7b-4cc9a41ba2ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We're shaking...It's an earthquake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They'd probably still show more life than Arse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hey! How are you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>What a nice hat?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fuck off!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79c39ae6-7e8d-4cd8-ba7b-4cc9a41ba2ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79c39ae6-7e8d-4cd8-ba7b-4cc9a41ba2ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79c39ae6-7e8d-4cd8-ba7b-4cc9a41ba2ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to make this test data compatible with our model"
      ],
      "metadata": {
        "id": "2-KG2J-aPECn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = test_df['text'].to_numpy()\n",
        "test_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqX0q0nBPQvt",
        "outputId": "bd9ab1fc-3ef1-4dcd-c9b2-a829e5c17d78"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Just happened a terrible car crash',\n",
              "       'Heard about #earthquake is different cities, stay safe everyone.',\n",
              "       'there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all',\n",
              "       'Apocalypse lighting. #Spokane #wildfires',\n",
              "       'Typhoon Soudelor kills 28 in China and Taiwan',\n",
              "       \"We're shaking...It's an earthquake\",\n",
              "       \"They'd probably still show more life than Arsenal did yesterday, eh? EH?\",\n",
              "       'Hey! How are you?', 'What a nice hat?', 'Fuck off!'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "test_pred_probs = model_6.predict(test_sentences)\n",
        "\n",
        "test_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icc2FEU5PaT0",
        "outputId": "69cd7e89-82e7-43f7-d03c-f7aa9d2e6213"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102/102 [==============================] - 1s 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6496799 ],\n",
              "       [0.8729977 ],\n",
              "       [0.8864363 ],\n",
              "       [0.91369927],\n",
              "       [0.9693103 ],\n",
              "       [0.4697555 ],\n",
              "       [0.06590932],\n",
              "       [0.05289321],\n",
              "       [0.07023633],\n",
              "       [0.06235705]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert them into comparable labels\n",
        "test_preds = tf.squeeze(tf.round(test_pred_probs))\n",
        "test_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKXgwDmIPirl",
        "outputId": "5fc32daf-3d9d-482f-c7ce-168afd540316"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3263,), dtype=float32, numpy=array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the test_df\n",
        "test_prediction_df = test_df\n",
        "\n",
        "test_prediction_df['probs'] = tf.squeeze(test_pred_probs)\n",
        "test_prediction_df['predictions'] = test_preds.numpy()"
      ],
      "metadata": {
        "id": "sZ10j_RnPtcG"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C02MwfQXRubC",
        "outputId": "e2060217-d54c-4c06-98a1-ce53f37c3bb5"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
              "\n",
              "   predictions     probs  \n",
              "0          1.0  0.649680  \n",
              "1          1.0  0.872998  \n",
              "2          1.0  0.886436  \n",
              "3          1.0  0.913699  \n",
              "4          1.0  0.969310  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae64ed5c-c7d5-492b-8874-df1214b99c5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>predictions</th>\n",
              "      <th>probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.649680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.872998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.886436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.913699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.969310</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae64ed5c-c7d5-492b-8874-df1214b99c5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae64ed5c-c7d5-492b-8874-df1214b99c5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae64ed5c-c7d5-492b-8874-df1214b99c5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize some predictions\n",
        "num_of_text = 10\n",
        "for row in test_prediction_df[:num_of_text].itertuples():\n",
        "  _,_,_,_,text,prediction,prob = row\n",
        "  pred_label = \"Disaster\" if prediction==1 else \"Not a Disaster\"\n",
        "  print(f\"Prediction: {pred_label}, Probs: {prob:2f}\")\n",
        "  print(f\"Text :\\n{text}\\n\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9PhCzZ2P7tA",
        "outputId": "e6e46312-c1e8-4524-b2e3-d7c98483e35e"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Disaster, Probs: 0.649680\n",
            "Text :\n",
            "Just happened a terrible car crash\n",
            "\n",
            "Prediction: Disaster, Probs: 0.872998\n",
            "Text :\n",
            "Heard about #earthquake is different cities, stay safe everyone.\n",
            "\n",
            "Prediction: Disaster, Probs: 0.886436\n",
            "Text :\n",
            "there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all\n",
            "\n",
            "Prediction: Disaster, Probs: 0.913699\n",
            "Text :\n",
            "Apocalypse lighting. #Spokane #wildfires\n",
            "\n",
            "Prediction: Disaster, Probs: 0.969310\n",
            "Text :\n",
            "Typhoon Soudelor kills 28 in China and Taiwan\n",
            "\n",
            "Prediction: Not a Disaster, Probs: 0.469756\n",
            "Text :\n",
            "We're shaking...It's an earthquake\n",
            "\n",
            "Prediction: Not a Disaster, Probs: 0.065909\n",
            "Text :\n",
            "They'd probably still show more life than Arsenal did yesterday, eh? EH?\n",
            "\n",
            "Prediction: Not a Disaster, Probs: 0.052893\n",
            "Text :\n",
            "Hey! How are you?\n",
            "\n",
            "Prediction: Not a Disaster, Probs: 0.070236\n",
            "Text :\n",
            "What a nice hat?\n",
            "\n",
            "Prediction: Not a Disaster, Probs: 0.062357\n",
            "Text :\n",
            "Fuck off!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tiAPgXWvQLX8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}