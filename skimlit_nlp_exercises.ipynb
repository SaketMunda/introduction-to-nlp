{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1WU4KgmZbm2vsfwKJNIvYoyPK-iGZy5e8",
      "authorship_tag": "ABX9TyMwQNkz706nMMureGDSwfpB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/introduction-to-nlp/blob/master/skimlit_nlp_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SkimLit NLP Milestone Project : Exercises\n",
        "\n",
        "1. Train `model_5` on all of the data in the training dataset for as many epochs until it stops improving. Since this might take a while, you might want to use:\n",
        "  - [tf.keras.callbacks.ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) to save the model's best weights only.\n",
        "  - [tf.keras.callbacks.EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to stop the model from training once the validation loss has stopped improving for ~3 epochs.\n",
        "2. Checkout the [Keras guide on using pretrained GloVe embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/). Can you get this working with one of our models?\n",
        "  - Hint: You'll want to incorporate it with a custom token [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n",
        "  - It's up to you whether or not you fine-tune the GloVe embeddings or leave them frozen.\n",
        "3. Try replacing the TensorFlow Hub Universal Sentence Encoder pretrained embedding for the [TensorFlow Hub BERT PubMed expert](https://tfhub.dev/google/experts/bert/pubmed/2) (a language model pretrained on PubMed texts) pretrained embedding. Does this effect results?\n",
        "  - Note: Using the BERT PubMed expert pretrained embedding requires an extra preprocessing step for sequences (as detailed in the [TensorFlow Hub guide](https://tfhub.dev/google/experts/bert/pubmed/2)).\n",
        "  - Does the BERT model beat the results mentioned in this paper? https://arxiv.org/pdf/1710.06071.pdf\n",
        "4. What happens if you were to merge our `line_number` and `total_lines` features for each sequence? For example, created a `X_of_Y` feature instead? Does this effect model performance?\n",
        "  - Another example: `line_number=1` and `total_lines=11` turns into `line_of_X=1_of_11`.\n",
        "5. Write a function (or series of functions) to take a sample abstract string, preprocess it (in the same way our model has been trained), make a prediction on each sequence in the abstract and return the abstract in the format:\n",
        "  - `PREDICTED_LABEL`: `SEQUENCE`\n",
        "  - `PREDICTED_LABEL`: `SEQUENCE`\n",
        "  - `PREDICTED_LABEL`: `SEQUENCE`\n",
        "  - `PREDICTED_LABEL`: `SEQUENCE`\n",
        "  - `...`\n",
        "    - You can find your own unstrcutured RCT abstract from PubMed or try this one from: [Baclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection](https://pubmed.ncbi.nlm.nih.gov/22244707/)."
      ],
      "metadata": {
        "id": "xqeSc1wpPe6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the gpu\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG0yKyYWQw_v",
        "outputId": "71ddf0c8-8169-45db-cf95-01648b05a4ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-60093581-201a-3d8e-80ff-31653e9161d9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import helper function\n",
        "!wget https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
        "\n",
        "from helper_functions import create_tensorboard_callback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqfBJbSvQ8JQ",
        "outputId": "2def4a92-ccc6-4de3-80f7-5cdf392a6057"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-18 03:51:42--  https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2904 (2.8K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]   2.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-18 03:51:42 (46.9 MB/s) - ‘helper_functions.py’ saved [2904/2904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the Data\n"
      ],
      "metadata": {
        "id": "5lu0cd2-RlhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVdiTWDCRpXf",
        "outputId": "6a943844-d7a2-4720-b4f9-ea0ce3dd8f16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 5), reused 5 (delta 5), pack-reused 25\u001b[K\n",
            "Unpacking objects: 100% (33/33), 177.08 MiB | 9.63 MiB/s, done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEiyZ6GIRr0U",
        "outputId": "757b2f8c-2630-408d-88d3-cb0f44db792d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'\n",
        "\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0XedXoMR13o",
        "outputId": "ada891f7-0492-4d34-8139-984c6797156b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Data"
      ],
      "metadata": {
        "id": "5iLt-F9wfKCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform Data\n",
        "\n",
        "Since our data is in txt format, we need to convert it into some dataframe for further training and modelling experiments."
      ],
      "metadata": {
        "id": "4atv4tYKSQX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads a filename(.txt) and returns the lines of text as a list.\n",
        "  \"\"\"\n",
        "  with open(filename, 'r') as file:\n",
        "    return file.readlines()"
      ],
      "metadata": {
        "id": "K0j7AyBtSjW1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines = get_lines(data_dir + 'train.txt')\n",
        "train_lines[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HVzLlMVS6py",
        "outputId": "8276bfb8-0e3d-4a2c-aec9-58511c506845"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to write a function which can transform the labels associated with the sentence in one column, the text in another column and also few other details like line_number and total_lines.\n",
        "\n",
        "In a format like,\n",
        "\n",
        "```\n",
        "[\n",
        "  {\n",
        "    'line_number':0,\n",
        "    'target': 'OBJECTIVE',\n",
        "    'text': 'To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .'\n",
        "    'total_lines':11\n",
        "  }\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "bBugiCwPTGq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "  Returns the list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes the filename as input, reads it contents and sort through each line, \n",
        "  extracting things like the target label, text of the sentence, how many lines\n",
        "  in that abstract and what sentence number the target line is.\n",
        "  \"\"\"\n",
        "\n",
        "  input_lines = get_lines(filename)\n",
        "  abstract_lines = \"\"\n",
        "  abstract_samples = []\n",
        "\n",
        "  for line in input_lines:\n",
        "    if line.startswith('###'):\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\"\n",
        "    elif line.isspace():\n",
        "      abstract_line_split = abstract_lines.splitlines()\n",
        "\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {}\n",
        "        target_text_split = abstract_line.split('\\t')\n",
        "        line_data['target'] = target_text_split[0]\n",
        "        line_data['text'] = target_text_split[1].lower()\n",
        "        line_data['line_number'] = abstract_line_number\n",
        "        line_data['total_lines'] = len(abstract_line_split) - 1 # starting from 0\n",
        "        abstract_samples.append(line_data)\n",
        "    else:\n",
        "      abstract_lines+=line\n",
        "  \n",
        "  return abstract_samples"
      ],
      "metadata": {
        "id": "GwRzj-aATWmM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data from files and preprocess it\n",
        "%%time\n",
        "\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir+'train.txt')\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir+'test.txt')\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir+'dev.txt')\n",
        "\n",
        "len(train_samples), len(test_samples), len(val_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx0Ydlf5WCgC",
        "outputId": "c9862846-fdb7-4f8a-d74e-13bad64e623d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 356 ms, sys: 81.2 ms, total: 438 ms\n",
            "Wall time: 440 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30135, 30212)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples[:12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4HsuAO9WhBb",
        "outputId": "d20cdb10-d080-430a-da8e-6924f2376435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 11},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 11}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's convert them into `pandas` dataframe"
      ],
      "metadata": {
        "id": "I0M32S9fYFB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "\n",
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP5jqPvEYVXD",
        "outputId": "c2f3978d-10e7-4b98-c532-8523c676eece"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hjBZ4bsyYi6z",
        "outputId": "a36a3cff-fc52-4f26-d0c9-95414bfdb565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target                                               text  line_number  \\\n",
              "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
              "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
              "2    METHODS  outcome measures included pain reduction and i...            2   \n",
              "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
              "4    METHODS  secondary outcome measures included the wester...            4   \n",
              "\n",
              "   total_lines  \n",
              "0           11  \n",
              "1           11  \n",
              "2           11  \n",
              "3           11  \n",
              "4           11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c226d11-3c29-4f87-b589-8f8ea13fa843\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c226d11-3c29-4f87-b589-8f8ea13fa843')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c226d11-3c29-4f87-b589-8f8ea13fa843 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c226d11-3c29-4f87-b589-8f8ea13fa843');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubsZ0Y2FY5Ll",
        "outputId": "ac014596-c487-43c2-afff-ed947e246b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.total_lines.plot.hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "HnuiJCKoYmPM",
        "outputId": "2be86dc6-8368-42da-9abc-955f0f2a347a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the list of sentences\n"
      ],
      "metadata": {
        "id": "xKS7fpV8Y-HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = train_df.text.tolist()\n",
        "test_sentences = test_df.text.tolist()\n",
        "val_sentences = val_df.text.tolist()\n",
        "\n",
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCDCcah_ZIwc",
        "outputId": "d086a064-79be-46c0-c810-7043e7ec79a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make numeric labels"
      ],
      "metadata": {
        "id": "rr29TQ0RZZr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## one hot encoded\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot = one_hot_encoder.fit_transform(test_df['target'].to_numpy().reshape(-1,1))\n",
        "val_labels_one_hot = one_hot_encoder.fit_transform(val_df['target'].to_numpy().reshape(-1,1))\n",
        "\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPCwa8KAaJ3N",
        "outputId": "fb974501-51f6-4eab-ba90-e85b979c8ba1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the class names and number of classes from OneHotEncoder instance\n",
        "num_classes = len(one_hot_encoder.categories_[0])\n",
        "class_names = one_hot_encoder.categories_[0]\n",
        "\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-GHUlfKbE24",
        "outputId": "f41d2ca5-aa9a-4f69-d59c-5f5e9a525d1e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OneHotEncode `line_number` and `total_lines`"
      ],
      "metadata": {
        "id": "IMrEUnzDbKG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "train_line_number_one_hot = tf.one_hot(train_df['line_number'].to_numpy(), depth=15)\n",
        "test_line_number_one_hot = tf.one_hot(test_df['line_number'].to_numpy(), depth=15)\n",
        "val_line_number_one_hot = tf.one_hot(val_df['line_number'].to_numpy(), depth=15)\n",
        "\n",
        "train_line_number_one_hot[:10], train_line_number_one_hot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Us2bLZ2cYUR",
        "outputId": "e93c4f97-c92e-4b53-fc37-2e8f42b6670e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10, 15), dtype=float32, numpy=\n",
              " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
              "       dtype=float32)>, TensorShape([180040, 15]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same with total lines\n",
        "train_total_lines_one_hot = tf.one_hot(train_df['total_lines'].to_numpy(), depth=20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df['total_lines'].to_numpy(), depth=20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df['total_lines'].to_numpy(), depth=20)\n",
        "\n",
        "train_total_lines_one_hot[:10], train_total_lines_one_hot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plmvMRmtcu77",
        "outputId": "bac600ca-93f5-483f-b4fb-f6224b50407f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
              " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.]], dtype=float32)>, TensorShape([180040, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Sentences into Characters"
      ],
      "metadata": {
        "id": "epDop9YfdEEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_chars(text):\n",
        "  return \" \".join(list(text))"
      ],
      "metadata": {
        "id": "XsdCpBpceUkP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "\n",
        "train_chars[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "KYJvTyi0ehzh",
        "outputId": "ac81b35f-6ee9-4e99-87f5-02ba247f61d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Train `model_5` for as many epochs until it stops improving"
      ],
      "metadata": {
        "id": "17mb2hTpe-nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's load the model\n",
        "drive_path = 'drive/MyDrive/Data Science/SkimLit/skimlit_tribrid_model'\n",
        "\n",
        "model = tf.keras.models.load_model(drive_path)"
      ],
      "metadata": {
        "id": "Ch-wO0oDfern"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "MfBLD_jAf5md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So first we need to create few things for further training,\n",
        "- Create a prefetched dataset using `tf.Data.Dataset` API of tensorflow\n",
        "- ModelCheckpoint using `tf.keras.callbacks.ModelCheckpoint`\n",
        "- EarlyStopping using `tf.keras.callbacks.EarlyStopping`"
      ],
      "metadata": {
        "id": "-UrzL6NjgV-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prefetch Dataset\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_line_number_one_hot,\n",
        "                                                    train_total_lines_one_hot,\n",
        "                                                    train_sentences,\n",
        "                                                    train_chars))\n",
        "train_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
        "\n",
        "train_dataset = tf.data.Dataset.zip((train_data, train_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF73tZxPiXvj",
        "outputId": "1501cf07-99e3-477b-f86f-bf50a2bc54f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=((TensorSpec(shape=(None, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = tf.data.Dataset.from_tensor_slices((val_line_number_one_hot,\n",
        "                                               val_total_lines_one_hot,\n",
        "                                               val_sentences,\n",
        "                                               val_chars))\n",
        "val_labels = tf.data.Dataset.from_tensor_slices((val_labels_one_hot))\n",
        "\n",
        "val_dataset = tf.data.Dataset.zip((val_data, val_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_line_number_one_hot,\n",
        "                                                test_total_lines_one_hot,\n",
        "                                                test_sentences,\n",
        "                                                test_chars))\n",
        "\n",
        "test_labels = tf.data.Dataset.from_tensor_slices((test_labels_one_hot))\n",
        "\n",
        "test_dataset = tf.data.Dataset.zip((test_data, test_labels)).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "UHoLdAk2jM-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model checkpoint callback\n",
        "filepath = 'model_logs/checkpoint'\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
        "                                                               monitor='val_loss',\n",
        "                                                               save_weights_only=True,\n",
        "                                                               save_best_only=True,\n",
        "                                                               mode='min',\n",
        "                                                               save_freq = 'epoch')\n",
        "\n",
        "# early stopping callback\n",
        "model_early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                                 patience=3)"
      ],
      "metadata": {
        "id": "fDLZ3h4YkAzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great ! Now we can first compile the loaded model and then we can fit the model with callbacks to see the results."
      ],
      "metadata": {
        "id": "al8CGFn4l3Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=50,                    \n",
        "                    validation_data=val_dataset,\n",
        "                    validation_steps=int(0.1 * len(val_dataset)),\n",
        "                    callbacks=[create_tensorboard_callback('model_logs/tensorboard','model_exercise_1'),\n",
        "                               model_checkpoint_callback,\n",
        "                               model_early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSDVAHQjmBAh",
        "outputId": "38a3ac41-11f9-47a1-ae9a-f0f7ff1f8287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to: model_logs/tensorboard/model_exercise_1/20230316-040934\n",
            "Epoch 1/50\n",
            "5627/5627 [==============================] - 194s 32ms/step - loss: 0.3945 - accuracy: 0.8506 - val_loss: 0.3671 - val_accuracy: 0.8574\n",
            "Epoch 2/50\n",
            "5627/5627 [==============================] - 176s 31ms/step - loss: 0.3519 - accuracy: 0.8686 - val_loss: 0.3506 - val_accuracy: 0.8630\n",
            "Epoch 3/50\n",
            "5627/5627 [==============================] - 182s 32ms/step - loss: 0.3298 - accuracy: 0.8773 - val_loss: 0.3482 - val_accuracy: 0.8624\n",
            "Epoch 4/50\n",
            "5627/5627 [==============================] - 183s 33ms/step - loss: 0.3145 - accuracy: 0.8822 - val_loss: 0.3472 - val_accuracy: 0.8670\n",
            "Epoch 5/50\n",
            "5627/5627 [==============================] - 179s 32ms/step - loss: 0.3008 - accuracy: 0.8867 - val_loss: 0.3520 - val_accuracy: 0.8677\n",
            "Epoch 6/50\n",
            "5627/5627 [==============================] - 178s 32ms/step - loss: 0.2897 - accuracy: 0.8910 - val_loss: 0.3531 - val_accuracy: 0.8660\n",
            "Epoch 7/50\n",
            "5627/5627 [==============================] - 179s 32ms/step - loss: 0.2795 - accuracy: 0.8943 - val_loss: 0.3544 - val_accuracy: 0.8677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets evaluate on validation data\n",
        "model.evaluate(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82RbLLVam9br",
        "outputId": "71fe76eb-1ede-468c-abcd-81c17cccf8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 18s 19ms/step - loss: 0.3631 - accuracy: 0.8668\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36314550042152405, 0.8668410181999207]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2 : Using pretrained GloVe embeddings"
      ],
      "metadata": {
        "id": "uIpckEHMtR9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorizer Layer"
      ],
      "metadata": {
        "id": "bKY2_KK4nQ5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify the average sentence length of training data\n",
        "import numpy as np\n",
        "sentence_length = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_length = np.mean(sentence_length)\n",
        "avg_sent_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4gePnlpjqE2",
        "outputId": "3be3ec20-6e48-42d1-b41b-8e9accb2eb5e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sentence_length, bins=5);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vm5Xqnixkzhg",
        "outputId": "e6b0b559-4679-4bde-cdff-01588bd733a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like majority of sentences are between 0 and 50 tokens in length.\n",
        "\n",
        "We can use Numpy's percentile to find the value which covers 95% of the sentence lengths."
      ],
      "metadata": {
        "id": "O3tvs7c6mUaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq_len = int(np.percentile(sentence_length, 95))\n",
        "output_seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OijPlSZWmwZy",
        "outputId": "b3f41bfc-9f0d-42cb-e701-83eecc549917"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also according to the [PubMed 200K RCT Paper](https://arxiv.org/pdf/1710.06071.pdf), the vocabulary size of the PubMed 20K dataset should be 68,000, so i.e our `max_tokens` value in TextVectorization"
      ],
      "metadata": {
        "id": "1Q0zkgw4nPDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens = 68000\n",
        "\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=max_tokens, output_sequence_length=output_seq_len)"
      ],
      "metadata": {
        "id": "uck5ZQFLntwS"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adapt the training samples\n",
        "vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "ZRdt9mvJoHXp"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get information from our `vectorizer` of `train_sentences`"
      ],
      "metadata": {
        "id": "oQK1ZGvEoPUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vectorizer.get_vocabulary()\n",
        "\n",
        "print(f'Number of vocabulary in training sentences:{len(vocab)}')\n",
        "print(f'\\nMost common words in the vocabulary:{vocab[:5]}')\n",
        "print(f'\\nLeast common words in the vocabulary:{vocab[-5:]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfMIkWZopI5T",
        "outputId": "a705aa8b-09b8-4c17-9c0a-8807a8bcf938"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vocabulary in training sentences:64841\n",
            "\n",
            "Most common words in the vocabulary:['', '[UNK]', 'the', 'and', 'of']\n",
            "\n",
            "Least common words in the vocabulary:['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create pretrained GloVe embedding layer\n",
        "\n",
        "https://keras.io/examples/nlp/pretrained_word_embeddings/"
      ],
      "metadata": {
        "id": "CRPmVJZTphvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pretrained embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7oD2B-Ep8eL",
        "outputId": "6782267d-e7a7-4a11-fbc8-e94e5da77436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-17 03:41:13--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-03-17 03:41:14--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-03-17 03:41:14--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.11MB/s    in 2m 39s  \n",
            "\n",
            "2023-03-17 03:43:55 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The zip file contains text-encoded vectors of various sizes: 50 dimensional, 100 dimensional, 200 dimensional, 300 dimensional. We'll use 100D ones first.\n",
        "\n"
      ],
      "metadata": {
        "id": "2b8OP0X5qEHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_filename = 'glove.6B.100d.txt'\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(glove_filename, 'r') as f:\n",
        "  for line in f:\n",
        "    word, coefs = line.split(maxsplit=1)\n",
        "    coefs = np.fromstring(coefs,'f', sep=\" \")\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "len(embeddings_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-_UEsmxrt81",
        "outputId": "cbc7a341-4bfc-4a06-adae-6da67f4b7013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the embeddings of 5 most common words of our vocabulary in glove embedding"
      ],
      "metadata": {
        "id": "X_86IuGoshRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_words = vocab[:5]\n",
        "common_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK3N9yPCsnZ8",
        "outputId": "5be2c0d3-3c74-4095-8e8a-fb1dd54d884d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'and', 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in common_words:\n",
        "  if word in embeddings_index.keys():\n",
        "    print(f\"\\nEmbedding of '{word}':\\n {embeddings_index[word]}\")\n",
        "  else:\n",
        "    print(f\"\\nEmbedding doesn't exist of {word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArPQCrn_uKRl",
        "outputId": "348e7837-6346-4091-85a2-9d61e45aba8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Embedding doesn't exist of \n",
            "\n",
            "Embedding doesn't exist of [UNK]\n",
            "\n",
            "Embedding of 'the':\n",
            " [-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n",
            "\n",
            "Embedding of 'and':\n",
            " [-0.071953  0.23127   0.023731 -0.50638   0.33923   0.1959   -0.32943\n",
            "  0.18364  -0.18057   0.28963   0.20448  -0.5496    0.27399   0.58327\n",
            "  0.20468  -0.49228   0.19974  -0.070237 -0.88049   0.29485   0.14071\n",
            " -0.1009    0.99449   0.36973   0.44554   0.28998  -0.1376   -0.56365\n",
            " -0.029365 -0.4122   -0.25269   0.63181  -0.44767   0.24363  -0.10813\n",
            "  0.25164   0.46967   0.3755   -0.23613  -0.14129  -0.44537  -0.65737\n",
            " -0.042421 -0.28636  -0.28811   0.063766  0.20281  -0.53542   0.41307\n",
            " -0.59722  -0.38614   0.19389  -0.17809   1.6618   -0.011819 -2.3737\n",
            "  0.058427 -0.2698    1.2823    0.81925  -0.22322   0.72932  -0.053211\n",
            "  0.43507   0.85011  -0.42935   0.92664   0.39051   1.0585   -0.24561\n",
            " -0.18265  -0.5328    0.059518 -0.66019   0.18991   0.28836  -0.2434\n",
            "  0.52784  -0.65762  -0.14081   1.0491    0.5134   -0.23816   0.69895\n",
            " -1.4813   -0.2487   -0.17936  -0.059137 -0.08056  -0.48782   0.014487\n",
            " -0.6259   -0.32367   0.41862  -1.0807    0.46742  -0.49931  -0.71895\n",
            "  0.86894   0.19539 ]\n",
            "\n",
            "Embedding of 'of':\n",
            " [-0.1529   -0.24279   0.89837   0.16996   0.53516   0.48784  -0.58826\n",
            " -0.17982  -1.3581    0.42541   0.15377   0.24215   0.13474   0.41193\n",
            "  0.67043  -0.56418   0.42985  -0.012183 -0.11677   0.31781   0.054177\n",
            " -0.054273  0.35516  -0.30241   0.31434  -0.33846   0.71715  -0.26855\n",
            " -0.15837  -0.47467   0.051581 -0.33252   0.15003  -0.1299   -0.54617\n",
            " -0.37843   0.64261   0.82187  -0.080006  0.078479 -0.96976  -0.57741\n",
            "  0.56491  -0.39873  -0.057099  0.19743   0.065706 -0.48092  -0.20125\n",
            " -0.40834   0.39456  -0.02642  -0.11838   1.012    -0.53171  -2.7474\n",
            " -0.042981 -0.74849   1.7574    0.59085   0.04885   0.78267   0.38497\n",
            "  0.42097   0.67882   0.10337   0.6328   -0.026595  0.58647  -0.44332\n",
            "  0.33057  -0.12022  -0.55645   0.073611  0.20915   0.43395  -0.012761\n",
            "  0.089874 -1.7991    0.084808  0.77112   0.63105  -0.90685   0.60326\n",
            " -1.7515    0.18596  -0.50687  -0.70203   0.66578  -0.81304   0.18712\n",
            " -0.018488 -0.26757   0.727    -0.59363  -0.34839  -0.56094  -0.591\n",
            "  1.0039    0.20664 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now, we have to prepare a corresponding embedding matrix that we can use in Keras `Embedding` layer. It's a simple Numpy matrix where entry at `index i` is the pre-trained vector for the word of `index i` in our vectorizer's vocabulary."
      ],
      "metadata": {
        "id": "WzFmJ8G4ugDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# it will create the index of all the words in the vocabulary\n",
        "word_index = dict(zip(vocab, range(len(vocab))))"
      ],
      "metadata": {
        "id": "rJ821p5rxVHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(vocab) + 2\n",
        "output_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, output_dim))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # Words not found in embedding index will be all-zeroes\n",
        "    # This include the representation for \"OOV\" and \"padding\"\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "    hits += 1\n",
        "  else:\n",
        "    misses += 1\n",
        "\n",
        "print(f'Converted {hits} words ({misses} misses)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9EypaW2wWZS",
        "outputId": "a8ed6c4e-d7c2-42a8-b679-1ad3130e59da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 29730 words (35111 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lot's of misses, anyways let's create the `Embedding Layer`"
      ],
      "metadata": {
        "id": "0sFFolXAyTmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_layer = layers.Embedding(\n",
        "    input_dim=num_tokens,\n",
        "    output_dim=output_dim,\n",
        "    mask_zero=True,\n",
        "    embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False # freezing the embeddings, not updating the values while training\n",
        "    )"
      ],
      "metadata": {
        "id": "7ZQCX6apzzN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try in any one of the random `train_sentences`"
      ],
      "metadata": {
        "id": "7-1yeaee0N6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "sample_sentence = random.choice(train_sentences)\n",
        "\n",
        "print(f'Sentence before embedding:\\n{sample_sentence}')\n",
        "vectorized_sentence= vectorizer([sample_sentence])\n",
        "print(f'\\nVectorized Sentence:\\n{vectorized_sentence}')\n",
        "embedded_sentence = embedding_layer(vectorized_sentence)\n",
        "print(f'\\nSentence after embedding:\\n{embedded_sentence}')\n",
        "print(f'\\nEmbedded Sentence Shape:{embedded_sentence.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ3sFqZP1Cjt",
        "outputId": "6568ead5-2fd3-4cf5-8ac1-cc2ec1abc0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before embedding:\n",
            "the ideal duration of modified ultrafiltration has not been established yet .\n",
            "\n",
            "Vectorized Sentence:\n",
            "[[   2 3913  282    4  599 6582  139   31  167 1016 1337    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "Sentence after embedding:\n",
            "[[[-0.038194 -0.24487   0.72812  ... -0.1459    0.8278    0.27062 ]\n",
            "  [ 0.021146  0.3907    0.40079  ... -0.71329   0.077824  0.62242 ]\n",
            "  [-0.3765    0.18407  -0.23377  ...  0.33156   0.04296  -0.44148 ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]]\n",
            "\n",
            "Embedded Sentence Shape:(1, 55, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Prefetch Dataset"
      ],
      "metadata": {
        "id": "daf1LrWR2EIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_ex_2 = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset_ex_2 = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset_ex_2 = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset_ex_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Sjndew2NOX",
        "outputId": "29ec51e3-1b04-422b-e450-2d401b5b56b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create & Build the Model"
      ],
      "metadata": {
        "id": "u4xhxudV2q8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "text_vectorizer = vectorizer(inputs)\n",
        "pretrained_embed = embedding_layer(text_vectorizer)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding='same', activation='relu')(pretrained_embed)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name='experiment_2_pretrained_glove')\n",
        "\n",
        "# compile the model\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pORtGd1v20OE",
        "outputId": "ca2e1302-6c30-46ef-a466-097ad26c53f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"experiment_2_pretrained_glove\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None,)]                 0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 55, 100)           6484300   \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 55, 64)            32064     \n",
            "                                                                 \n",
            " global_average_pooling1d_4   (None, 64)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,516,689\n",
            "Trainable params: 32,389\n",
            "Non-trainable params: 6,484,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "history_2 = model_2.fit(train_dataset_ex_2,\n",
        "                        steps_per_epoch=int(0.1 * len(train_dataset_ex_2)),\n",
        "                        epochs=3,\n",
        "                        validation_data=val_dataset_ex_2,\n",
        "                        validation_steps=int(0.1 * len(val_dataset_ex_2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6NC5hy44dlX",
        "outputId": "16c2aec9-6f6e-4753-fcb5-e14a23329e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 13s 5ms/step - loss: 1.0442 - accuracy: 0.5974 - val_loss: 0.9611 - val_accuracy: 0.6350\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 3s 5ms/step - loss: 0.8981 - accuracy: 0.6535 - val_loss: 0.8861 - val_accuracy: 0.6586\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 3s 5ms/step - loss: 0.8633 - accuracy: 0.6714 - val_loss: 0.8496 - val_accuracy: 0.6892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can further train with more epochs and also add more conv layers and pooling layer in the process of fine-tuning to obtain better metrics results."
      ],
      "metadata": {
        "id": "WUgXy07F56IO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3 : Use Tensorflow Hub BERT instead of USE\n",
        "\n",
        "Try replacing the TensorFlow Hub Universal Sentence Encoder pretrained embedding for the [TensorFlow Hub BERT PubMed expert](https://tfhub.dev/google/experts/bert/pubmed/2) (a language model pretrained on PubMed texts) pretrained embedding. Does this effect results?\n",
        "  - Note: Using the BERT PubMed expert pretrained embedding requires an extra preprocessing step for sequences (as detailed in the [TensorFlow Hub guide](https://tfhub.dev/google/experts/bert/pubmed/2)).\n",
        "  - Does the BERT model beat the results mentioned in this paper? https://arxiv.org/pdf/1710.06071.pdf"
      ],
      "metadata": {
        "id": "kVKIQ7m16qo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create pretrained BERT PubMed expert layer"
      ],
      "metadata": {
        "id": "j7EA6xeK7GS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --quiet tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9ai7JwO8tD4",
        "outputId": "c021791d-70a4-4ff5-a410-0c0defef9de0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/5.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/5.8 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m5.4/5.8 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load the Bert encoder ad preprocessing models\n",
        "bert_preprocessing_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "                                          trainable=False,\n",
        "                                          name='bert_preprocessing_layer')\n",
        "\n",
        "bert_layer = hub.KerasLayer('https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "                            trainable=False,\n",
        "                            name='bert_model_layer')"
      ],
      "metadata": {
        "id": "TFv34ZeB7UZi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For prefetched dataset we will use the same as `Experiment 2` i.e `train_dataset_exp_2`"
      ],
      "metadata": {
        "id": "_AWhfivI9g7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build and Fit the BERT model"
      ],
      "metadata": {
        "id": "0nYZ5UZjsilX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = layers.Input(shape=[], dtype=tf.string, name='input_sentences')\n",
        "bert_inputs = bert_preprocessing_layer(input)\n",
        "bert_embedding = bert_layer(bert_inputs)\n",
        "print(f'bert embedding shape: {bert_embedding}')\n",
        "x = layers.Dense(128, activation='relu')(bert_embedding['pooled_output'])\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "pubmed_bert_model = tf.keras.Model(input, output)\n",
        "pubmed_bert_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnoGGJiyvdjb",
        "outputId": "f2baa2da-7741-479c-f18d-6e0c89d72e83"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert embedding shape: {'default': <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'bert_model_layer')>, 'sequence_output': <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, 'encoder_outputs': [<KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>], 'pooled_output': <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'bert_model_layer')>}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_sentences (InputLayer)   [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " bert_preprocessing_layer (Kera  {'input_mask': (Non  0          ['input_sentences[0][0]']        \n",
            " sLayer)                        e, 128),                                                          \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " bert_model_layer (KerasLayer)  {'default': (None,   109482241   ['bert_preprocessing_layer[0][0]'\n",
            "                                768),                            , 'bert_preprocessing_layer[0][1]\n",
            "                                 'sequence_output':              ',                               \n",
            "                                 (None, 128, 768),                'bert_preprocessing_layer[0][2]'\n",
            "                                 'encoder_outputs':              ]                                \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['bert_model_layer[0][13]']      \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 5)            645         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,581,318\n",
            "Trainable params: 99,077\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "pubmed_bert_model.compile(loss='categorical_crossentropy',\n",
        "                          optimizer='Adam',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "# fit the model\n",
        "history_bert = pubmed_bert_model.fit(train_dataset_ex_2,\n",
        "                                     epochs=3,\n",
        "                                     steps_per_epoch=int(0.1 * len(train_dataset_ex_2)),\n",
        "                                     validation_data=val_dataset_ex_2,\n",
        "                                     validation_steps=int(0.1 * len(val_dataset_ex_2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joVn0vrY2hyo",
        "outputId": "fe05b9c3-b8d8-4c9b-8c30-dc3124ec7c68"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 252s 423ms/step - loss: 0.6534 - accuracy: 0.7740 - val_loss: 0.4420 - val_accuracy: 0.8454\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 237s 422ms/step - loss: 0.5218 - accuracy: 0.8189 - val_loss: 0.4331 - val_accuracy: 0.8431\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 227s 404ms/step - loss: 0.5006 - accuracy: 0.8255 - val_loss: 0.4170 - val_accuracy: 0.8570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "pubmed_bert_model.evaluate(val_dataset_ex_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLxZb0jy3MvP",
        "outputId": "d1e1edec-b29d-440c-aa50-d7bb2736d233"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 336s 355ms/step - loss: 0.4123 - accuracy: 0.8517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4123277962207794, 0.8516814708709717]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4 : Convert the `line_number` and `total_lines` feature into `X_of_Y`\n",
        "\n",
        "What happens if you were to merge our `line_number` and `total_lines` features for each sequence? For example, created a `X_of_Y` feature instead? Does this effect model performance?\n",
        "  - Another example: `line_number=1` and `total_lines=11` turns into `line_of_X=1_of_11`."
      ],
      "metadata": {
        "id": "bUBnLvcH3VFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's first view data\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HP4JPPx33kop",
        "outputId": "cc59663c-baee-4d28-b752-3669199adaf4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target  ... total_lines\n",
              "0  OBJECTIVE  ...          11\n",
              "1    METHODS  ...          11\n",
              "2    METHODS  ...          11\n",
              "3    METHODS  ...          11\n",
              "4    METHODS  ...          11\n",
              "\n",
              "[5 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddd493a5-423b-4d0b-b333-6926a384ebd6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddd493a5-423b-4d0b-b333-6926a384ebd6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddd493a5-423b-4d0b-b333-6926a384ebd6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddd493a5-423b-4d0b-b333-6926a384ebd6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['line_number_total'] = train_df['line_number'].astype(str) + '_of_' + train_df['total_lines'].astype(str)\n",
        "val_df['line_number_total'] = train_df['line_number'].astype(str) + '_of_' + train_df['total_lines'].astype(str)\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TIebCHH13u2m",
        "outputId": "fa3ec0c2-1cc4-433b-85ba-d6e8ff76b846"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target  ... line_number_total\n",
              "0  OBJECTIVE  ...           0_of_11\n",
              "1    METHODS  ...           1_of_11\n",
              "2    METHODS  ...           2_of_11\n",
              "3    METHODS  ...           3_of_11\n",
              "4    METHODS  ...           4_of_11\n",
              "\n",
              "[5 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f5136dd-e20a-4d96-9400-a36c1a1fc1f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "      <th>line_number_total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>2_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>3_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>4_of_11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f5136dd-e20a-4d96-9400-a36c1a1fc1f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f5136dd-e20a-4d96-9400-a36c1a1fc1f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f5136dd-e20a-4d96-9400-a36c1a1fc1f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65XskEyI7-sv",
        "outputId": "22de67ec-68ad-4fb5-ab7f-48a51602fb74"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target               object\n",
              "text                 object\n",
              "line_number           int64\n",
              "total_lines           int64\n",
              "line_number_total    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OneHot Encode"
      ],
      "metadata": {
        "id": "HgDa_eMI-xnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode the new feature\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "\n",
        "# Fitting the onehotencoder\n",
        "one_hot_encoder.fit(np.expand_dims(train_df['line_number_total'], axis=1))\n",
        "\n",
        "# Transforming both train and val df\n",
        "train_line_number_total_encoded = one_hot_encoder.transform(np.expand_dims(train_df['line_number_total'], axis=1))\n",
        "val_line_number_total_encoded = one_hot_encoder.transform(np.expand_dims(val_df['line_number_total'], axis=1))\n",
        "\n",
        "# checking the shapes\n",
        "train_line_number_total_encoded.shape, val_line_number_total_encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhiPe7Fa4Dit",
        "outputId": "2fcfe13b-39d8-403e-b51e-f34d29ba0de8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((180040, 460), (30212, 460))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_line_number_total_encoded[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQfwN0AQ7Btf",
        "outputId": "67f79c0f-c654-422b-cd6f-6a0ac560672f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x460 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the sparse matrix to array\n",
        "train_line_number_total_encoded = train_line_number_total_encoded.toarray()\n",
        "val_line_number_total_encoded = val_line_number_total_encoded.toarray()\n",
        "\n",
        "train_line_number_total_encoded[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cvKBu1h-1eY",
        "outputId": "7895b192-a75f-4d29-91bc-34416180c2d0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0.])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the dtype to int\n",
        "train_line_number_total_encoded= tf.cast(train_line_number_total_encoded, dtype=tf.float32)\n",
        "val_line_number_total_encoded= tf.cast(val_line_number_total_encoded, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "ivOD_cR__JMa"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_line_number_total_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1rgjjk2_gzl",
        "outputId": "ebbe7085-91ae-4b92-db0e-1385af0ef655"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_line_number_total_encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6U365FqGy5D",
        "outputId": "19909922-c708-49ba-db6f-2299a41db824"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([180040, 460])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prefetch dataset"
      ],
      "metadata": {
        "id": "hZVxCTE-7H_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_exp_4 = tf.data.Dataset.from_tensor_slices((train_line_number_total_encoded,\n",
        "                                                       train_sentences,\n",
        "                                                       train_chars))\n",
        "train_labels_exp_4 = tf.data.Dataset.from_tensor_slices((train_labels_one_hot))\n",
        "\n",
        "train_dataset_exp_4 = tf.data.Dataset.zip((train_data_exp_4, train_labels_exp_4)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "val_data_exp_4 = tf.data.Dataset.from_tensor_slices((val_line_number_total_encoded,\n",
        "                                                     val_sentences,\n",
        "                                                     val_chars))\n",
        "val_labels_exp_4 = tf.data.Dataset.from_tensor_slices((val_labels_one_hot))\n",
        "\n",
        "val_dataset_exp_4 = tf.data.Dataset.zip((val_data_exp_4, val_labels_exp_4)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "train_dataset_exp_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf9T8Vg87SOl",
        "outputId": "d4932f3b-1a4b-4e03-923b-70222852ccb9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=((TensorSpec(shape=(None, 460), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Character Level Tokenizer and Embedding"
      ],
      "metadata": {
        "id": "zns6fw3JBL2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_chars[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "sCElPlRdBTaj",
        "outputId": "2b794a88-e02b-412d-853f-9b22dd875c82"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# identify the maximum character length\n",
        "char_len = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_length = np.mean(char_len)\n",
        "mean_char_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKftopj-BaVO",
        "outputId": "a45987f1-1b4e-4d35-a77a-5beaa86a1ed1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_len, bins=7);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "bZe8NzEABuQv",
        "outputId": "7e075c37-32e4-42f8-f9fd-273115eeae2d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like the majority of sentences have char_len is between 0-400"
      ],
      "metadata": {
        "id": "46FNsy3uB5TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq_char_len = int(np.percentile(char_len, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNY-dDFLCAOz",
        "outputId": "1f650ea5-a0e2-4264-a2b0-3c12a69ccc86"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "alphabet = string.ascii_lowercase + string.punctuation + string.digits\n",
        "alphabet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LqWnU84OCzca",
        "outputId": "7b331bae-7f86-4a64-ba1e-11548df26b72"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0123456789'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2\n",
        "\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    name='char_vectorizer')\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "uut3e7c6DISC"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "\n",
        "print(f'Number of different characters:{len(char_vocab)}')\n",
        "print(f'Number of most common chars:{char_vocab[:5]}')\n",
        "print(f'Number of least common chars:{char_vocab[-5:]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-zcgJU6DfWr",
        "outputId": "31c9e829-3122-45e8-9f17-931314f26846"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different characters:28\n",
            "Number of most common chars:['', '[UNK]', 'e', 't', 'i']\n",
            "Number of least common chars:['k', 'x', 'z', 'q', 'j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to create an Embedding Layer"
      ],
      "metadata": {
        "id": "hHt61wLcD28s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "char_embed = Embedding(input_dim=NUM_CHAR_TOKENS,\n",
        "                       output_dim=25,\n",
        "                       mask_zero=False,\n",
        "                       name='char_embedding')"
      ],
      "metadata": {
        "id": "x1wPVwMLD8Kr"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the model"
      ],
      "metadata": {
        "id": "N_eotRD0Adjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Token Inputs (using BERT model as a layer)\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name='token_inputs')\n",
        "token_preprocess_bert = bert_preprocessing_layer(token_inputs)\n",
        "token_embedded_bert = bert_layer(token_preprocess_bert)\n",
        "token_outputs = layers.Dense(128, activation='relu')(token_embedded_bert['pooled_output'])\n",
        "token_model = tf.keras.Model(token_inputs, token_outputs)\n",
        "\n",
        "\n",
        "# 2. Char Inputs\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name='char_inputs')\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embedded = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embedded)\n",
        "char_model = tf.keras.Model(char_inputs, char_bi_lstm)\n",
        "\n",
        "\n",
        "# 3. Line NUmber Total inputs\n",
        "line_number_total_inputs = layers.Input(shape=(460,), dtype=tf.float32, name='line_number_totals')\n",
        "x = layers.Dense(64, activation='relu')(line_number_total_inputs)\n",
        "line_number_total_model = tf.keras.Model(line_number_total_inputs, x)\n",
        "\n",
        "# 4. Combine outputs of 1 and 2\n",
        "combined_embeddings = layers.Concatenate(name='token_char_embeddings')([token_model.output,\n",
        "                                                                        char_model.output])\n",
        "\n",
        "z = layers.Dense(256, activation='relu')(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "\n",
        "# Combine outputs of 3 and 4\n",
        "z = layers.Concatenate(name='token_char_line_number_totals_embeddings')([line_number_total_model.output,\n",
        "                                                                         z])\n",
        "\n",
        "# Create an output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax', name='output_layer')(z)\n",
        "model_4 = tf.keras.Model(inputs=[line_number_total_model.input,\n",
        "                                 token_model.input,\n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name='model_4_tribrid_model')"
      ],
      "metadata": {
        "id": "1jfZdi_TBBPB"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOEzh4GVIM9_",
        "outputId": "af802cfa-ba3b-466c-f16a-64282806af67"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_tribrid_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " token_inputs (InputLayer)      [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " char_inputs (InputLayer)       [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " bert_preprocessing_layer (Kera  {'input_mask': (Non  0          ['token_inputs[0][0]']           \n",
            " sLayer)                        e, 128),                                                          \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " char_vectorizer (TextVectoriza  (None, 290)         0           ['char_inputs[0][0]']            \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " bert_model_layer (KerasLayer)  {'default': (None,   109482241   ['bert_preprocessing_layer[2][0]'\n",
            "                                768),                            , 'bert_preprocessing_layer[2][1]\n",
            "                                 'sequence_output':              ',                               \n",
            "                                 (None, 128, 768),                'bert_preprocessing_layer[2][2]'\n",
            "                                 'encoder_outputs':              ]                                \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " char_embedding (Embedding)     (None, 290, 25)      1750        ['char_vectorizer[0][0]']        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          98432       ['bert_model_layer[2][13]']      \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 64)           14848       ['char_embedding[0][0]']         \n",
            "                                                                                                  \n",
            " token_char_embeddings (Concate  (None, 192)         0           ['dense_3[0][0]',                \n",
            " nate)                                                            'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " line_number_totals (InputLayer  [(None, 460)]       0           []                               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 256)          49408       ['token_char_embeddings[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64)           29504       ['line_number_totals[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 256)          0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " token_char_line_number_totals_  (None, 320)         0           ['dense_4[0][0]',                \n",
            " embeddings (Concatenate)                                         'dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " output_layer (Dense)           (None, 5)            1605        ['token_char_line_number_totals_e\n",
            "                                                                 mbeddings[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,677,788\n",
            "Trainable params: 195,547\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's compile the model\n",
        "model_4.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pz6GEg8nI5WO"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_4 = model_4.fit(train_dataset_exp_4,\n",
        "                        epochs=3,\n",
        "                        steps_per_epoch=int(0.1 * len(train_dataset_exp_4)),\n",
        "                        validation_data=val_dataset_exp_4,\n",
        "                        validation_steps=int(0.1 * len(val_dataset_exp_4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeKxRvkTJS-Z",
        "outputId": "830a1def-fa89-4a29-c7c4-b379b52cc139"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 254s 436ms/step - loss: 0.9849 - accuracy: 0.8112 - val_loss: 0.9622 - val_accuracy: 0.8241\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 248s 441ms/step - loss: 0.8831 - accuracy: 0.8731 - val_loss: 1.0701 - val_accuracy: 0.7311\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 249s 442ms/step - loss: 0.8658 - accuracy: 0.8831 - val_loss: 1.1024 - val_accuracy: 0.7118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(val_dataset_exp_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vssZSwXbJ4XB",
        "outputId": "edeead9a-fc42-450c-b6b1-5fbbf863314a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 337s 357ms/step - loss: 1.1241 - accuracy: 0.7030\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1240503787994385, 0.7029657363891602]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "orzObO42KFv2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}